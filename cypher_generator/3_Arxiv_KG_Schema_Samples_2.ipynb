{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZbM1DMDwhmT7gAuDoytNI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Builder - Parametric Queries - Part II"
      ],
      "metadata": {
        "id": "36gYjVzINawd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this notebook:**\n",
        "\n",
        "- process data extracted from KG,\n",
        "- generate sample queries - part II,\n",
        "- save the data to a file.\n",
        "\n",
        "There are 31 generating functions in this collection."
      ],
      "metadata": {
        "id": "cjZYMDI2cQT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workspace Setup"
      ],
      "metadata": {
        "id": "i0sxPVZnNfFp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ4XwHqGNFSq"
      },
      "outputs": [],
      "source": [
        "%pip install neo4j\n",
        "%pip install python-levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and mount the drive helper\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the working directory\n",
        "%cd '/content/drive/MyDrive/cypherGen/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5OQXISWNj6U",
        "outputId": "ebd6d566-9b56-423f-ba0f-1bc65c450862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/cypherGen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import neo4j\n",
        "import pandas as pd\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "# Import the local modules\n",
        "from utils.utilities import *\n",
        "from utils.graph_utils import *"
      ],
      "metadata": {
        "id": "mPBZDJ0pNmO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for Sample Building"
      ],
      "metadata": {
        "id": "byPso7wFNujd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a path variable for the data folder\n",
        "data_path = '/content/drive/MyDrive/cypherGen/datas/'\n",
        "\n",
        "# File names\n",
        "schema_file = 'schema_file.json'\n",
        "#formatted_schema_file = 'formatted_schema.txt'\n",
        "node_instances_file = 'node_instances_file.json'\n",
        "rels_instances_file = 'rels_instances_file.json'\n",
        "\n",
        "# Read data from JSON files\n",
        "jschema = read_json(data_path+schema_file)\n",
        "node_instances = read_json(data_path+node_instances_file)\n",
        "rels_instances = read_json(data_path+rels_instances_file)"
      ],
      "metadata": {
        "id": "rzsiflhYNwxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of node labesl\n",
        "nodes = get_nodes_list(jschema)\n",
        "\n",
        "# Read the nodes with their properties and datatypes\n",
        "node_props_types = jschema['node_props']\n",
        "\n",
        "# Read the relationship properties with their datatypes\n",
        "rel_props_types = jschema['rel_props']\n",
        "\n",
        "# Read the relationships as a list of triples\n",
        "relationships = jschema['relationships']\n",
        "\n",
        "# Extract node labels and properties with data type: STRING\n",
        "string_properties = get_nodes_properties_of_datatype(jschema, nodes,'STRING')\n",
        "\n",
        "# Extract node labels and properties with data type: INTEGER\n",
        "integer_properties = get_nodes_properties_of_datatype(jschema, nodes, 'INTEGER')\n",
        "\n",
        "# Extract node labels and properties with data type: DATE\n",
        "date_properties = get_nodes_properties_of_datatype(jschema, nodes, 'DATE')"
      ],
      "metadata": {
        "id": "cZrmmfiIN1FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and parse n instances of specified datatype\n",
        "\n",
        "string_parsed = parse_node_instances_datatype(jschema, node_instances, nodes,'STRING')\n",
        "string_parsed = filter_empty_sublists(string_parsed)\n",
        "\n",
        "integer_parsed =  parse_node_instances_datatype(jschema, node_instances, nodes,'INTEGER')\n",
        "integer_parsed = filter_empty_sublists(integer_parsed)\n",
        "\n",
        "date_parsed =  parse_node_instances_datatype(jschema, node_instances, nodes,'DATE')\n",
        "date_parsed = filter_empty_sublists(date_parsed)\n",
        "\n",
        "# All node instances parsed\n",
        "dtypes_parsed = string_parsed+integer_parsed+date_parsed"
      ],
      "metadata": {
        "id": "UTNvEeloN4C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse relationships instances\n",
        "\n",
        "string_string_rels = filter_relationships_instances(jschema, rels_instances, 'STRING', 'STRING')\n",
        "string_integer_rels = filter_relationships_instances(jschema, rels_instances, 'STRING', 'INTEGER')\n",
        "string_date_rels = filter_relationships_instances(jschema, rels_instances, 'STRING', 'DATE')\n",
        "integer_integer_rels = filter_relationships_instances(jschema, rels_instances, 'INTEGER', 'INTEGER')\n",
        "date_date_rels = filter_relationships_instances(jschema, rels_instances, 'DATE', 'DATE')\n",
        "all_rels = string_string_rels+string_integer_rels+string_date_rels+integer_integer_rels+date_date_rels"
      ],
      "metadata": {
        "id": "hVMvvw_cN62g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to collect the samples\n",
        "trainer=[]\n",
        "\n",
        "# Function to select a number of samples of each type\n",
        "def collect_samples(sampler, M=100):\n",
        "    M = min(M, len(sampler))\n",
        "    rsampler = random.sample(sampler, M)\n",
        "    return rsampler"
      ],
      "metadata": {
        "id": "uYcKvNdhZHfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the Nodes"
      ],
      "metadata": {
        "id": "c3prW6srEZIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count nodes of given label\n",
        "def count_nodes_of_given_label():\n",
        "    def prompter(label_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the total number of {label_1} in the graph!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) RETURN count(n)\"\n",
        "                   }\n",
        "        return message\n",
        "    sampler = []\n",
        "    for label in nodes:\n",
        "        temp_dict = prompter(label)\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_1 = count_nodes_of_given_label()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_1)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_1)\n",
        "# Display an example for inspection\n",
        "sampler_1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhAIXX3k9tvs",
        "outputId": "e064161f-4226-489d-c901-4b9a07487da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 9 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the total number of Article in the graph!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (n:Article) RETURN count(n)'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find node by property\n",
        "def find_node_by_property():\n",
        "    def prompter(label_1, prop_1, val_1):\n",
        "        # Extract subschema for the variables of interest\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the {label_1} for which {prop_1} is {val_1}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1} {{{prop_1}:'{val_1}'}}) RETURN n\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in dtypes_parsed:\n",
        "        temp_dict = prompter(e[0], e[1], e[2])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "\n",
        "# Build the set\n",
        "sampler_2 =  find_node_by_property()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_2)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_2)\n",
        "# Display an example for inspection\n",
        "sampler_2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY-9zXIB9tr8",
        "outputId": "d62a155f-9a00-467c-e492-cafa95ea6f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 87 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the Article for which abstract is   Using matrix inversion and determinant evaluation techniques we prove several\\nsummation and transformation formulas for terminating, balanced,\\nvery-well-poised, elliptic hypergeometric series.\\n!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': \"MATCH (n:Article {abstract:'  Using matrix inversion and determinant evaluation techniques we prove several\\nsummation and transformation formulas for terminating, balanced,\\nvery-well-poised, elliptic hypergeometric series.\\n'}) RETURN n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find node with property that starts with substring\n",
        "def find_node_by_start_substring():\n",
        "    def prompter(label_1, prop_1, val_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the {label_1} for which {prop_1} starts with {val_1[:3]}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} STARTS WITH '{val_1[:3]}' RETURN n\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in string_parsed:\n",
        "        temp_dict = prompter(e[0], e[1], e[2])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_3 = find_node_by_start_substring()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_3)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_3)\n",
        "# Display an example for inspection\n",
        "sampler_3[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-vBWQF4AesK",
        "outputId": "f3749131-5d0d-45d6-bf77-5a35dccf14ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 76 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the Article for which abstract starts with   U!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': \"MATCH (n:Article) WHERE n.abstract STARTS WITH '  U' RETURN n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find properties of nodes with property that starts with substring\n",
        "def return_properties_for_prop_by_start_substring():\n",
        "    def prompter(label_1, prop_1, val_1, prop_2, prop_3):\n",
        "        # Extract subschema for the variables of interest\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the {label_1} for which the {prop_1} starts with {val_1[:2]} and return the {prop_1}, {prop_2} and {prop_3}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} STARTS WITH '{val_1[:2]}' RETURN n.{prop_1} AS {prop_1}, n.{prop_2} AS {prop_2}, n.{prop_3} AS {prop_3}\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "\n",
        "    for entry in string_parsed:\n",
        "        label_1 = entry[0]\n",
        "        prop_1 = entry[1]\n",
        "        val_1 = entry[2]\n",
        "\n",
        "        if len(node_props_types[label_1]) > 1:\n",
        "                prop_2 = node_props_types[label_1][0]['property']\n",
        "                prop_3 = node_props_types[label_1][1]['property']\n",
        "        else:\n",
        "                prop_2 = prop_3 = node_props_types[label_1][0]['property']\n",
        "\n",
        "        temp_dict = prompter(label_1, prop_1, val_1, prop_2, prop_3)\n",
        "        sampler.append(temp_dict)\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_4 = return_properties_for_prop_by_start_substring()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_4)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_4)\n",
        "# Display an example for inspection\n",
        "sampler_4[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA6ceeMBAehr",
        "outputId": "0cab719b-c53d-4440-c753-00839e6ed342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 76 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the Topic for which the description starts with Th and return the description, cluster and description!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nTopic {cluster: INTEGER, description: STRING, label: STRING}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': \"MATCH (n:Topic) WHERE n.description STARTS WITH 'Th' RETURN n.description AS description, n.cluster AS cluster, n.description AS description\"}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the Paths"
      ],
      "metadata": {
        "id": "jdOSgYSPEiY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all one hoops from given node\n",
        "def find_node_neighbours():\n",
        "    def prompter(label_1, prop_1, val_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find all nodes directly connected to the {label_1} that has {prop_1} equal to {val_1}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH path=(:{label_1} {{{prop_1}:'{val_1}'}})-->() RETURN path\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in dtypes_parsed:\n",
        "        temp_dict = prompter(e[0], e[1], e[2])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_5 = find_node_neighbours()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_5)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_5)\n",
        "# Display an example for inspection\n",
        "sampler_5[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeOlBFznBcf-",
        "outputId": "e719d8d7-1ba6-4d4e-c18b-610ac9426bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 87 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find all nodes directly connected to the Article that has comments equal to 44 pages!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': \"MATCH path=(:Article {comments:'44 pages'})-->() RETURN path\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_relation_count():\n",
        "    def prompter(label_1, prop_1,rel_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Fetch all the {label_1} and return the {prop_1} and the number of nodes connected to them via {rel_1}.\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) RETURN n.{prop_1} AS {prop_1}, size((n)<-[:{rel_1}]-()) AS count\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[4].items():\n",
        "            temp_dict = prompter(e[0], k, e[2])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_6 = find_node_relation_count()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_6)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_6)\n",
        "# Display an example for inspection\n",
        "sampler_6[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4nyFgutEoZp",
        "outputId": "fb749b9b-8ed6-4cb9-cb4b-c4ee14eb8323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 144 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Fetch all the Article and return the name and the number of nodes connected to them via HAS_KEY.',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (n:Article) RETURN n.name AS name, size((n)<-[:HAS_KEY]-()) AS count'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_relation_node_count():\n",
        "    def prompter(label_1, prop_1,rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find all the {label_1} and return their {prop_1} along with the count of {label_2} that are linked via {rel_1}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) RETURN n.{prop_1} AS {prop_1}, count(m) AS count\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_7 = find_node_relation_node_count()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_7)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_7)\n",
        "# Display an example for inspection\n",
        "sampler_7[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j25aNG5EoWp",
        "outputId": "7bf7005f-b4cf-4f00-e10f-ae1ca6cecee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find all the Article and return their abstract along with the count of Keyword that are linked via HAS_KEY!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) RETURN n.abstract AS abstract, count(m) AS count'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter with Nodes and Paths"
      ],
      "metadata": {
        "id": "ajXybkudJvqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count nodes of given label\n",
        "def find_node_property_count():\n",
        "    def prompter(label_1, prop_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the total number of {label_1} that have the {prop_1} recorded!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE EXISTS(n.{prop_1}) RETURN count(n)\"\n",
        "                   }\n",
        "        return message\n",
        "\n",
        "    sampler = []\n",
        "\n",
        "    for e in dtypes_parsed:\n",
        "        temp_dict = prompter(e[0], e[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_8 = find_node_property_count()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_8)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_8)\n",
        "# Display an example for inspection\n",
        "sampler_8[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vf2KSpQJqn1",
        "outputId": "0a432492-cccb-44a8-e98c-c951c307755e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 87 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the total number of Article that have the abstract recorded!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (n:Article) WHERE EXISTS(n.abstract) RETURN count(n)'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count nodes of given label\n",
        "def find_node_notproperty_count():\n",
        "    def prompter(label_1, prop_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the total number of {label_1} for which the {prop_1} is missing!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE NOT EXISTS(n.{prop_1}) RETURN count(n)\"\n",
        "                   }\n",
        "        return message\n",
        "    sampler = []\n",
        "\n",
        "    for e in dtypes_parsed:\n",
        "        temp_dict = prompter(e[0], e[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_9 = find_node_notproperty_count()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_9)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_9)\n",
        "# Display an example for inspection\n",
        "sampler_9[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tHfzS7KJqe5",
        "outputId": "eb9d554f-8ca5-4dcd-d0cb-1ae80eb35909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 87 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the total number of Article for which the abstract is missing!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (n:Article) WHERE NOT EXISTS(n.abstract) RETURN count(n)'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pattern check\n",
        "def find_notrelationships():\n",
        "    def prompter(label_1, rel_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Fetch five {label_1} that are not linked through {rel_1} relationships!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (p:{label_1}) WHERE NOT EXISTS ((p)-[:{rel_1}]->()) RETURN p LIMIT 5\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        temp_dict = prompter(e[0], e[2])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_10 = find_notrelationships()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_10)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_10)\n",
        "# Display an example for inspection\n",
        "sampler_10[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGPQbkqDEq9x",
        "outputId": "45977d31-7bdc-4b98-b5ed-7547466324fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 72 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Fetch five Article that are not linked through HAS_KEY relationships!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (p:Article) WHERE NOT EXISTS ((p)-[:HAS_KEY]->()) RETURN p LIMIT 5'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pattern check\n",
        "def find_yesrelationships():\n",
        "    def prompter(label_1, rel_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find four {label_1} that have {rel_1} links!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (p:{label_1}) WHERE EXISTS ((p)-[:{rel_1}]->()) RETURN p LIMIT 4\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        temp_dict = prompter(e[0], e[2])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_11 = find_yesrelationships()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_11)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_11)\n",
        "# Display an example for inspection\n",
        "sampler_11[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUkAzCjSrzgt",
        "outputId": "69ba952b-5a76-4deb-e22b-73bca20d0c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 72 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find four Article that have HAS_KEY links!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (p:Article) WHERE EXISTS ((p)-[:HAS_KEY]->()) RETURN p LIMIT 4'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_relation_ordered_count():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"For each {label_1}, find the number of {label_2} linked via {rel_1} and retrieve the {prop_1} of the {label_1} and the {label_2} counts in ascending order!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m RETURN n.{prop_1} AS {prop_1}, count(m) AS {label_2.lower()}_count ORDER BY {label_2.lower()}_count\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_12 = find_node_relation_ordered_count()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_12)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_12)\n",
        "# Display an example for inspection\n",
        "sampler_12[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd66ri_wrzYo",
        "outputId": "e5b72c41-7377-4801-f5a5-105d30b7933b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'For each Article, find the number of Keyword linked via HAS_KEY and retrieve the abstract of the Article and the Keyword counts in ascending order!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m RETURN n.abstract AS abstract, count(m) AS keyword_count ORDER BY keyword_count'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_relation_ordered_count_desc():\n",
        "    def prompter(label_1, prop_1,rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"For each {label_1} find its {prop_1} and the count of {label_2} linked via {rel_1}, and retrieve seven results in desc order of the counts!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m RETURN n.{prop_1} AS {prop_1}, count(m) AS count ORDER BY count DESC LIMIT 7\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_13 = find_node_relation_ordered_count_desc()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_13)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_13)\n",
        "# Display an example for inspection\n",
        "sampler_13[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZW5Jez9rzRa",
        "outputId": "001d99a1-d0fc-4f95-a993-8d59ca81638a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'For each Article find its abstract and the count of Keyword linked via HAS_KEY, and retrieve seven results in desc order of the counts!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m RETURN n.abstract AS abstract, count(m) AS count ORDER BY count DESC LIMIT 7'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Node count by property and relation\n",
        "def find_node_relation_ordered_count_filter():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"For each {label_1} and its {prop_1}, count the {label_2} connected through {rel_1} and fetch the {prop_1} and the counts that are greater than 5, starting with the largest {prop_1} and count!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m WITH n.{prop_1} AS {prop_1}, count(m) AS count WHERE count > 5 RETURN {prop_1}, count ORDER BY {prop_1} DESC, count DESC\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_14 = find_node_relation_ordered_count_filter()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_14)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_14)\n",
        "# Display an example for inspection\n",
        "sampler_14[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_FEbYnGr3dT",
        "outputId": "4b52d47d-dfeb-475d-8eb1-332516cb01e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'For each Article and its abstract, count the Keyword connected through HAS_KEY and fetch the abstract and the counts that are greater than 5, starting with the largest abstract and count!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m WITH n.abstract AS abstract, count(m) AS count WHERE count > 5 RETURN abstract, count ORDER BY abstract DESC, count DESC'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregations"
      ],
      "metadata": {
        "id": "F3e4Kes41CPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_relation_ordered_count_collect():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Fetch the {prop_1} of the {label_1} that are linked via {rel_1} to more than three {label_2}, and list {label_2} {prop_2} and {label_2} counts, ordering by {label_2} count and limiting to the top six results!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m WITH n.{prop_1} AS {prop_1}, count(m) AS count, COLLECT(m.{prop_2}) as {prop_2} WHERE count > 3 RETURN {prop_1}, count, {prop_2} ORDER BY count LIMIT 6\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            for kk, vv in e[4].items():\n",
        "                temp_dict = prompter(e[0], k, e[2], e[3], kk)\n",
        "                sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_15 = find_node_relation_ordered_count_collect()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_15)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_15)\n",
        "# Display an example for inspection\n",
        "sampler_15[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yps2VT6zr3aa",
        "outputId": "c913e30b-c196-45ac-c557-5bfbf0bb6115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 408 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Fetch the abstract of the Article that are linked via HAS_KEY to more than three Keyword, and list Keyword name and Keyword counts, ordering by Keyword count and limiting to the top six results!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m WITH n.abstract AS abstract, count(m) AS count, COLLECT(m.name) as name WHERE count > 3 RETURN abstract, count, name ORDER BY count LIMIT 6'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def aggregate_integers_by_string():\n",
        "    def prompter(label_1, prop_1, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"For each nonull {prop_1} of the {label_1}, how many times does it appear, and what are the minimum, maximum and average values of {prop_2} associated to it?\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} IS NOT NULL WITH DISTINCT n WITH n.{prop_1} as {prop_1}, COUNT(n) AS count, min(n.{prop_2}) AS min({prop_2}), max(n.{prop_2}) AS max({prop_2}), avg(n.{prop_2}) AS avg({prop_2}) RETURN {prop_1}, count, min({prop_2}), max({prop_2}), avg({prop_2})\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in integer_parsed:\n",
        "        for ee in integer_parsed:\n",
        "            if e[0] == ee[0]:\n",
        "                temp_dict = prompter(e[0], e[1], ee[1])\n",
        "                sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Creates a list of samples of the form\n",
        "aggregate_integers_by_string()[1]\n",
        "\n",
        "# Build the set\n",
        "sampler_16 = aggregate_integers_by_string()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_16)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_16)\n",
        "# Display an example for inspection\n",
        "sampler_16[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeXt80rGr3XT",
        "outputId": "fc657e4f-1dcb-4228-86ec-45a1a19462d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 25 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'For each nonull article_id of the Article, how many times does it appear, and what are the minimum, maximum and average values of article_id associated to it?',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (n:Article) WHERE n.article_id IS NOT NULL WITH DISTINCT n WITH n.article_id as article_id, COUNT(n) AS count, min(n.article_id) AS min(article_id), max(n.article_id) AS max(article_id), avg(n.article_id) AS avg(article_id) RETURN article_id, count, min(article_id), max(article_id), avg(article_id)'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def aggregate_numerical_by_integer():\n",
        "    def prompter(label_1, prop_1, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the {label_1} counts where {prop_1} is smaller than ten, and return the maximum, minimum and average values of the {prop_2}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} < 10 WITH DISTINCT n WITH n.{prop_1} as {prop_1}, COUNT(n) AS count, min(n.{prop_2}) AS min({prop_2}), max(n.{prop_2}) AS max({prop_2}), avg(n.{prop_2}) AS avg({prop_2}) RETURN {prop_1}, count, min({prop_2}), max({prop_2}), avg({prop_2})\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in integer_parsed:\n",
        "        for ee in integer_parsed:\n",
        "            if e[0] == ee[0]:\n",
        "                temp_dict = prompter(e[0], e[1], ee[1])\n",
        "                sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_17 = aggregate_numerical_by_integer()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_17)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_17)\n",
        "# Display an example for inspection\n",
        "sampler_17[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiIkN_Sjr5WQ",
        "outputId": "d0c5eba1-d43a-4234-c514-b953d3e2d38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 25 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the Article counts where article_id is smaller than ten, and return the maximum, minimum and average values of the article_id!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report)',\n",
              " 'Cypher': 'MATCH (n:Article) WHERE n.article_id < 10 WITH DISTINCT n WITH n.article_id as article_id, COUNT(n) AS count, min(n.article_id) AS min(article_id), max(n.article_id) AS max(article_id), avg(n.article_id) AS avg(article_id) RETURN article_id, count, min(article_id), max(article_id), avg(article_id)'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter with WHERE and WITH"
      ],
      "metadata": {
        "id": "CBlVnBcdCTWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_property_by_condition_on_node():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find the {prop_1} of {label_1} that each have more than one hundred {label_2} nodes connected via {rel_1}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m WITH n.{prop_1} AS {prop_1}, count(m) AS count WHERE {label_2} > 100 RETURN {prop_1}\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_18 = find_node_property_by_condition_on_node()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_18)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_18)\n",
        "# Display an example for inspection\n",
        "sampler_18[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aG8pEcir5TD",
        "outputId": "9ecf6246-2a58-4330-b1b8-de2b552c49bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find the abstract of Article that each have more than one hundred Keyword nodes connected via HAS_KEY!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m WITH n.abstract AS abstract, count(m) AS count WHERE Keyword > 100 RETURN abstract'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_property_with_count_limit():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Search for the {prop_1} values from 20 {label_1} that are linked to {label_2} via {rel_1} and return {prop_1} along with the respective {label_2} counts!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m RETURN n.{prop_1} AS {prop_1}, count(m) AS count LIMIT 20\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_19 = find_node_property_with_count_limit()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_19)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_19)\n",
        "# Display an example for inspection\n",
        "sampler_19[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxcVnVaZr5QE",
        "outputId": "a65bb4c7-4f3c-4833-a3b2-efe0d08bcf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Search for the abstract values from 20 Article that are linked to Keyword via HAS_KEY and return abstract along with the respective Keyword counts!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m RETURN n.abstract AS abstract, count(m) AS count LIMIT 20'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_property_with_rel():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Fetch the {prop_1} from those {label_1} that are connected to {label_2} via a {rel_1}, and return the respective counts of {label_2} together with the {prop_1}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) WITH DISTINCT n, m RETURN n.{prop_1} AS {prop_1}, count(m) AS count\"\n",
        "        }\n",
        "        return message\n",
        "    sampler=[]\n",
        "    for e in all_rels:\n",
        "        for k, v in e[1].items():\n",
        "            temp_dict = prompter(e[0], k, e[2], e[3])\n",
        "            sampler.append(temp_dict)\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_20 = find_node_property_with_rel()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_20)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_20)\n",
        "# Display an example for inspection\n",
        "sampler_20[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi4Ix6jJr7N5",
        "outputId": "4b41504a-d82f-46c2-c966-b3f2d68ec276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 200 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Fetch the abstract from those Article that are connected to Keyword via a HAS_KEY, and return the respective counts of Keyword together with the abstract!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nArticle {abstract: STRING, article_id: INTEGER, comments: STRING, title: STRING},Keyword {name: STRING, key_id: STRING}\\nRelationship properties are the following:\\nPUBLISHED_IN {meta: STRING, pages: STRING, year: INTEGER}\\nThe relationships are the following:\\n(:Article)-[:HAS_KEY]->(:Keyword),(:Article)-[:HAS_DOI]->(:DOI),(:Article)-[:HAS_CATEGORY]->(:Categories),(:Article)-[:WRITTEN_BY]->(:Author),(:Article)-[:UPDATED]->(:UpdateDate),(:Article)-[:PUBLISHED_IN]->(:Journal),(:Article)-[:HAS_REPORT]->(:Report),(:Article)-[:HAS_KEY]->(:Keyword),(:Keyword)-[:HAS_TOPIC]->(:Topic)',\n",
              " 'Cypher': 'MATCH (n:Article) -[:HAS_KEY]->(m:Keyword) WITH DISTINCT n, m RETURN n.abstract AS abstract, count(m) AS count'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Temporal functions"
      ],
      "metadata": {
        "id": "3jbY00l8H7Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_property_after_date():\n",
        "    def prompter(label_1, prop_1, prop_2):\n",
        "\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find all {prop_1} for {label_1} that have {prop_2} after January 1, 2020!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE date(n.{prop_2}) > date('2020-01-01') RETURN n.{prop_1}\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in dtypes_parsed:\n",
        "        for ee in date_parsed:\n",
        "            if e[0] == ee[0]:\n",
        "                temp_dict = prompter(e[0], e[1], ee[1])\n",
        "                sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_21 = find_property_after_date()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_21)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_21)\n",
        "# Display an example for inspection\n",
        "sampler_21[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANrO3_CBILJ8",
        "outputId": "b0fde100-78ca-4187-f153-a509d32b2617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find all update_date for UpdateDate that have update_date after January 1, 2020!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': \"MATCH (n:UpdateDate) WHERE date(n.update_date) > date('2020-01-01') RETURN n.update_date\"}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_property_in_year():\n",
        "    def prompter(label_1, prop_1, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find all {prop_1} for {label_1} that have {prop_2} in 2020!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE date(n.{prop_2}).year = 2020 RETURN n.{prop_1}\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in dtypes_parsed:\n",
        "        for ee in date_parsed:\n",
        "            if e[0] == ee[0]:\n",
        "                temp_dict = prompter(e[0], e[1], ee[1])\n",
        "                sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_22 = find_property_in_year()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_22)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_22)\n",
        "# Display an example for inspection\n",
        "sampler_22[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxcJMwOGILDs",
        "outputId": "5136f2cc-ed93-4eb4-9ad1-4b90895b35a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find all update_date for UpdateDate that have update_date in 2020!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': 'MATCH (n:UpdateDate) WHERE date(n.update_date).year = 2020 RETURN n.update_date'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_property_in_month():\n",
        "    def prompter(label_1, prop_1, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1,], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find how many {prop_1} for {label_1} have {prop_2} in June!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE date(n.{prop_2}).month = 6 RETURN count(n.{prop_1})\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in dtypes_parsed:\n",
        "        for ee in date_parsed:\n",
        "            if e[0] == ee[0]:\n",
        "                temp_dict = prompter(e[0], e[1], ee[1])\n",
        "                sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_23 = find_property_in_month()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_23)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_23)\n",
        "# Display an example for inspection\n",
        "sampler_23[12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZBN-miEIWzn",
        "outputId": "da5f38fb-e39a-4cf4-eabb-16aace090227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find how many update_date for UpdateDate have update_date in June!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': 'MATCH (n:UpdateDate) WHERE date(n.update_date).month = 6 RETURN count(n.update_date)'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count for interval\n",
        "def find_count_in_interval():\n",
        "    def prompter(label_1, prop_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"How many {label_1} have {prop_1} between January 1, 2010 and January 1, 2015?!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} >= date('2010-01-01') AND n.{prop_1} <= date('2015-01-01') RETURN count(n) AS {label_1}s\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "\n",
        "    for ee in date_parsed:\n",
        "        temp_dict = prompter(ee[0], ee[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_24 = find_count_in_interval()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_24)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_24)\n",
        "# Display an example for inspection\n",
        "sampler_24[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRw2FrETIK9t",
        "outputId": "45f77fd8-b29e-4dc4-bfab-981d275f796c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'How many UpdateDate have update_date between January 1, 2010 and January 1, 2015?!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': \"MATCH (n:UpdateDate) WHERE n.update_date >= date('2010-01-01') AND n.update_date <= date('2015-01-01') RETURN count(n) AS UpdateDates\"}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count for interval\n",
        "def find_property_after_hour():\n",
        "    def prompter(label_1, prop_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find how many {label_1}s were {prop_1} after 6PM, January 1, 2020?\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} >= datetime('2010-01-01T18:00:00') RETURN count(n) AS {label_1}s\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "\n",
        "    for ee in date_parsed:\n",
        "        temp_dict = prompter(ee[0], ee[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_25 = find_property_after_hour()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_25)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_25)\n",
        "# Display an example for inspection\n",
        "sampler_25[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z13qxQ-qIK3k",
        "outputId": "6515ba9e-adec-42f6-e70a-cb7af2f5f009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Find how many UpdateDates were update_date after 6PM, January 1, 2020?',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': \"MATCH (n:UpdateDate) WHERE n.update_date >= datetime('2010-01-01T18:00:00') RETURN count(n) AS UpdateDates\"}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count for interval\n",
        "def find_nodes_today():\n",
        "    def prompter(label_1, prop_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"List {label_1} that have {prop_1} in the last 24 hours!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1} > datetime() - duration('P1D') RETURN n\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "\n",
        "    for ee in date_parsed:\n",
        "        temp_dict = prompter(ee[0], ee[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_26 = find_nodes_today()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_26)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_26)\n",
        "# Display an example for inspection\n",
        "sampler_26[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS_DqAaWIKxt",
        "outputId": "381d91e0-3b03-4f24-fa0d-d68f5f431c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'List UpdateDate that have update_date in the last 24 hours!',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': \"MATCH (n:UpdateDate) WHERE n.update_date > datetime() - duration('P1D') RETURN n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count for interval\n",
        "def find_nodes_monday():\n",
        "    def prompter(label_1, prop_1):\n",
        "\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"How many {label_1} have {prop_1} on a Monday?\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE date(n.{prop_1}).weekday = 1 RETURN count(n)\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    datetime_parsed=[]\n",
        "    for ee in date_parsed+datetime_parsed:\n",
        "        temp_dict = prompter(ee[0], ee[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_27 = find_nodes_monday()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_27)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_27)\n",
        "# Display an example for inspection\n",
        "sampler_27[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bYPndsEIKsD",
        "outputId": "f8ccadda-7c12-4f62-8712-31ec9cbfd4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'How many UpdateDate have update_date on a Monday?',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': 'MATCH (n:UpdateDate) WHERE date(n.update_date).weekday = 1 RETURN count(n)'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count for interval\n",
        "def find_nodes_midnight():\n",
        "    def prompter(label_1, prop_1):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Which {label_1} have {prop_1} at exactly midnight?\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) WHERE n.{prop_1}.hour = 0 AND n.{prop_1}.minute=0 RETURN DISTINCT n\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    datetime_parsed=[]\n",
        "    for ee in date_parsed+datetime_parsed:\n",
        "        temp_dict = prompter(ee[0], ee[1])\n",
        "        sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_28 = find_nodes_midnight()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_28)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_28)\n",
        "# Display an example for inspection\n",
        "sampler_28[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZOTBJccIKlf",
        "outputId": "62bef12d-ccd0-4aa5-b000-578c8ce7d087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Prompt': 'Convert the following question into a Cypher query using the provided graph schema!',\n",
              " 'Question': 'Which UpdateDate have update_date at exactly midnight?',\n",
              " 'Schema': 'Graph schema: Node properties are the following:\\nUpdateDate {update_date: DATE}\\nRelationship properties are the following:\\n\\nThe relationships are the following:\\n(:Article)-[:UPDATED]->(:UpdateDate)',\n",
              " 'Cypher': 'MATCH (n:UpdateDate) WHERE n.update_date.hour = 0 AND n.update_date.minute=0 RETURN DISTINCT n'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_aggregation_date():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Find {prop_1} values for {label_1} that are connected through {rel_1} to {label_2} with {prop_2} later than January 1, 2018 and return both the {prop_1} and the count of associated {label_2}!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel}]->(m:{label_2}) WHERE m.{prop_2} > date('2018-01-01') WITH n, count(m) AS {label_2}_Count ORDER BY {label_2}_Count DESC LIMIT 1 RETURN n.{prop_1}, {label_2}_Count\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in date_parsed:\n",
        "        for er in all_rels:\n",
        "            if e[0] == er[4]:\n",
        "                for k, v in er[1].items():\n",
        "                    temp_dict = prompter(er[0], k, er[2], e[0], e[1])\n",
        "                    sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_29 = find_node_aggregation_date()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_29)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_29)\n",
        "# Display an example for inspection\n",
        "sampler_29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6q6bCwGIKfP",
        "outputId": "f187acdf-57ff-45b9-d6fe-d63ece430201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Node count by property and relation\n",
        "def find_node_aggregation_date_rels():\n",
        "    def prompter(label_1, prop_1, rel_1, label_2, prop_2):\n",
        "        subschema = get_subgraph_schema(jschema, [label_1, label_2], 2, True)\n",
        "        message = {\"Prompt\": \"Convert the following question into a Cypher query using the provided graph schema!\",\n",
        "                   \"Question\": f\"\"\"Calculate the average {prop_2} for {label_2} that are linked to {label_1} via {rel_1} and have {prop_2} date falling between January 1, 2018 and December 31, 2020!\"\"\",\n",
        "                   \"Schema\": f\"Graph schema: {subschema}\",\n",
        "                   \"Cypher\": f\"MATCH (n:{label_1}) -[:{rel_1}]->(m1:{label_2}) WHERE m1.{prop_2} < date('2020-12-31') WITH n MATCH (n) -[:{rel_1}]->(m2:{label_2}) WHERE m2.{prop_2} > date('2012-01-01') WITH n MATCH (n:{label_1}) -[:{rel_1}]->(m:{label_2}) RETURN n.{prop_1}, avg(m.{prop_2}.year) AS avg({prop_2})\"\n",
        "        }\n",
        "        return message\n",
        "\n",
        "    sampler=[]\n",
        "    for e in date_parsed:\n",
        "        for er in all_rels:\n",
        "            if e[0] == er[4]:\n",
        "                for k, v in er[1].items():\n",
        "                    temp_dict = prompter(er[0], k, er[2], e[0], e[1])\n",
        "                    sampler.append(temp_dict)\n",
        "\n",
        "    return sampler\n",
        "\n",
        "# Build the set\n",
        "sampler_30 = find_node_aggregation_date_rels()\n",
        "# Print information about the sampler set\n",
        "print(f\"There are {len(sampler_30)} queries in this subset.\")\n",
        "# Add to trainer dataset\n",
        "trainer += collect_samples(sampler_30)\n",
        "# Display an example for inspection\n",
        "sampler_30\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsL4f4tmIKZG",
        "outputId": "81607bbb-daa2-4759-e91b-7c00d9801d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 0 queries in this subset.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Saving"
      ],
      "metadata": {
        "id": "_iDiRJZ85i3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of fine-tuning pairs collected\n",
        "len(trainer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_vXOCQjIKO3",
        "outputId": "27c14ae6-25a0-4346-9f87-d0d8520e0706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1671"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save data to a file\n",
        "trainer_two = \"trainer_two.json\"\n",
        "write_json(trainer, data_path+trainer_two)"
      ],
      "metadata": {
        "id": "AOYJqhL9Odye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}