id,title,abstract
0001001,Von Neumann Quantum Logic vs. Classical von Neumann Architecture?,"  The name of John von Neumann is common both in quantum mechanics and computer
science. Are they really two absolutely unconnected areas? Many works devoted
to quantum computations and communications are serious argument to suggest
about existence of such a relation, but it is impossible to touch the new and
active theme in a short review. In the paper are described the structures and
models of linear algebra and just due to their generality it is possible to use
universal description of very different areas as quantum mechanics and theory
of Bayesian image analysis, associative memory, neural networks, fuzzy logic.
"
0001002,Minimum Description Length and Compositionality,"  We present a non-vacuous definition of compositionality. It is based on the
idea of combining the minimum description length principle with the original
definition of compositionality (that is, that the meaning of the whole is a
function of the meaning of the parts).
  The new definition is intuitive and allows us to distinguish between
compositional and non-compositional semantics, and between idiomatic and
non-idiomatic expressions. It is not ad hoc, since it does not make any
references to non-intrinsic properties of meaning functions (like being a
polynomial). Moreover, it allows us to compare different meaning functions with
respect to how compositional they are. It bridges linguistic and corpus-based,
statistical approaches to natural language understanding.
"
0001005,Effect of different packet sizes on RED performance,"  We consider the adaptation of random early detection (RED) as an active queue
management algorithm for TCP traffic in Internet gateways where different
maximum transfer units (MTUs) are used. We studied the two existing RED
variants and point out a weakness in both. The first variant where the drop
probability is independent from the packet size discriminates connections with
smaller MTUs. The second variant results in a very high Packet Loss Ratio
(PLR), and as a consequence low goodput, for connections with higher MTUs. We
show that fairness in terms of loss and goodput can be supplied through an
appropriate setting of the RED algorithm.
"
0001007,RED behavior with different packet sizes,"  We consider the adaptation of random early detection (RED) as a buffer
management algorithm for TCP traffic in Internet gateways where different
maximum transfer units (MTUs) are used. We studied the two RED variants
described in [4] and point out a weakness in both. The first variant where drop
probability is independent from the packet size discriminates connections with
smaller MTUs. The second variant results in a very high packet loss ratio
(PLR), and as a consequence low goodput, for connections with higher MTUs. We
show that fairness in terms of loss and goodput can be supplied through an
appropriate setting of the RED algorithm.
"
0001026,A Logic for SDSI's Linked Local Name Spaces,"  Abadi has introduced a logic to explicate the meaning of local names in SDSI,
the Simple Distributed Security Infrastructure proposed by Rivest and Lampson.
Abadi's logic does not correspond precisely to SDSI, however; it draws
conclusions about local names that do not follow from SDSI's name resolution
algorithm. Moreover, its semantics is somewhat unintuitive. This paper presents
the Logic of Local Name Containment, which does not suffer from these
deficiencies. It has a clear semantics and provides a tight characterization of
SDSI name resolution. The semantics is shown to be closely related to that of
logic programs, leading to an approach to the efficient implementation of
queries concerning local names. A complete axiomatization of the logic is also
provided.
"
0002006,Multiplicative Nonholonomic/Newton -like Algorithm,"  We construct new algorithms from scratch, which use the fourth order cumulant
of stochastic variables for the cost function. The multiplicative updating rule
here constructed is natural from the homogeneous nature of the Lie group and
has numerous merits for the rigorous treatment of the dynamics. As one
consequence, the second order convergence is shown. For the cost function,
functions invariant under the componentwise scaling are choosen. By identifying
points which can be transformed to each other by the scaling, we assume that
the dynamics is in a coset space. In our method, a point can move toward any
direction in this coset. Thus, no prewhitening is required.
"
0002007,Requirements of Text Processing Lexicons,"  As text processing systems expand in scope, they will require ever larger
lexicons along with a parsing capability for discriminating among many senses
of a word. Existing systems do not incorporate such subtleties in meaning for
their lexicons. Ordinary dictionaries contain such information, but are largely
untapped. When the contents of dictionaries are scrutinized, they reveal many
requirements that must be satisfied in representing meaning and in developing
semantic parsers. These requirements were identified in research designed to
find primitive verb concepts. The requirements are outlined and general
procedures for satisfying them through the use of ordinary dictionaries are
described, illustrated by building frames for and examining the definitions of
""change"" and its uses as a hypernym in other definitions.
"
0002014,Safe cooperative robot dynamics on graphs,"  This paper initiates the use of vector fields to design, optimize, and
implement reactive schedules for safe cooperative robot patterns on planar
graphs. We consider Automated Guided Vehicles (AGV's) operating upon a
predefined network of pathways. In contrast to the case of locally Euclidean
configuration spaces, regularization of collisions is no longer a local
procedure, and issues concerning the global topology of configuration spaces
must be addressed. The focus of the present inquiry is the achievement of safe,
efficient, cooperative patterns in the simplest nontrivial example (a pair of
robots on a Y-network) by means of a state-event heirarchical controller.
"
0003003,Prospects for in-depth story understanding by computer,"  While much research on the hard problem of in-depth story understanding by
computer was performed starting in the 1970s, interest shifted in the 1990s to
information extraction and word sense disambiguation. Now that a degree of
success has been achieved on these easier problems, I propose it is time to
return to in-depth story understanding. In this paper I examine the shift away
from story understanding, discuss some of the major problems in building a
story understanding system, present some possible solutions involving a set of
interacting understanding agents, and provide pointers to useful tools and
resources for building story understanding systems.
"
0003009,Conditional indifference and conditional preservation,"  The idea of preserving conditional beliefs emerged recently as a new paradigm
apt to guide the revision of epistemic states. Conditionals are substantially
different from propositional beliefs and need specific treatment. In this
paper, we present a new approach to conditionals, capturing particularly well
their dynamic part as revision policies. We thoroughly axiomatize a principle
of conditional preservation as an indifference property with respect to
conditional structures of worlds. This principle is developed in a
semi-quantitative setting, so as to reveal its fundamental meaning for belief
revision in quantitative as well as in qualitative frameworks. In fact, it is
shown to cover other proposed approaches to conditional preservation.
"
0003013,A flexible framework for defeasible logics,"  Logics for knowledge representation suffer from over-specialization: while
each logic may provide an ideal representation formalism for some problems, it
is less than optimal for others. A solution to this problem is to choose from
several logics and, when necessary, combine the representations. In general,
such an approach results in a very difficult problem of combination. However,
if we can choose the logics from a uniform framework then the problem of
combining them is greatly simplified. In this paper, we develop such a
framework for defeasible logics. It supports all defeasible logics that satisfy
a strong negation principle. We use logic meta-programs as the basis for the
framework.
"
0003015,On the semantics of merging,"  Intelligent agents are often faced with the problem of trying to merge
possibly conflicting pieces of information obtained from different sources into
a consistent view of the world. We propose a framework for the modelling of
such merging operations with roots in the work of Spohn (1988, 1991). Unlike
most approaches we focus on the merging of epistemic states, not knowledge
bases. We construct a number of plausible merging operations and measure them
against various properties that merging operations ought to satisfy. Finally,
we discuss the connection between merging and the use of infobases Meyer (1999)
and Meyer et al. (2000).
"
0003016,"Abductive and Consistency-Based Diagnosis Revisited: a Modeling
  Perspective","  Diagnostic reasoning has been characterized logically as consistency-based
reasoning or abductive reasoning. Previous analyses in the literature have
shown, on the one hand, that choosing the (in general more restrictive)
abductive definition may be appropriate or not, depending on the content of the
knowledge base [Console&Torasso91], and, on the other hand, that, depending on
the choice of the definition the same knowledge should be expressed in
different form [Poole94].
  Since in Model-Based Diagnosis a major problem is finding the right way of
abstracting the behavior of the system to be modeled, this paper discusses the
relation between modeling, and in particular abstraction in the model, and the
notion of diagnosis.
"
0003024,A Compiler for Ordered Logic Programs,"  This paper describes a system, called PLP, for compiling ordered logic
programs into standard logic programs under the answer set semantics. In an
ordered logic program, rules are named by unique terms, and preferences among
rules are given by a set of dedicated atoms. An ordered logic program is
transformed into a second, regular, extended logic program wherein the
preferences are respected, in that the answer sets obtained in the transformed
theory correspond with the preferred answer sets of the original theory. Since
the result of the translation is an extended logic program, existing logic
programming systems can be used as underlying reasoning engine. In particular,
PLP is conceived as a front-end to the logic programming systems dlv and
smodels.
"
0003026,"A Comparison of Logic Programming Approaches for Representation and
  Solving of Constraint Satisfaction Problems","  Many logic programming based approaches can be used to describe and solve
combinatorial search problems. On the one hand there are definite programs and
constraint logic programs that compute a solution as an answer substitution to
a query containing the variables of the constraint satisfaction problem. On the
other hand there are approaches based on stable model semantics, abduction, and
first-order logic model generation that compute solutions as models of some
theory. This paper compares these different approaches from point of view of
knowledge representation (how declarative are the programs) and from point of
view of performance (how good are they at solving typical problems).
"
0003056,A note on the Declarative reading(s) of Logic Programming,"  This paper analyses the declarative readings of logic programming. Logic
programming - and negation as failure - has no unique declarative reading. One
common view is that logic programming is a logic for default reasoning, a
sub-formalism of default logic or autoepistemic logic. In this view, negation
as failure is a modal operator. In an alternative view, a logic program is
interpreted as a definition. In this view, negation as failure is classical
objective negation. From a commonsense point of view, there is definitely a
difference between these views. Surprisingly though, both types of declarative
readings lead to grosso modo the same model semantics. This note investigates
the causes for this.
"
0003069,Proving Failure of Queries for Definite Logic Programs Using XSB-Prolog,"  Proving failure of queries for definite logic programs can be done by
constructing a finite model of the program in which the query is false. A
general purpose model generator for first order logic can be used for this. A
recent paper presented at PLILP98 shows how the peculiarities of definite
programs can be exploited to obtain a better solution. There a procedure is
described which combines abduction with tabulation and uses a meta-interpreter
for heuristic control of the search. The current paper shows how similar
results can be obtained by direct execution under the standard tabulation of
the XSB-Prolog system. The loss of control is compensated for by better
intelligent backtracking and more accurate failure analysis.
"
0003075,On the theory of system administration,"  This paper describes necessary elements for constructing theoretical models
of network and system administration. Armed with a theoretical model it becomes
possible to determine best practices and optimal strategies in a way which
objectively relates policies and assumptions to results obtained. It is
concluded that a mixture of automation and human, or other intelligent
incursion is required to fully implement system policy with current technology.
Some aspects of the author's immunity model for automated system administration
are explained, as an example. A theoretical framework makes the prediction that
the optimal balance between resource availability and garbage collection
strategies is encompassed by the immunity model.
"
0003081,Variable Word Rate N-grams,"  The rate of occurrence of words is not uniform but varies from document to
document. Despite this observation, parameters for conventional n-gram language
models are usually derived using the assumption of a constant word rate. In
this paper we investigate the use of variable word rate assumption, modelled by
a Poisson distribution or a continuous mixture of Poissons. We present an
approach to estimating the relative frequencies of words or n-grams taking
prior information of their occurrences into account. Discounting and smoothing
schemes are also considered. Using the Broadcast News task, the approach
demonstrates a reduction of perplexity up to 10%.
"
0003084,Information Extraction from Broadcast News,"  This paper discusses the development of trainable statistical models for
extracting content from television and radio news broadcasts. In particular we
concentrate on statistical finite state models for identifying proper names and
other named entities in broadcast speech. Two models are presented: the first
represents name class information as a word attribute; the second represents
both word-word and class-class transitions explicitly. A common n-gram based
formulation is used for both models. The task of named entity identification is
characterized by relatively sparse training data and issues related to
smoothing are discussed. Experiments are reported using the DARPA/NIST Hub-4E
evaluation for North American Broadcast News.
"
0004015,"Introduction to the GiNaC Framework for Symbolic Computation within the
  C++ Programming Language","  The traditional split-up into a low level language and a high level language
in the design of computer algebra systems may become obsolete with the advent
of more versatile computer languages. We describe GiNaC, a special-purpose
system that deliberately denies the need for such a distinction. It is entirely
written in C++ and the user can interact with it directly in that language. It
was designed to provide efficient handling of multivariate polynomials,
algebras and special functions that are needed for loop calculations in
theoretical quantum field theory. It also bears some potential to become a more
general purpose symbolic package.
"
0004016,Looking at discourse in a corpus: The role of lexical cohesion,"  This paper is aimed at reporting on the development and application of a
computer model for discourse analysis through segmentation. Segmentation refers
to the principled division of texts into contiguous constituents. Other studies
have looked at the application of a number of models to the analysis of
discourse by computer. The segmentation procedure developed for the present
investigation is called LSM ('Link Set Median'). It was applied to three corpus
of 300 texts from three different genres. The results obtained by application
of the LSM procedure on the corpus were then compared to segmentation carried
out at random. Statistical analyses suggested that LSM significantly
outperformed random segmentation, thus indicating that the segmentation was
meaningful.
"
0005002,"Application Software, Domain-Specific Languages, and Language Design
  Assistants","  While application software does the real work, domain-specific languages
(DSLs) are tools to help produce it efficiently, and language design assistants
in turn are meta-tools to help produce DSLs quickly. DSLs are already in wide
use (HTML for web pages, Excel macros for spreadsheet applications, VHDL for
hardware design, ...), but many more will be needed for both new as well as
existing application domains. Language design assistants to help develop them
currently exist only in the basic form of language development systems. After a
quick look at domain-specific languages, and especially their relationship to
application libraries, we survey existing language development systems and give
an outline of future language design assistants.
"
0005009,PSPACE Reasoning for Graded Modal Logics,"  We present a PSPACE algorithm that decides satisfiability of the graded modal
logic Gr(K_R)---a natural extension of propositional modal logic K_R by
counting expressions---which plays an important role in the area of knowledge
representation. The algorithm employs a tableaux approach and is the first
known algorithm which meets the lower bound for the complexity of the problem.
Thus, we exactly fix the complexity of the problem and refute an
ExpTime-hardness conjecture. We extend the results to the logic Gr(K_(R \cap
I)), which augments Gr(K_R) with inverse relations and intersection of
accessibility relations. This establishes a kind of ``theoretical benchmark''
that all algorithmic approaches can be measured against.
"
0005023,"C++ programming language for an abstract massively parallel SIMD
  architecture","  The aim of this work is to define and implement an extended C++ language to
support the SIMD programming paradigm. The C++ programming language has been
extended to express all the potentiality of an abstract SIMD machine consisting
of a central Control Processor and a N-dimensional toroidal array of Numeric
Processors. Very few extensions have been added to the standard C++ with the
goal of minimising the effort for the programmer in learning a new language and
to keep very high the performance of the compiled code. The proposed language
has been implemented as a porting of the GNU C++ Compiler on a SIMD
supercomputer.
"
0005030,Axiomatizing Causal Reasoning,"  Causal models defined in terms of a collection of equations, as defined by
Pearl, are axiomatized here. Axiomatizations are provided for three
successively more general classes of causal models: (1) the class of recursive
theories (those without feedback), (2) the class of theories where the
solutions to the equations are unique, (3) arbitrary theories (where the
equations may not have solutions and, if they do, they are not necessarily
unique). It is shown that to reason about causality in the most general third
class, we must extend the language used by Galles and Pearl. In addition, the
complexity of the decision procedures is characterized for all the languages
and classes of models considered.
"
0006007,Novelty Detection on a Mobile Robot Using Habituation,"  In this paper a novelty filter is introduced which allows a robot operating
in an un structured environment to produce a self-organised model of its
surroundings and to detect deviations from the learned model. The environment
is perceived using the rob ot's 16 sonar sensors. The algorithm produces a
novelty measure for each sensor scan relative to the model it has learned. This
means that it highlights stimuli which h ave not been previously experienced.
The novelty filter proposed uses a model of hab ituation. Habituation is a
decrement in behavioural response when a stimulus is pre sented repeatedly.
Robot experiments are presented which demonstrate the reliable o peration of
the filter in a number of environments.
"
0006032,Estimation of English and non-English Language Use on the WWW,"  The World Wide Web has grown so big, in such an anarchic fashion, that it is
difficult to describe. One of the evident intrinsic characteristics of the
World Wide Web is its multilinguality. Here, we present a technique for
estimating the size of a language-specific corpus given the frequency of
commonly occurring words in the corpus. We apply this technique to estimating
the number of words available through Web browsers for given languages.
Comparing data from 1996 to data from 1999 and 2000, we calculate the growth of
a number of European languages on the Web. As expected, non-English languages
are growing at a faster pace than English, though the position of English is
still dominant.
"
0006034,Type Classes and Constraint Handling Rules,"  Type classes are an elegant extension to traditional, Hindley-Milner based
typing systems. They are used in modern, typed languages such as Haskell to
support controlled overloading of symbols. Haskell 98 supports only
single-parameter and constructor type classes. Other extensions such as
multi-parameter type classes are highly desired but are still not officially
supported by Haskell. Subtle issues arise with extensions, which may lead to a
loss of feasible type inference or ambiguous programs. A proper logical basis
for type class systems seems to be missing. Such a basis would allow extensions
to be characterised and studied rigorously. We propose to employ Constraint
Handling Rules as a tool to study and develop type class systems in a uniform
way.
"
0007006,DISCO: An object-oriented system for music composition and sound design,"  This paper describes an object-oriented approach to music composition and
sound design. The approach unifies the processes of music making and instrument
building by using similar logic, objects, and procedures. The composition
modules use an abstract representation of musical data, which can be easily
mapped onto different synthesis languages or a traditionally notated score. An
abstract base class is used to derive classes on different time scales. Objects
can be related to act across time scales, as well as across an entire piece,
and relationships between similar objects can replicate traditional music
operations or introduce new ones. The DISCO (Digital Instrument for
Sonification and Composition) system is an open-ended work in progress.
"
0007010,Boosting Applied to Word Sense Disambiguation,"  In this paper Schapire and Singer's AdaBoost.MH boosting algorithm is applied
to the Word Sense Disambiguation (WSD) problem. Initial experiments on a set of
15 selected polysemous words show that the boosting approach surpasses Naive
Bayes and Exemplar-based approaches, which represent state-of-the-art accuracy
on supervised WSD. In order to make boosting practical for a real learning
domain of thousands of words, several ways of accelerating the algorithm by
reducing the feature space are studied. The best variant, which we call
LazyBoosting, is tested on the largest sense-tagged corpus available containing
192,800 examples of the 191 most frequent and ambiguous English words. Again,
boosting compares favourably to the other benchmark algorithms.
"
0007020,Polynomial-time Computation via Local Inference Relations,"  We consider the concept of a local set of inference rules. A local rule set
can be automatically transformed into a rule set for which bottom-up evaluation
terminates in polynomial time. The local-rule-set transformation gives
polynomial-time evaluation strategies for a large variety of rule sets that
cannot be given terminating evaluation strategies by any other known automatic
technique. This paper discusses three new results. First, it is shown that
every polynomial-time predicate can be defined by an (unstratified) local rule
set. Second, a new machine-recognizable subclass of the local rule sets is
identified. Finally we show that locality, as a property of rule sets, is
undecidable in general.
"
0007036,"Language identification of controlled systems: Modelling, control and
  anomaly detection","  Formal language techniques have been used in the past to study autonomous
dynamical systems. However, for controlled systems, new features are needed to
distinguish between information generated by the system and input control. We
show how the modelling framework for controlled dynamical systems leads
naturally to a formulation in terms of context-dependent grammars. A learning
algorithm is proposed for on-line generation of the grammar productions, this
formulation being then used for modelling, control and anomaly detection.
Practical applications are described for electromechanical drives. Grammatical
interpolation techniques yield accurate results and the pattern detection
capabilities of the language-based formulation makes it a promising technique
for the early detection of anomalies or faulty behaviour.
"
0007039,Ordering-based Representations of Rational Inference,"  Rational inference relations were introduced by Lehmann and Magidor as the
ideal systems for drawing conclusions from a conditional base. However, there
has been no simple characterization of these relations, other than its original
representation by preferential models. In this paper, we shall characterize
them with a class of total preorders of formulas by improving and extending
Gardenfors and Makinson's results for expectation inference relations. A second
representation is application-oriented and is obtained by considering a class
of consequence operators that grade sets of defaults according to our reliance
on them. The finitary fragment of this class of consequence operators has been
employed by recent default logic formalisms based on maxiconsistency.
"
0008004,Comparing two trainable grammatical relations finders,"  Grammatical relationships (GRs) form an important level of natural language
processing, but different sets of GRs are useful for different purposes.
Therefore, one may often only have time to obtain a small training corpus with
the desired GR annotations. On such a small training corpus, we compare two
systems. They use different learning techniques, but we find that this
difference by itself only has a minor effect. A larger factor is that in
English, a different GR length measure appears better suited for finding simple
argument GRs than for finding modifier GRs. We also find that partitioning the
data may help memory-based learning.
"
0008006,Algorithms for Analysing Firewall and Router Access Lists,"  Network firewalls and routers use a rule database to decide which packets
will be allowed from one network onto another. By filtering packets the
firewalls and routers can improve security and performance. However, as the
size of the rule list increases, it becomes difficult to maintain and validate
the rules, and lookup latency may increase significantly. Ordered binary
decision diagrams (BDDs) - a compact method of representing and manipulating
boolean expressions - are a potential method of representing the rules. This
paper presents a new algorithm for representing such lists as a BDD and then
shows how the resulting boolean expression can be used to analyse rule sets.
"
0008007,Tagger Evaluation Given Hierarchical Tag Sets,"  We present methods for evaluating human and automatic taggers that extend
current practice in three ways. First, we show how to evaluate taggers that
assign multiple tags to each test instance, even if they do not assign
probabilities. Second, we show how to accommodate a common property of manually
constructed ``gold standards'' that are typically used for objective
evaluation, namely that there is often more than one correct answer. Third, we
show how to measure performance when the set of possible tags is
tree-structured in an IS-A hierarchy. To illustrate how our methods can be used
to measure inter-annotator agreement, we show how to compute the kappa
coefficient over hierarchical tag sets.
"
0008015,Temiar Reduplication in One-Level Prosodic Morphology,"  Temiar reduplication is a difficult piece of prosodic morphology. This paper
presents the first computational analysis of Temiar reduplication, using the
novel finite-state approach of One-Level Prosodic Morphology originally
developed by Walther (1999b, 2000). After reviewing both the data and the basic
tenets of One-level Prosodic Morphology, the analysis is laid out in some
detail, using the notation of the FSA Utilities finite-state toolkit (van Noord
1997). One important discovery is that in this approach one can easily define a
regular expression operator which ambiguously scans a string in the left- or
rightward direction for a certain prosodic property. This yields an elegant
account of base-length-dependent triggering of reduplication as found in
Temiar.
"
0008016,Processing Self Corrections in a speech to speech system,"  Speech repairs occur often in spontaneous spoken dialogues. The ability to
detect and correct those repairs is necessary for any spoken language system.
We present a framework to detect and correct speech repairs where all relevant
levels of information, i.e., acoustics, lexis, syntax and semantics can be
integrated. The basic idea is to reduce the search space for repairs as soon as
possible by cascading filters that involve more and more features. At first an
acoustic module generates hypotheses about the existence of a repair. Second a
stochastic model suggests a correction for every hypothesis. Well scored
corrections are inserted as new paths in the word lattice. Finally a lattice
parser decides on accepting the rep air.
"
0008020,"Explaining away ambiguity: Learning verb selectional preference with
  Bayesian networks","  This paper presents a Bayesian model for unsupervised learning of verb
selectional preferences. For each verb the model creates a Bayesian network
whose architecture is determined by the lexical hierarchy of Wordnet and whose
parameters are estimated from a list of verb-object pairs found from a corpus.
``Explaining away'', a well-known property of Bayesian networks, helps the
model deal in a natural fashion with word sense ambiguity in the training data.
On a word sense disambiguation test our model performed better than other state
of the art systems for unsupervised learning of selectional preferences.
Computational complexity problems, ways of improving this approach and methods
for implementing ``explaining away'' in other graphical frameworks are
discussed.
"
0008026,"Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon
  construction","  Generating semantic lexicons semi-automatically could be a great time saver,
relative to creating them by hand. In this paper, we present an algorithm for
extracting potential entries for a category from an on-line corpus, based upon
a small set of exemplars. Our algorithm finds more correct terms and fewer
incorrect ones than previous work in this area. Additionally, the entries that
are generated potentially provide broader coverage of the category than would
occur to an individual coding them by hand. Our algorithm finds many terms not
included within Wordnet (many more than previous algorithms), and could be
viewed as an ``enhancer'' of existing broad-coverage resources.
"
0009004,A usage based analysis of CoRR,"  Based on an empirical analysis of author usage of CoRR, and of its
predecessor in the Los Alamos eprint archives, it is shown that CoRR has not
yet been able to match the early growth of the Los Alamos physics archives.
Some of the reasons are implicit in Halpern's paper, and we explore them
further here. In particular we refer to the need to promote CoRR more
effectively for its intended community - computer scientists in universities,
industrial research labs and in government. We take up some points of detail on
this new world of open archiving concerning central versus distributed
self-archiving, publication, the restructuring of the journal publishers'
niche, peer review and copyright.
"
0009011,"Anaphora Resolution in Japanese Sentences Using Surface Expressions and
  Examples","  Anaphora resolution is one of the major problems in natural language
processing. It is also one of the important tasks in machine translation and
man/machine dialogue. We solve the problem by using surface expressions and
examples. Surface expressions are the words in sentences which provide clues
for anaphora resolution. Examples are linguistic data which are actually used
in conversations and texts. The method using surface expressions and examples
is a practical method. This thesis handles almost all kinds of anaphora: i. The
referential property and number of a noun phrase ii. Noun phrase direct
anaphora iii. Noun phrase indirect anaphora iv. Pronoun anaphora v. Verb phrase
ellipsis
"
0009014,Combining Linguistic and Spatial Information for Document Analysis,"  We present a framework to analyze color documents of complex layout. In
addition, no assumption is made on the layout. Our framework combines in a
content-driven bottom-up approach two different sources of information: textual
and spatial. To analyze the text, shallow natural language processing tools,
such as taggers and partial parsers, are used. To infer relations of the
logical layout we resort to a qualitative spatial calculus closely related to
Allen's calculus. We evaluate the system against documents from a color journal
and present the results of extracting the reading order from the journal's
pages. In this case, our analysis is successful as it extracts the intended
reading order from the document.
"
0009016,Contextual Inference in Computational Semantics,"  In this paper, an application of automated theorem proving techniques to
computational semantics is considered. In order to compute the presuppositions
of a natural language discourse, several inference tasks arise. Instead of
treating these inferences independently of each other, we show how integrating
techniques from formal approaches to context into deduction can help to compute
presuppositions more efficiently. Contexts are represented as Discourse
Representation Structures and the way they are nested is made explicit. In
addition, a tableau calculus is present which keeps track of contextual
information, and thereby allows to avoid carrying out redundant inference steps
as it happens in approaches that neglect explicit nesting of contexts.
"
0009020,Cluster Computing: A High-Performance Contender,"  When you first heard people speak of Piles of PCs, the first thing that came
to mind may have been a cluttered computer room with processors, monitors, and
snarls of cables all around. Collections of computers have undoubtedly become
more sophisticated than in the early days of shared drives and modem
connections. No matter what you call them, Clusters of Workstations (COW),
Networks of Workstations (NOW), Workstation Clusters (WCs), Clusters of PCs
(CoPs), clusters of computers are now filling the processing niche once
occupied by more powerful stand-alone machines. This article discusses the need
for cluster computing technology, Technologies, Components, and Applications,
Supercluster Systems and Issues, The Need for a New Task Force, and Cluster
Computing Educational Resources.
"
0009025,Parsing with the Shortest Derivation,"  Common wisdom has it that the bias of stochastic grammars in favor of shorter
derivations of a sentence is harmful and should be redressed. We show that the
common wisdom is wrong for stochastic grammars that use elementary trees
instead of context-free rules, such as Stochastic Tree-Substitution Grammars
used by Data-Oriented Parsing models. For such grammars a non-probabilistic
metric based on the shortest derivation outperforms a probabilistic metric on
the ATIS and OVIS corpora, while it obtains very competitive results on the
Wall Street Journal corpus. This paper also contains the first published
experiments with DOP on the Wall Street Journal.
"
0010002,Noise Effects in Fuzzy Modelling Systems,"  Noise is source of ambiguity for fuzzy systems. Although being an important
aspect, the effects of noise in fuzzy modeling have been little investigated.
This paper presents a set of tests using three well-known fuzzy modeling
algorithms. These evaluate perturbations in the extracted rule-bases caused by
noise polluting the learning data, and the corresponding deformations in each
learned functional relation. We present results to show: 1) how these fuzzy
modeling systems deal with noise; 2) how the established fuzzy model structure
influences noise sensitivity of each algorithm; and 3) whose characteristics of
the learning algorithms are relevant to noise attenuation.
"
0010003,"Torque Ripple Minimization in a Switched Reluctance Drive by Neuro-Fuzzy
  Compensation","  Simple power electronic drive circuit and fault tolerance of converter are
specific advantages of SRM drives, but excessive torque ripple has limited its
use to special applications. It is well known that controlling the current
shape adequately can minimize the torque ripple. This paper presents a new
method for shaping the motor currents to minimize the torque ripple, using a
neuro-fuzzy compensator. In the proposed method, a compensating signal is added
to the output of a PI controller, in a current-regulated speed control loop.
Numerical results are presented in this paper, with an analysis of the effects
of changing the form of the membership function of the neuro-fuzzy compensator.
"
0010015,"On Exponential-Time Completeness of the Circularity Problem for
  Attribute Grammars","  Attribute grammars (AGs) are a formal technique for defining semantics of
programming languages. Existing complexity proofs on the circularity problem of
AGs are based on automata theory, such as writing pushdown acceptor and
alternating Turing machines. They reduced the acceptance problems of above
automata, which are exponential-time (EXPTIME) complete, to the AG circularity
problem. These proofs thus show that the circularity problem is EXPTIME-hard,
at least as hard as the most difficult problems in EXPTIME. However, none has
given a proof for the EXPTIME-completeness of the problem. This paper first
presents an alternating Turing machine for the circularity problem. The
alternating Turing machine requires polynomial space. Thus, the circularity
problem is in EXPTIME and is then EXPTIME-complete.
"
0010016,Towards rule-based visual programming of generic visual systems,"  This paper illustrates how the diagram programming language DiaPlan can be
used to program visual systems. DiaPlan is a visual rule-based language that is
founded on the computational model of graph transformation. The language
supports object-oriented programming since its graphs are hierarchically
structured. Typing allows the shape of these graphs to be specified recursively
in order to increase program security. Thanks to its genericity, DiaPlan allows
to implement systems that represent and manipulate data in arbitrary diagram
notations. The environment for the language exploits the diagram editor
generator DiaGen for providing genericity, and for implementing its user
interface and type checker.
"
0010019,"The Random Oracle Methodology, Revisited","  We take a critical look at the relationship between the security of
cryptographic schemes in the Random Oracle Model, and the security of the
schemes that result from implementing the random oracle by so called
""cryptographic hash functions"". The main result of this paper is a negative
one: There exist signature and encryption schemes that are secure in the Random
Oracle Model, but for which any implementation of the random oracle results in
insecure schemes.
  In the process of devising the above schemes, we consider possible
definitions for the notion of a ""good implementation"" of a random oracle,
pointing out limitations and challenges.
"
0010026,Enriching very large ontologies using the WWW,"  This paper explores the possibility to exploit text on the world wide web in
order to enrich the concepts in existing ontologies. First, a method to
retrieve documents from the WWW related to a concept is described. These
document collections are used 1) to construct topic signatures (lists of
topically related words) for each concept in WordNet, and 2) to build
hierarchical clusters of the concepts (the word senses) that lexicalize a given
word. The overall goal is to overcome two shortcomings of WordNet: the lack of
topical links among concepts, and the proliferation of senses. Topic signatures
are validated on a word sense disambiguation task with good results, which are
improved when the hierarchical clusters are used.
"
0010027,One Sense per Collocation and Genre/Topic Variations,"  This paper revisits the one sense per collocation hypothesis using
fine-grained sense distinctions and two different corpora. We show that the
hypothesis is weaker for fine-grained sense distinctions (70% vs. 99% reported
earlier on 2-way ambiguities). We also show that one sense per collocation does
hold across corpora, but that collocations vary from one corpus to the other,
following genre and topic variations. This explains the low results when
performing word sense disambiguation across corpora. In fact, we demonstrate
that when two independent corpora share a related genre/topic, the word sense
disambiguation results would be better. Future work on word sense
disambiguation will have to take into account genre and topic as important
parameters on their models.
"
0010029,"Using Modes to Ensure Subject Reduction for Typed Logic Programs with
  Subtyping","  We consider a general prescriptive type system with parametric polymorphism
and subtyping for logic programs. The property of subject reduction expresses
the consistency of the type system w.r.t. the execution model: if a program is
""well-typed"", then all derivations starting in a ""well-typed"" goal are again
""well-typed"". It is well-established that without subtyping, this property is
readily obtained for logic programs w.r.t. their standard (untyped) execution
model. Here we give syntactic conditions that ensure subject reduction also in
the presence of general subtyping relations between type constructors. The idea
is to consider logic programs with a fixed dataflow, given by modes.
"
0011003,"Applying Machine Translation to Two-Stage Cross-Language Information
  Retrieval","  Cross-language information retrieval (CLIR), where queries and documents are
in different languages, needs a translation of queries and/or documents, so as
to standardize both of them into a common representation. For this purpose, the
use of machine translation is an effective approach. However, computational
cost is prohibitive in translating large-scale document collections. To resolve
this problem, we propose a two-stage CLIR method. First, we translate a given
query into the document language, and retrieve a limited number of foreign
documents. Second, we machine translate only those documents into the user
language, and re-rank them based on the translation result. We also show the
effectiveness of our method by way of experiments using Japanese queries and
English technical documents.
"
0011008,"A Lambda-Calculus with letrec, case, constructors and non-determinism","  A non-deterministic call-by-need lambda-calculus \calc with case,
constructors, letrec and a (non-deterministic) erratic choice, based on
rewriting rules is investigated. A standard reduction is defined as a variant
of left-most outermost reduction. The semantics is defined by contextual
equivalence of expressions instead of using $\alpha\beta(\eta)$-equivalence. It
is shown that several program transformations are correct, for example all
(deterministic) rules of the calculus, and in addition the rules for garbage
collection, removing indirections and unique copy.
  This shows that the combination of a context lemma and a meta-rewriting on
reductions using complete sets of commuting (forking, resp.) diagrams is a
useful and successful method for providing a semantics of a functional
programming language and proving correctness of program transformations.
"
0011016,Designing Proxies for Stock Market Indices is Computationally Hard,"  In this paper, we study the problem of designing proxies (or portfolios) for
various stock market indices based on historical data. We use four different
methods for computing market indices, all of which are formulas used in actual
stock market analysis. For each index, we consider three criteria for designing
the proxy: the proxy must either track the market index, outperform the market
index, or perform within a margin of error of the index while maintaining a low
volatility. In eleven of the twelve cases (all combinations of four indices
with three criteria except the problem of sacrificing return for less
volatility using the price-relative index) we show that the problem is NP-hard,
and hence most likely intractable.
"
0011030,"Logic Programming Approaches for Representing and Solving Constraint
  Satisfaction Problems: A Comparison","  Many logic programming based approaches can be used to describe and solve
combinatorial search problems. On the one hand there is constraint logic
programming which computes a solution as an answer substitution to a query
containing the variables of the constraint satisfaction problem. On the other
hand there are systems based on stable model semantics, abductive systems, and
first order logic model generators which compute solutions as models of some
theory. This paper compares these different approaches from the point of view
of knowledge representation (how declarative are the programs) and from the
point of view of performance (how good are they at solving typical problems).
"
0011034,Semantic interpretation of temporal information by abductive inference,"  Besides temporal information explicitly available in verbs and adjuncts, the
temporal interpretation of a text also depends on general world knowledge and
default assumptions. We will present a theory for describing the relation
between, on the one hand, verbs, their tenses and adjuncts and, on the other,
the eventualities and periods of time they represent and their relative
temporal locations.
  The theory is formulated in logic and is a practical implementation of the
concepts described in Ness Schelkens et al. We will show how an abductive
resolution procedure can be used on this representation to extract temporal
information from texts.
"
0011041,EquiX---A Search and Query Language for XML,"  EquiX is a search language for XML that combines the power of querying with
the simplicity of searching. Requirements for such languages are discussed and
it is shown that EquiX meets the necessary criteria. Both a graphical abstract
syntax and a formal concrete syntax are presented for EquiX queries. In
addition, the semantics is defined and an evaluation algorithm is presented.
The evaluation algorithm is polynomial under combined complexity.
  EquiX combines pattern matching, quantification and logical expressions to
query both the data and meta-data of XML documents. The result of a query in
EquiX is a set of XML documents. A DTD describing the result documents is
derived automatically from the query.
"
0011042,Order-consistent programs are cautiously monotonic,"  Some normal logic programs under the answer set (stable model) semantics lack
the appealing property of ""cautious monotonicity."" That is, augmenting a
program with one of its consequences may cause it to lose another of its
consequences. The syntactic condition of ""order-consistency"" was shown by Fages
to guarantee existence of an answer set. This note establishes that
order-consistent programs are not only consistent, but cautiously monotonic.
  From this it follows that they are also ""cumulative."" That is, augmenting an
order-consistent with some of its consequences does not alter its consequences.
In fact, as we show, its answer sets remain unchanged.
"
0011046,Available Stabilizing Heaps,"  This paper describes a heap construction that supports insert and delete
operations in arbitrary (possibly illegitimate) states. After any sequence of
at most O(m) heap operations, the heap state is guarantee to be legitimate,
where m is the initial number of items in the heap. The response from each
operation is consistent with its effect on the data structure, even for
illegitimate states. The time complexity of each operation is O(lg K) where K
is the capacity of the data structure; when the heap's state is legitimate the
time complexity is O(lg n) for n equal to the number items in the heap.
"
0012003,"Questions for a Materialist Philosophy Implying the Equivalence of
  Computers and Human Cognition","  Issues related to a materialist philosophy are explored as concerns the
implied equivalence of computers running software and human observers. One
issue explored concerns the measurement process in quantum mechanics. Another
issue explored concerns the nature of experience as revealed by the existence
of dreams. Some difficulties stemming from a materialist philosophy as regards
these issues are pointed out. For example, a gedankenexperiment involving what
has been called ""negative"" observation is discussed that illustrates the
difficulty with a materialist assumption in quantum mechanics. Based on an
exploration of these difficulties, specifications are outlined briefly that
would provide a means to demonstrate the equivalence of of computers running
software and human experience given a materialist assumption.
"
0012005,Value Withdrawal Explanation in CSP,"  This work is devoted to constraint solving motivated by the debugging of
constraint logic programs a la GNU-Prolog. The paper focuses only on the
constraints. In this framework, constraint solving amounts to domain reduction.
A computation is formalized by a chaotic iteration. The computed result is
described as a closure. This model is well suited to the design of debugging
notions and tools, for example failure explanations or error diagnosis. In this
paper we detail an application of the model to an explanation of a value
withdrawal in a domain. Some other works have already shown the interest of
such a notion of explanation not only for failure analysis.
"
0012011,"Towards a Universal Theory of Artificial Intelligence based on
  Algorithmic Probability and Sequential Decision Theory","  Decision theory formally solves the problem of rational agents in uncertain
worlds if the true environmental probability distribution is known.
Solomonoff's theory of universal induction formally solves the problem of
sequence prediction for unknown distribution. We unify both theories and give
strong arguments that the resulting universal AIXI model behaves optimal in any
computable environment. The major drawback of the AIXI model is that it is
uncomputable. To overcome this problem, we construct a modified algorithm
AIXI^tl, which is still superior to any other time t and space l bounded agent.
The computation time of AIXI^tl is of the order t x 2^l.
"
0012024,Byzantine Agreement with Faulty Majority using Bounded Broadcast,"  Byzantine Agreement introduced in [Pease, Shostak, Lamport, 80] is a widely
used building block of reliable distributed protocols. It simulates broadcast
despite the presence of faulty parties within the network, traditionally using
only private unicast links. Under such conditions, Byzantine Agreement requires
more than 2/3 of the parties to be compliant. [Fitzi, Maurer, 00], constructed
a Byzantine Agreement protocol for any compliant majority based on an
additional primitive allowing transmission to any two parties simultaneously.
They proposed a problem of generalizing these results to wider channels and
fewer compliant parties. We prove that 2f < kh condition is necessary and
sufficient for implementing broadcast with h compliant and f faulty parties
using k-cast channels.
"
0101016,"A Dynamic Programming Approach to De Novo Peptide Sequencing via Tandem
  Mass Spectrometry","  The tandem mass spectrometry fragments a large number of molecules of the
same peptide sequence into charged prefix and suffix subsequences, and then
measures mass/charge ratios of these ions. The de novo peptide sequencing
problem is to reconstruct the peptide sequence from a given tandem mass
spectral data of k ions. By implicitly transforming the spectral data into an
NC-spectrum graph G=(V,E) where |V|=2k+2, we can solve this problem in
O(|V|+|E|) time and O(|V|) space using dynamic programming. Our approach can be
further used to discover a modified amino acid in O(|V||E|) time and to analyze
data with other types of noise in O(|V||E|) time. Our algorithms have been
implemented and tested on actual experimental data.
"
0101017,Checking Properties within Fairness and Behavior Abstractions,"  This paper is motivated by the fact that verifying liveness properties under
a fairness condition is often problematic, especially when abstraction is used.
It shows that using a more abstract notion than truth under fairness,
specifically the concept of a property being satisfied within fairness can lead
to interesting possibilities. Technically, it is first established that
deciding satisfaction within fairness is a PSPACE-complete problem and it is
shown that properties satisfied within fairness can always be satisfied by some
fair implementation. Thereafter, the interaction between behavior abstraction
and satisfaction within fairness is studied and it is proved that satisfaction
of properties within fairness can be verified on behavior abstractions, if the
abstraction homomorphism is weakly continuation-closed.
"
0101020,More Robust Multiparty Protocols with Oblivious Transfer,"  With oblivious transfer multiparty protocols become possible even in the
presence of a faulty majority. But all known protocols can be aborted by just
one disruptor.
  This paper presents more robust solutions for multiparty protocols with
oblivious transfer. This additional robustness against disruptors weakens the
security of the protocol and the guarantee that the result is correct. We can
observe a trade off between robustness against disruption and security and
correctness.
  We give an application to quantum multiparty protocols. These allow the
implementation of oblivious transfer and the protocols of this paper relative
to temporary assumptions, i.e., the security increases after the termination of
the protocol.
"
0101031,"Cavity Matchings, Label Compressions, and Unrooted Evolutionary Trees","  We present an algorithm for computing a maximum agreement subtree of two
unrooted evolutionary trees. It takes O(n^{1.5} log n) time for trees with
unbounded degrees, matching the best known time complexity for the rooted case.
Our algorithm allows the input trees to be mixed trees, i.e., trees that may
contain directed and undirected edges at the same time. Our algorithm adopts a
recursive strategy exploiting a technique called label compression. The
backbone of this technique is an algorithm that computes the maximum weight
matchings over many subgraphs of a bipartite graph as fast as it takes to
compute a single matching.
"
0102002,On the Automated Classification of Web Sites,"  In this paper we discuss several issues related to automated text
classification of web sites. We analyze the nature of web content and metadata
in relation to requirements for text features. We find that HTML metatags are a
good source of text features, but are not in wide use despite their role in
search engine rankings. We present an approach for targeted spidering including
metadata extraction and opportunistic crawling of specific semantic hyperlinks.
We describe a system for automatically classifying web sites into industry
categories and present performance results based on different combinations of
text features and training data. This system can serve as the basis for a
generalized framework for automated metadata creation.
"
0102006,Orderly Spanning Trees with Applications,"  We introduce and study the {\em orderly spanning trees} of plane graphs. This
algorithmic tool generalizes {\em canonical orderings}, which exist only for
triconnected plane graphs. Although not every plane graph admits an orderly
spanning tree, we provide an algorithm to compute an {\em orderly pair} for any
connected planar graph $G$, consisting of a plane graph $H$ of $G$, and an
orderly spanning tree of $H$. We also present several applications of orderly
spanning trees: (1) a new constructive proof for Schnyder's Realizer Theorem,
(2) the first area-optimal 2-visibility drawing of $G$, and (3) the best known
encodings of $G$ with O(1)-time query support. All algorithms in this paper run
in linear time.
"
0102013,"Quantum Multi-Prover Interactive Proof Systems with Limited Prior
  Entanglement","  This paper gives the first formal treatment of a quantum analogue of
multi-prover interactive proof systems. It is proved that the class of
languages having quantum multi-prover interactive proof systems is necessarily
contained in NEXP, under the assumption that provers are allowed to share at
most polynomially many prior-entangled qubits. This implies that, in
particular, if provers do not share any prior entanglement with each other, the
class of languages having quantum multi-prover interactive proof systems is
equal to NEXP. Related to these, it is shown that, in the case a prover does
not have his private qubits, the class of languages having quantum
single-prover interactive proof systems is also equal to NEXP.
"
0102020,Multi-Syllable Phonotactic Modelling,"  This paper describes a novel approach to constructing phonotactic models. The
underlying theoretical approach to phonological description is the
multisyllable approach in which multiple syllable classes are defined that
reflect phonotactically idiosyncratic syllable subcategories. A new
finite-state formalism, OFS Modelling, is used as a tool for encoding,
automatically constructing and generalising phonotactic descriptions.
Language-independent prototype models are constructed which are instantiated on
the basis of data sets of phonological strings, and generalised with a
clustering algorithm. The resulting approach enables the automatic construction
of phonotactic models that encode arbitrarily close approximations of a
language's set of attested phonological forms. The approach is applied to the
construction of multi-syllable word-level phonotactic models for German,
English and Dutch.
"
0102028,Communities of Practice: Going Virtual,"  With the current trends towards downsizing, outsourcing and globalisation,
modern organisations are reducing the numbers of people they employ. In
addition, organisations now have to cope with the increasing
internationalisation of business forcing collaboration and knowledge sharing
across time and distance simultaneously. There is a need for new ways of
thinking about how knowledge is shared in distributed groups. In this paper we
explore a relatively new approach to knowledge sharing using Lave and Wenger's
(1991) theory of Communities of Practice (CoPs). We investigate whether CoPs
might translate to a geographically distributed international environment
through a case study that explores the functioning of a CoP across national
boundaries.
"
0103004,"Rapid Application Evolution and Integration Through Document
  Metamorphosis","  The Harland document management system implements a data model in which
document (object) structure can be altered by mixin-style multiple inheritance
at any time. This kind of structural fluidity has long been supported by
knowledge-base management systems, but its use has primarily been in support of
reasoning and inference. In this paper, we report our experiences building and
supporting several non-trivial applications on top of this data model. Based on
these experiences, we argue that structural fluidity is convenient for
data-intensive applications other than knowledge-base management. Specifically,
we suggest that this flexible data model is a natural fit for the decoupled
programming methodology that arises naturally when using enterprise component
frameworks.
"
0103012,"Meaning Sort - Three examples: dictionary construction, tagged corpus
  construction, and information presentation system","  It is often useful to sort words into an order that reflects relations among
their meanings as obtained by using a thesaurus. In this paper, we introduce a
method of arranging words semantically by using several types of `{\sf is-a}'
thesauri and a multi-dimensional thesaurus. We also describe three major
applications where a meaning sort is useful and show the effectiveness of a
meaning sort. Since there is no doubt that a word list in meaning-order is
easier to use than a word list in some random order, a meaning sort, which can
easily produce a word list in meaning-order, must be useful and effective.
"
0103015,Fitness Uniform Selection to Preserve Genetic Diversity,"  In evolutionary algorithms, the fitness of a population increases with time
by mutating and recombining individuals and by a biased selection of more fit
individuals. The right selection pressure is critical in ensuring sufficient
optimization progress on the one hand and in preserving genetic diversity to be
able to escape from local optima on the other. We propose a new selection
scheme, which is uniform in the fitness values. It generates selection pressure
towards sparsely populated fitness regions, not necessarily towards higher
fitness, as is the case for all other selection schemes. We show that the new
selection scheme can be much more effective than standard selection schemes.
"
0103017,Nice point sets can have nasty Delaunay triangulations,"  We consider the complexity of Delaunay triangulations of sets of points in
R^3 under certain practical geometric constraints. The spread of a set of
points is the ratio between the longest and shortest pairwise distances. We
show that in the worst case, the Delaunay triangulation of n points in R^3 with
spread D has complexity Omega(min{D^3, nD, n^2}) and O(min{D^4, n^2}). For the
case D = Theta(sqrt{n}), our lower bound construction consists of a uniform
sample of a smooth convex surface with bounded curvature. We also construct a
family of smooth connected surfaces such that the Delaunay triangulation of any
good point sample has near-quadratic complexity.
"
0103018,"The Existential Theory of Equations with Rational Constraints in Free
  Groups is PSPACE-Complete","  It is known that the existential theory of equations in free groups is
decidable. This is a famous result of Makanin. On the other hand it has been
shown that the scheme of his algorithm is not primitive recursive. In this
paper we present an algorithm that works in polynomial space, even in the more
general setting where each variable has a rational constraint, that is, the
solution has to respect a specification given by a regular word language. Our
main result states that the existential theory of equations in free groups with
rational constraints is PSPACE-complete. We obtain this result as a corollary
of the corresponding statement about free monoids with involution.
"
0104009,Evaluating Recommendation Algorithms by Graph Analysis,"  We present a novel framework for evaluating recommendation algorithms in
terms of the `jumps' that they make to connect people to artifacts. This
approach emphasizes reachability via an algorithm within the implicit graph
structure underlying a recommender dataset, and serves as a complement to
evaluation in terms of predictive accuracy. The framework allows us to consider
questions relating algorithmic parameters to properties of the datasets. For
instance, given a particular algorithm `jump,' what is the average path length
from a person to an artifact? Or, what choices of minimum ratings and jumps
maintain a connected graph? We illustrate the approach with a common jump
called the `hammock' using movie recommender datasets.
"
0104020,"Coaxing Confidences from an Old Friend: Probabilistic Classifications
  from Transformation Rule Lists","  Transformation-based learning has been successfully employed to solve many
natural language processing problems. It has many positive features, but one
drawback is that it does not provide estimates of class membership
probabilities.
  In this paper, we present a novel method for obtaining class membership
probabilities from a transformation-based rule list classifier. Three
experiments are presented which measure the modeling accuracy and cross-entropy
of the probabilistic classifier on unseen data and the degree to which the
output probabilities from the classifier can be used to estimate confidences in
its classification decisions.
  The results of these experiments show that, for the task of text chunking,
the estimates produced by this technique are more informative than those
generated by a state-of-the-art decision tree.
"
0105011,Component Programming and Interoperability in Constraint Solver Design,"  Prolog was once the main host for implementing constraint solvers.
  It seems that it is no longer so. To be useful, constraint solvers have to be
integrable into industrial applications written in imperative or
object-oriented languages; to be efficient, they have to interact with other
solvers. To meet these requirements, many solvers are now implemented in the
form of extensible object-oriented libraries. Following Pfister and Szyperski,
we argue that ``objects are not enough,'' and we propose to design solvers as
component-oriented libraries. We illustrate our approach by the description of
the architecture of a prototype, and we assess its strong points and
weaknesses.
"
0105027,Bounds on sample size for policy evaluation in Markov environments,"  Reinforcement learning means finding the optimal course of action in
Markovian environments without knowledge of the environment's dynamics.
Stochastic optimization algorithms used in the field rely on estimates of the
value of a policy. Typically, the value of a policy is estimated from results
of simulating that very policy in the environment. This approach requires a
large amount of simulation as different points in the policy space are
considered. In this paper, we develop value estimators that utilize data
gathered when using one policy to estimate the value of using another policy,
resulting in much more data-efficient algorithms. We consider the question of
accumulating a sufficient experience and give PAC-style bounds.
"
0105033,Lectures on Reduce and Maple at UAM I - Mexico,"  These lectures give a brief introduction to the Computer Algebra systems
Reduce and Maple. The aim is to provide a systematic survey of most important
commands and concepts. In particular, this includes a discussion of
simplification schemes and the handling of simplification and substitution
rules (e.g., a Lie Algebra is implemented in Reduce by means of simplification
rules).
  Another emphasis is on the different implementations of tensor calculi and
the exterior calculus by Reduce and Maple and their application in Gravitation
theory and Differential Geometry.
  I held the lectures at the Universidad Autonoma Metropolitana-Iztapalapa,
Departamento de Fisica, Mexico, in November 1999.
"
0106001,Approximating the satisfiability threshold for random k-XOR-formulas,"  In this paper we study random linear systems with $k$ variables per equation
over the finite field GF(2), or equivalently $k$-XOR-CNF formulas. In a
previous paper Creignou and Daud\'e proved that the phase transition for the
consistency (satisfiability) of such systems (formulas) exhibits a sharp
threshold. Here we prove that the phase transition occurs as the number of
equations (clauses) is proportional to the number of variables. For any $k\ge
3$ we establish first estimates for the critical ratio. For $k=3$ we get 0.93
as an upper bound, 0.89 as a lower bound, whereas experiments suggest that the
critical ratio is approximately 0.92.
"
0106011,Computational properties of environment-based disambiguation,"  The standard pipeline approach to semantic processing, in which sentences are
morphologically and syntactically resolved to a single tree before they are
interpreted, is a poor fit for applications such as natural language
interfaces. This is because the environment information, in the form of the
objects and events in the application's run-time environment, cannot be used to
inform parsing decisions unless the input sentence is semantically analyzed,
but this does not occur until after parsing in the single-tree semantic
architecture. This paper describes the computational properties of an
alternative architecture, in which semantic analysis is performed on all
possible interpretations during parsing, in polynomial time.
"
0106014,L.T.Kuzin: Research Program,"  Lev T. Kuzin (1928--1997) is one of the founders of modern cybernetics and
information science in Russia. He was awarded and honored the USSR State Prize
for inspiring vision into the future of technical cybernetics and his invention
and innovation of key technologies.
  The last years he interested in the computational models of geometrical and
algebraic nature and their applications in various branches of computer science
and information technologies. In the recent years the interest in computation
models based on object notion has grown tremendously stimulating an interest to
Kuzin's ideas. This year of 50th Anniversary of Cybernetics and on the occasion
of his 70th birthday on September 12, 1998 seems especially appropriate for
discussing Kuzin's Research Program.
"
0106019,Playing Games with Algorithms: Algorithmic Combinatorial Game Theory,"  Combinatorial games lead to several interesting, clean problems in algorithms
and complexity theory, many of which remain open. The purpose of this paper is
to provide an overview of the area to encourage further research. In
particular, we begin with general background in Combinatorial Game Theory,
which analyzes ideal play in perfect-information games, and Constraint Logic,
which provides a framework for showing hardness. Then we survey results about
the complexity of determining ideal play in these games, and the related
problems of solving puzzles, in terms of both polynomial-time algorithms and
computational intractability results. Our review of background and survey of
algorithmic results are by no means complete, but should serve as a useful
primer.
"
0106027,Event Driven Objects,"  A formal consideration in this paper is given for the essential notations to
characterize the object that is distinguished in a problem domain. The distinct
object is represented by another idealized object, which is a schematic
element. When the existence of an element is significant, then a class of these
partial elements is dropped down into actual, potential and virtual objects.
The potential objects are gathered into the variable domains which are the
extended ranges for unbound variables. The families of actual objects are shown
to be parameterized with the types and events. The transitions between events
are shown to be driven by the scripts. A computational framework arises which
is described by the commutative diagrams.
"
0106032,Hinged Kite Mirror Dissection,"  Any two polygons of equal area can be partitioned into congruent sets of
polygonal pieces, and in many cases one can connect the pieces by flexible
hinges while still allowing the connected set to form both polygons. However it
is open whether such a hinged dissection always exists. We solve a special case
of this problem, by showing that any asymmetric polygon always has a hinged
dissection to its mirror image. Our dissection forms a chain of kite-shaped
pieces, found by a circle-packing algorithm for quadrilateral mesh generation.
A hinged mirror dissection of a polygon with n sides can be formed with O(n)
kites in O(n log n) time.
"
0106044,A Sequential Model for Multi-Class Classification,"  Many classification problems require decisions among a large number of
competing classes. These tasks, however, are not handled well by general
purpose learning methods and are usually addressed in an ad-hoc fashion. We
suggest a general approach -- a sequential learning model that utilizes
classifiers to sequentially restrict the number of competing classes while
maintaining, with high probability, the presence of the true outcome in the
candidates set. Some theoretical and computational properties of the model are
discussed and we argue that these are important in NLP-like domains. The
advantages of the model are illustrated in an experiment in part-of-speech
tagging.
"
0107031,The Complexity of Clickomania,"  We study a popular puzzle game known variously as Clickomania and Same Game.
Basically, a rectangular grid of blocks is initially colored with some number
of colors, and the player repeatedly removes a chosen connected monochromatic
group of at least two square blocks, and any blocks above it fall down. We show
that one-column puzzles can be solved, i.e., the maximum possible number of
blocks can be removed, in linear time for two colors, and in polynomial time
for an arbitrary number of colors. On the other hand, deciding whether a puzzle
is solvable (all blocks can be removed) is NP-complete for two columns and five
colors, or five columns and three colors.
"
0107034,NEOS Server 4.0 Administrative Guide,"  The NEOS Server 4.0 provides a general Internet-based client/server as a link
between users and software applications. The administrative guide covers the
fundamental principals behind the operation of the NEOS Server, installation
and trouble-shooting of the Server software, and implementation details of
potential interest to a NEOS Server administrator. The guide also discusses
making new software applications available through the Server, including areas
of concern to remote solver administrators such as maintaining security,
providing usage instructions, and enforcing reasonable restrictions on jobs.
The administrative guide is intended both as an introduction to the NEOS Server
and as a reference for use when running the Server.
"
0108002,Bounded Concurrent Timestamp Systems Using Vector Clocks,"  Shared registers are basic objects used as communication mediums in
asynchronous concurrent computation. A concurrent timestamp system is a higher
typed communication object, and has been shown to be a powerful tool to solve
many concurrency control problems. It has turned out to be possible to
construct such higher typed objects from primitive lower typed ones. The next
step is to find efficient constructions. We propose a very efficient wait-free
construction of bounded concurrent timestamp systems from 1-writer multireader
registers. This finalizes, corrects, and extends, a preliminary bounded
multiwriter construction proposed by the second author in 1986. That work
partially initiated the current interest in wait-free concurrent objects, and
introduced a notion of discrete vector clocks in distributed algorithms.
"
0108010,A Note on Tiling under Tomographic Constraints,"  Given a tiling of a 2D grid with several types of tiles, we can count for
every row and column how many tiles of each type it intersects. These numbers
are called the_projections_. We are interested in the problem of reconstructing
a tiling which has given projections. Some simple variants of this problem,
involving tiles that are 1x1 or 1x2 rectangles, have been studied in the past,
and were proved to be either solvable in polynomial time or NP-complete. In
this note we make progress toward a comprehensive classification of various
tiling reconstruction problems, by proving NP-completeness results for several
sets of tiles.
"
0108014,"What's Fit To Print: The Effect Of Ownership Concentration On Product
  Variety In Daily Newspaper Markets","  This paper examines the effect of ownership concentration on product
position, product variety and readership in markets for daily newspapers. US
antitrust policy presumes that mergers reduce the amount and diversity of
content available to consumers. However, the effects of consolidation in
differentiated product markets cannot be determined solely from theory. Because
multi-product firms internalize business stealing, mergers may encourage firms
to reposition products, leading to more, not less, variety. Using data on
reporter assignments from 1993-1999, results show that differentiation and
variety increase with concentration. Moreover, there is evidence that
additional variety increases readership, suggesting that concentration benefits
consumers.
"
0109001,"Abstract Computability, Algebraic Specification and Initiality","  computable functions are defined by abstract finite deterministic algorithms
on many-sorted algebras. We show that there exist finite universal algebraic
specifications that specify uniquely (up to isomorphism) (i) all abstract
computable functions on any many-sorted algebra; and (ii) all functions
effectively approximable by abstract computable functions on any metric
algebra.
  We show that there exist universal algebraic specifications for all the
classically computable functions on the set R of real numbers. The algebraic
specifications used are mainly bounded universal equations and conditional
equations. We investigate the initial algebra semantics of these
specifications, and derive situations where algebraic specifications define
precisely the computable functions.
"
0109008,"The Role of Incentives for Opening Monopoly Markets: Comparing GTE and
  BOC Cooperation with Local Entrants","  While the 1996 Telecommunications Act requires all incumbent local telephone
companies to cooperate with local entrants, section 271 of the Act provides the
Bell companies (but not GTE) additional incentives to cooperate. Using an
original data set, I compare the negotiations of AT&T, as a local entrant, with
GTE and with the Bell companies in states where both operate. My results
suggest that the differential incentives matter: The Bells accommodate entry
more than does GTE, as evidenced in quicker agreements, less litigation, and
more favorable prices offered for network access. Consistent with this, there
is more entry into Bell territories
"
0109014,"Assigning Satisfaction Values to Constraints: An Algorithm to Solve
  Dynamic Meta-Constraints","  The model of Dynamic Meta-Constraints has special activity constraints which
can activate other constraints. It also has meta-constraints which range over
other constraints. An algorithm is presented in which constraints can be
assigned one of five different satisfaction values, which leads to the
assignment of domain values to the variables in the CSP. An outline of the
model and the algorithm is presented, followed by some initial results for two
problems: a simple classic CSP and the Car Configuration Problem. The algorithm
is shown to perform few backtracks per solution, but to have overheads in the
form of historical records required for the implementation of state.
"
0109015,Boosting Trees for Anti-Spam Email Filtering,"  This paper describes a set of comparative experiments for the problem of
automatically filtering unwanted electronic mail messages. Several variants of
the AdaBoost algorithm with confidence-rated predictions [Schapire & Singer,
99] have been applied, which differ in the complexity of the base learners
considered. Two main conclusions can be drawn from our experiments: a) The
boosting-based methods clearly outperform the baseline learning algorithms
(Naive Bayes and Induction of Decision Trees) on the PU1 corpus, achieving very
high levels of the F1 measure; b) Increasing the complexity of the base
learners allows to obtain better ``high-precision'' classifiers, which is a
very important issue when misclassification costs are considered.
"
0109020,"Modelling Semantic Association and Conceptual Inheritance for Semantic
  Analysis","  Allowing users to interact through language borders is an interesting
challenge for information technology. For the purpose of a computer assisted
language learning system, we have chosen icons for representing meaning on the
input interface, since icons do not depend on a particular language. However, a
key limitation of this type of communication is the expression of articulated
ideas instead of isolated concepts. We propose a method to interpret sequences
of icons as complex messages by reconstructing the relations between concepts,
so as to build conceptual graphs able to represent meaning and to be used for
natural language sentence generation. This method is based on an electronic
dictionary containing semantic information.
"
0109024,Verification of Timed Automata Using Rewrite Rules and Strategies,"  ELAN is a powerful language and environment for specifying and prototyping
deduction systems in a language based on rewrite rules controlled by
strategies. Timed automata is a class of continuous real-time models of
reactive systems for which efficient model-checking algorithms have been
devised. In this paper, we show that these algorithms can very easily be
prototyped in the ELAN system. This paper argues through this example that
rewriting based systems relying on rules and strategies are a good framework to
prototype, study and test rather efficiently symbolic model-checking
algorithms, i.e. algorithms which involve combination of graph exploration
rules, deduction rules, constraint solving techniques and decision procedures.
"
0109030,Knowledge Sources for Word Sense Disambiguation,"  Two kinds of systems have been defined during the long history of WSD:
principled systems that define which knowledge types are useful for WSD, and
robust systems that use the information sources at hand, such as, dictionaries,
light-weight ontologies or hand-tagged corpora. This paper tries to systematize
the relation between desired knowledge types and actual information sources. We
also compare the results for a wide range of algorithms that have been
evaluated on a common test setting in our research group. We hope that this
analysis will help change the shift from systems based on information sources
to systems based on knowledge sources. This study might also shed some light on
semi-automatic acquisition of desired knowledge types from existing resources.
"
0109032,"The Internet, 1995-2000: Access, Civic Involvement, and Social
  Interaction","  Our research, which began fielding surveys in 1995, and which have been
repeated with variation in 1996, 1997 and 2000, was apparently the first to use
national random telephone survey methods to track social and community aspects
of Internet use, and to compare users and non-users. It also seems to be among
the first that used these methods to compare users with non-users in regards to
communication, social and community issues. The work has been largely supported
by grants from the Markle Foundation of New York City as well as the Robert
Wood Johnson Foundation.
  Abridged, see full text for complete abstract.
"
0109036,Competition and Price Dispersion in International Long Distance Calling,"  This paper examines the relationship between changes in telecommunications
provider concentration on international long distance routes and changes in
prices on those routes. Overall, decreased concentration is associated with
significantly lower prices to consumers of long distance services. However, the
relationship between concentration and price varies according to the type of
long distance plan considered. For the international flagship plans frequently
selected by more price-conscious consumers of international long distance,
increased competition on a route is associated with lower prices. In contrast,
for the basic international plans that are the default selection for consumers,
increased competition on a route is actually associated with higher prices.
Thus, somewhat surprisingly, price dispersion appears to increase as
competition increases.
"
0109040,"The Building of BODHI, a Bio-diversity Database System","  We have recently built a database system called BODHI, intended to store
plant bio-diversity information. It is based on an object-oriented modeling
approach and is developed completely around public-domain software. The unique
feature of BODHI is that it seamlessly integrates diverse types of data,
including taxonomic characteristics, spatial distributions, and genetic
sequences, thereby spanning the entire range from molecular to organism-level
information. A variety of sophisticated indexing strategies are incorporated to
efficiently access the various types of data, and a rule-based query processor
is employed for optimizing query execution. In this paper, we report on our
experiences in building BODHI and on its performance characteristics for a
representative set of queries.
"
0109042,"Intelligent Search of Correlated Alarms from Database containing Noise
  Data","  Alarm correlation plays an important role in improving the service and
reliability in modern telecommunications networks. Most previous research of
alarm correlation didn't consider the effect of noise data in Database. This
paper focuses on the method of discovering alarm correlation rules from
database containing noise data. We firstly define two parameters Win_freq and
Win_add as the measure of noise data and then present the Robust_search
algorithm to solve the problem. At different size of Win_freq and Win_add,
experiments with alarm data containing noise data show that the Robust_search
Algorithm can discover the more rules with the bigger size of Win_add. We also
experimentally compare two different interestingness measures of confidence and
correlation.
"
0109058,"Profiling Internet Users' Participation in Social Change Agendas: An
  application of Q methodology","  New computer-mediated channels of communication are action oriented and have
the ability to deliver information and dialogue - moderated and unmoderated -
which can facilitate the bringing together of a series of society's
stakeholders, opinion leaders and change agents, who have the ability to
influence social action. However, existing online studies have been limited in
explaining Internet users' willingness to participate in social change agendas
online. They have relied predominately on basic demographic descriptors such as
age, education, income and access to technology and have ignored, social,
psychological and attitudinal variables that may explain online participation
and social change. The authors propose a Q methodology research approach better
evaluate Internet users participation in online social change agendas.
"
0109060,Branching: the Essence of Constraint Solving,"  This paper focuses on the branching process for solving any constraint
satisfaction problem (CSP). A parametrised schema is proposed that (with
suitable instantiations of the parameters) can solve CSP's on both finite and
infinite domains. The paper presents a formal specification of the schema and a
statement of a number of interesting properties that, subject to certain
conditions, are satisfied by any instances of the schema.
  It is also shown that the operational procedures of many constraint systems
including cooperative systems) satisfy these conditions.
  Moreover, the schema is also used to solve the same CSP in different ways by
means of different instantiations of its parameters.
"
0109062,"India Attempts to Give a Jump-start to its Derailed Telecommunications
  Liberalization Process","  After the 1991 economic policy made a shift from a closed economic model to a
market-oriented model. The government invited private sector to participate in
reforming its telecom sector. However, the government took a half-hearted
approach in overhauling the legal and regulatory regime, suitable for
competitive regime or in framing the 1994 Telecom Policy.
  Competition was allowed in cellular and basis services. The ministry and the
incumbent (DOT) issued licenses to their competitors. Lack of transparency in
issuing licenses and unrealistic license fee derailed the reforms process and
led to wasteful litigation. The courts did not support the regulator and
virtually made its role redundant.
"
0109065,"On the Use of Vickrey Auctions for Spectrum Allocation in Developing
  Countries","  In this paper, we assess the applicability of auctions based on the Vickrey
second price model for allocating wireless spectrum in developing countries. We
first provide an overview of auction models for allocating resources. We then
examine the experience of auctioning spectrum in different countries. Based on
this examination, we posit some axioms that seem to have to be satisfied when
allocating spectrum in most developing countries. In light of these axioms, we
provide a critical evaluation of using Vickrey second- price auctions to
allocate spectrum in developing countries. We suggest the use of a new auction
mechanism, the Vickrey ""share auction"" which will satisfy many of these axioms.
"
0109068,"Second-Level Digital Divide: Mapping Differences in People's Online
  Skills","  Much of the existing approach to the digital divide suffers from an important
limitation. It is based on a binary classification of Internet use by only
considering whether someone is or is not an Internet user. To remedy this
shortcoming, this project looks at the differences in people's level of skill
with respect to finding information online. Findings suggest that people search
for content in a myriad of ways and there is a large variance in how long
people take to find various types of information online. Data are collected to
see how user demographics, users' social support networks, people's experience
with the medium, and their autonomy of use influence their level of user
sophistication.
"
0109070,"Networks Unplugged: Towards A Model of Compatibility Regulation Between
  Information Platforms","  Networks Unplugged: Towards A Model of Compatibility Regulation Between
Information Platforms This Article outlines a basic model for regulating
interoperability between rival information platforms. In so doing, it insists
that antitrust, intellectual property, and telecommunications regulation all
must follow the same set of principles to facilitate competition between rival
standards where possible, mandating or allowing cooperation only where
necessary to facilitate competition within a standard when network-level
competition is infeasible. To date, the antitrust regime best approximates the
type of model I have in mind, but sound competition policy requires that
telecommunications regulation and intellectual property law follow its basic
principles as well.
"
0109071,"The Impact of Incentives in the Telecommunications Act of 1996 on
  Corporate Strategies","  Rules are necessary to provide or shape the incentives of individuals and
organizations. This is particularly true when free markets lead to undesirable
outcomes. The Telecommunications Act of 1996 attempted to create incentives to
foster competition. Ambiguity as well as the timing of the Act has led to
delays in the clarification of rules and the rapid obsolescence of the
document. The paper presents the strategies that common carriers adopted to try
to tilt regulation in their favor, slow the entry of competitors, maintain
their market leadership, and expand into other segments. Some of the strategies
analyzed include lobbying efforts, court challenges, and lack of cooperation
with new entrants.
"
0109072,Higher-Order Pattern Complement and the Strict Lambda-Calculus,"  We address the problem of complementing higher-order patterns without
repetitions of existential variables. Differently from the first-order case,
the complement of a pattern cannot, in general, be described by a pattern, or
even by a finite set of patterns. We therefore generalize the simply-typed
lambda-calculus to include an internal notion of strict function so that we can
directly express that a term must depend on a given variable. We show that, in
this more expressive calculus, finite sets of patterns without repeated
variables are closed under complement and intersection. Our principal
application is the transformational approach to negation in higher-order logic
programs.
"
0109074,Indicators of Independence in Regulatory Commissions,"  Independent regulatory commissions such as the Federal Communications
Commission (FCC) must produce policies that reflect technical expertise, legal
precedent, and stakeholder input. Given these situational imperatives, how does
the FCC implement independence in its decision-making? This research explicates
some of the underlying rules, resources, and relationships within the
environment in which the agency is embedded that influence agency work
practices to operationalize independence. Research such as this may be helpful
in the creation of new, or for assessment of existing, regulatory commissions,
but only if great attention is paid not only to institutional structure, but
also to the practice of staff in the agency.
"
0109081,"Pricing and Network Externalities in Peer-to-Peer Communications
  Networks (Draft)","  This paper analyzes the pricing of transit traffic in wireless peer-to-peer
networks using the concepts of direct and indirect network externalities. We
first establish that without any pricing mechanism, congestion externalities
overwhelm other network effects in a wireless data network. We show that
peering technology will mitigate the congestion and allow users to take
advantage of more the positive network externalities. However, without pricing,
the peering equilibrium breaks down just like a bucket brigade made up of
free-riding agents. With pricing and perfect competition, a peering equilibrium
is possible and allows many more users on the network at the same time.
However, the congestion externality is still a problem, so peering organized
through a club may be the best solution.
"
0109094,"Competition and Globalization Brazilian Telecommunications Policy at
  Crossroads","  The current pattern of competition in the Brazilian telecommunications market
was defined by a regulatory reform implemented in the second half of the
nineties. The telecommunications regulatory reform discussed in the paper
promoted the privatization of Telebras System and fostered competition in the
Brazilian market under the stricted supervision of the new regulator Anatel.
Notwithstanding, the regulatory Brazilian scheme is at a crossroads. From 2002
on an open market approach will be implemented in telecom arena. We analyse the
main aspects of those change, from the firms perspective and also in a broad
scenario under influence of the World Trade Organization system
"
0109105,"Standards and Intellectual Property Rights in the Age of Global
  Communication - A Review of the International Standardization of
  Third-Generation Mobile System","  When the European Telecommunications Standards Institute (ETSI) selected a
radio access technology based on Wideband Code-Division Multiple Access
(WCDMA), sponsored by European telecommunications equipment manufactures
Ericsson and Nokia, for its third-generation wireless communications system, a
bitter dispute developed between ETSI and Qualcommm Inc. Qualcomm threatened to
withhold its intellectual property on the CDMA technology unless the Europeans
agreed to make the radio access technology backward compatible with cdmaOne,
Qualcomm's favored version of CDMA. A dispute over intellectual property rights
over key CDMA techniques also erupted between Ericsson and Qualcomm and both
filed patent infringement in US Court. The dispute halted the standards
activity and has troubled operators worldwide as well as the International
Telecommunications Union (ITU).
"
0109112,Elusive Threats: Security Weaknesses of Commercial Cellular Networks,"  Commercial cellular telecommunications networks are routinely used as key
means of voice and data transport by both businesses and the Public. Despite
advances in encryption and other security measures, these commercial cellular
networks remain extremely vulnerable to malicious attacks and the loss of user
and data privacy and integrity. Such losses can result not only in mere
inconvenience, but in serious corporate and national security breaches. Because
of the potentially catastrophic nature of such security breaches, it behooves
cellular network operators, distributors, and users to explore these network
risk areas and mitigate them to the extent that current resources allow.
"
0109114,"The Consumer Product Selection Process in an Internet Age: Obstacles to
  Maximum Effectiveness & Policy Options","  Intermediaries, like real estate agents, Consumer Reports, and Zagats, have
long helped buyers to identify their most suitable options. Now, the
combination of databases and the Internet enables them to serve consumers
dramatically more effectively. This article begins by offering a three-part
framework for understanding the evolving forms of selection assistance. It then
focuses on numerous potential obstacles that could prevent shoppers from
enjoying the full benefits of these developing technologies. While concluding
that adjustments to business strategies and the enforcement of existing laws
can effectively overcome most of these impediments, the article identifies
several areas where proactive government action may be desirable, such as to
prevent the emergence of anticompetitive entry barriers.
"
0110009,"Algorithmic Self-Assembly of DNA Tiles and its Application to
  Cryptanalysis","  The early promises of DNA computing to deliver a massively parallel
architecture well-suited to computationally hard problems have so far been
largely unkept. Indeed, it is probably fair to say that only toy problems have
been addressed experimentally. Recent experimental development on algorithmic
self-assembly using DNA tiles seem to offer the most promising path toward a
potentially useful application of the DNA computing concept. In this paper, we
explore new geometries for algorithmic self-assembly, departing from those
previously described in the literature. This enables us to carry out
mathematical operations like binary multiplication or cyclic convolution
product. We then show how to use the latter operation to implement an attack
against the well-known public-key crypto system NTRU.
"
0110016,Limits To Certainty in QoS Pricing and Bandwidth,"  Advanced services require more reliable bandwidth than currently provided by
the Internet Protocol, even with the reliability enhancements provided by TCP.
More reliable bandwidth will be provided through QoS (quality of service), as
currently discussed widely. Yet QoS has some implications beyond providing
ubiquitous access to advance Internet service, which are of interest from a
policy perspective. In particular, what are the implications for price of
Internet services? Further, how will these changes impact demand and universal
service for the Internet. This paper explores the relationship between
certainty of bandwidth and certainty of price for Internet services over a
statistically shared network and finds that these are mutually exclusive goals.
"
0110030,Dense point sets have sparse Delaunay triangulations,"  The spread of a finite set of points is the ratio between the longest and
shortest pairwise distances. We prove that the Delaunay triangulation of any
set of n points in R^3 with spread D has complexity O(D^3). This bound is tight
in the worst case for all D = O(sqrt{n}). In particular, the Delaunay
triangulation of any dense point set has linear complexity. We also generalize
this upper bound to regular triangulations of k-ply systems of balls, unions of
several dense point sets, and uniform samples of smooth surfaces. On the other
hand, for any n and D=O(n), we construct a regular triangulation of complexity
Omega(nD) whose n vertices have spread D.
"
0110037,"Practical Aspects for a Working Compile Time Garbage Collection System
  for Mercury","  Compile-time garbage collection (CTGC) is still a very uncommon feature
within compilers. In previous work we have developed a compile-time structure
reuse system for Mercury, a logic programming language. This system indicates
which datastructures can safely be reused at run-time. As preliminary
experiments were promising, we have continued this work and have now a working
and well performing near-to-ship CTGC-system built into the Melbourne Mercury
Compiler (MMC).
  In this paper we present the multiple design decisions leading to this
system, we report the results of using CTGC for a set of benchmarks, including
a real-world program, and finally we discuss further possible improvements.
Benchmarks show substantial memory savings and a noticeable reduction in
execution time.
"
0110042,An Architecture for Security and Privacy in Mobile Communications,"  There is much discussion and debate about how to improve the security and
privacy of mobile communication systems, both voice and data. Most proposals
attempt to provide incremental improvements to systems that are deployed today.
Indeed, only incremental improvements are possible, given the regulatory,
technological, economic, and historical structure of the telecommunications
system. In this paper, we conduct a ``thought experiment'' to redesign the
mobile communications system to provide a high level of security and privacy
for the users of the system. We discuss the important requirements and how a
different architecture might successfully satisfy them. In doing so, we hope to
illuminate the possibilities for secure and private systems, as well as explore
their real limits.
"
0110044,EquiX--A Search and Query Language for XML,"  EquiX is a search language for XML that combines the power of querying with
the simplicity of searching. Requirements for such languages are discussed and
it is shown that EquiX meets the necessary criteria. Both a graph-based
abstract syntax and a formal concrete syntax are presented for EquiX queries.
In addition, the semantics is defined and an evaluation algorithm is presented.
The evaluation algorithm is polynomial under combined complexity.
  EquiX combines pattern matching, quantification and logical expressions to
query both the data and meta-data of XML documents. The result of a query in
EquiX is a set of XML documents. A DTD describing the result documents is
derived automatically from the query.
"
0110046,From 2G TO 3G - The Evolution of International Cellular Standards,"  The purpose of this paper is to examine the major factors surrouding and
contributing to the creation (and success) of Europe's 2nd generation 'GSM'
cellular system, and compare and contrast it to key events and recent
developments in 3rd generation 'IMT-2000' systems. The objective is to
ascertain whether lessons from the development of one system can be applied to
the other, and what implications 2G has for the development and assessment of
3G technologies. Among the major themes incorporated into this assessment is
the concept of cooperation, and its role in bringing about the collaboration
and integration necessary to support the success of an international cellular
standard.
"
0110049,A Symmetric Strategy in Graph Avoidance Games,"  In the graph avoidance game two players alternatingly color edges of a graph
G in red and in blue respectively. The player who first creates a monochromatic
subgraph isomorphic to a forbidden graph F loses. A symmetric strategy of the
second player ensures that, independently of the first player's strategy, the
blue and the red subgraph are isomorphic after every round of the game. We
address the class of those graphs G that admit a symmetric strategy for all F
and discuss relevant graph-theoretic and complexity issues. We also show
examples when, though a symmetric strategy on G generally does not exist, it is
still available for a particular F.
"
0110055,"Analytical solution of transient scalar wave and diffusion problems of
  arbitrary dimensionality and geometry by RBF wavelet series","  This study applies the RBF wavelet series to the evaluation of analytical
solutions of linear time-dependent wave and diffusion problems of any
dimensionality and geometry. To the best of the author's knowledge, such
analytical solutions have never been achieved before. The RBF wavelets can be
understood an alternative for multidimensional problems to the standard Fourier
series via fundamental and general solutions of partial differential equation.
The present RBF wavelets are infinitely differential, compactly supported,
orthogonal over different scales and very simple. The rigorous mathematical
proof of completeness and convergence is still missing in this study. The
present work may open a new window to numerical solution and theoretical
analysis of many other high-dimensional time-dependent PDE problems under
arbitrary geometry.
"
0111005,Automated Real-Time Testing (ARTT) for Embedded Control Systems (ECS),"  Developing real-time automated test systems for embedded control systems has
been a real problem. Some engineers and scientists have used customized
software and hardware as a solution, which can be very expensive and time
consuming to develop. We have discovered how to integrate a suite of
commercially available off-the-shelf software tools and hardware to develop a
scalable test platform that is capable of performing complete black-box testing
for a dual-channel real-time Embedded-PLC-based control system
(www.aps.anl.gov). We will discuss how the Vali/Test Pro testing methodology
was implemented to structure testing for a personnel safety system with large
quantities of requirements and test cases.
  This work was supported by the U.S. Department of Energy, Basic Energy
Sciences, under Contract No. W-31-109-Eng-38.
"
0111027,"Upgrade of Spring-8 Beamline Network with Vlan Technology Over Gigabit
  Ethernet","  The beamline network system at SPring-8 consists of three LANs; a BL-LAN for
beamline component control, a BL-USER-LAN for beamline experimental users and
an OA-LAN for the information services. These LANs are interconnected by a
firewall system. Since the network traffic and the number of beamlines have
increased, we upgraded the backbone of BL-USER-LAN from Fast Ethernet to
Gigabit Ethernet. And then, to establish the independency of a beamline and to
raise flexibility of every beamline, we also introduced the IEEE802.1Q Virtual
LAN (VLAN) technology into the BL-USER-LAN. We discuss here a future plan to
build the firewall system with hardware load balancers.
"
0111029,Versatile Data Acquisition and Controls for Epics Using Vme-Based Fpgas,"  Field-Programmable Gate Arrays (FPGAs) have provided Thomas Jefferson
National Accelerator Facility (Jefferson Lab) with versatile VME-based data
acquisition and control interfaces with minimal development times. FPGA designs
have been used to interface to VME and provide control logic for numerous
systems. The building blocks of these logic designs can be tailored to the
individual needs of each system and provide system operators with read-backs
and controls via a VME interface to an EPICS based computer. This versatility
allows the system developer to choose components and define operating
parameters and options that are not readily available commercially. Jefferson
Lab has begun developing standard FPGA libraries that result in quick turn
around times and inexpensive designs.
"
0111030,"A Dual Digital Signal Processor VME Board For Instrumentation And
  Control Applications","  A Dual Digital Signal Processing VME Board was developed for the Continuous
Electron Beam Accelerator Facility (CEBAF) Beam Current Monitor (BCM) system at
Jefferson Lab. It is a versatile general-purpose digital signal processing
board using an open architecture, which allows for adaptation to various
applications. The base design uses two independent Texas Instrument (TI)
TMS320C6711, which are 900 MFLOPS floating-point digital signal processors
(DSP). Applications that require a fixed point DSP can be implemented by
replacing the baseline DSP with the pin-for-pin compatible TMS320C6211. The
design can be manufactured with a reduced chip set without redesigning the
printed circuit board. For example it can be implemented as a single-channel
DSP with no analog I/O.
"
0111035,Open Source Real Time Operating Systems Overview,"  Modern control systems applications are often built on top of a real time
operating system (RTOS) which provides the necessary hardware abstraction as
well as scheduling, networking and other services. Several open source RTOS
solutions are publicly available, which is very attractive, both from an
economic (no licensing fees) as well as from a technical (control over the
source code) point of view. This contribution gives an overview of the RTLinux
and RTEMS systems (architecture, development environment, API etc.). Both
systems feature most popular CPUs, several APIs (including Posix), networking,
portability and optional commercial support. Some performance figures are
presented, focusing on interrupt latency and context switching delay.
"
0111039,"An Integrated Development Environment for Declarative Multi-Paradigm
  Programming","  In this paper we present CIDER (Curry Integrated Development EnviRonment), an
analysis and programming environment for the declarative multi-paradigm
language Curry. CIDER is a graphical environment to support the development of
Curry programs by providing integrated tools for the analysis and visualization
of programs. CIDER is completely implemented in Curry using libraries for GUI
programming (based on Tcl/Tk) and meta-programming. An important aspect of our
environment is the possible adaptation of the development environment to other
declarative source languages (e.g., Prolog or Haskell) and the extensibility
w.r.t. new analysis methods. To support the latter feature, the lazy evaluation
strategy of the underlying implementation language Curry becomes quite useful.
"
0111055,Overview of the NSTX Control System,"  The National Spherical Torus Experiment (NSTX) is an innovative magnetic
fusion device that was constructed by the Princeton Plasma Physics Laboratory
(PPPL) in collaboration with the Oak Ridge National Laboratory, Columbia
University, and the University of Washington at Seattle. Since achieving first
plasma in 1999, the device has been used for fusion research through an
international collaboration of over twenty institutions. The NSTX is operated
through a collection of control systems that encompass a wide range of
technology, from hardwired relay controls to real-time control systems with
giga-FLOPS of capability. This paper presents a broad introduction to the
control systems used on NSTX, with an emphasis on the computing controls, data
acquisition, and synchronization systems.
"
0111063,New RBF collocation methods and kernel RBF with applications,"  A few novel radial basis function (RBF) discretization schemes for partial
differential equations are developed in this study. For boundary-type methods,
we derive the indirect and direct symmetric boundary knot methods. Based on the
multiple reciprocity principle, the boundary particle method is introduced for
general inhomogeneous problems without using inner nodes. For domain-type
schemes, by using the Green integral we develop a novel Hermite RBF scheme
called the modified Kansa method, which significantly reduces calculation
errors at close-to-boundary nodes. To avoid Gibbs phenomenon, we present the
least square RBF collocation scheme. Finally, five types of the kernel RBF are
also briefly presented.
"
0112009,DNA Self-Assembly For Constructing 3D Boxes,"  We propose a mathematical model of DNA self-assembly using 2D tiles to form
3D nanostructures. This is the first work to combine studies in self-assembly
and nanotechnology in 3D, just as Rothemund and Winfree did in the 2D case. Our
model is a more precise superset of their Tile Assembly Model that facilitates
building scalable 3D molecules. Under our model, we present algorithms to build
a hollow cube, which is intuitively one of the simplest 3D structures to
construct. We also introduce five basic measures of complexity to analyze these
algorithms. Our model and algorithmic techniques are applicable to more complex
2D and 3D nanostructures.
"
0112014,Guaranteeing the diversity of number generators,"  A major problem in using iterative number generators of the form
x_i=f(x_{i-1}) is that they can enter unexpectedly short cycles. This is hard
to analyze when the generator is designed, hard to detect in real time when the
generator is used, and can have devastating cryptanalytic implications. In this
paper we define a measure of security, called_sequence_diversity_, which
generalizes the notion of cycle-length for non-iterative generators. We then
introduce the class of counter assisted generators, and show how to turn any
iterative generator (even a bad one designed or seeded by an adversary) into a
counter assisted generator with a provably high diversity, without reducing the
quality of generators which are already cryptographically strong.
"
0112015,Rational Competitive Analysis,"  Much work in computer science has adopted competitive analysis as a tool for
decision making under uncertainty. In this work we extend competitive analysis
to the context of multi-agent systems. Unlike classical competitive analysis
where the behavior of an agent's environment is taken to be arbitrary, we
consider the case where an agent's environment consists of other agents. These
agents will usually obey some (minimal) rationality constraints. This leads to
the definition of rational competitive analysis. We introduce the concept of
rational competitive analysis, and initiate the study of competitive analysis
for multi-agent systems. We also discuss the application of rational
competitive analysis to the context of bidding games, as well as to the
classical one-way trading problem.
"
0112017,Using Structural Metadata to Localize Experience of Digital Content,"  With the increasing technical sophistication of both information consumers
and providers, there is increasing demand for more meaningful experiences of
digital information. We present a framework that separates digital object
experience, or rendering, from digital object storage and manipulation, so the
rendering can be tailored to particular communities of users. Our framework
also accommodates extensible digital object behaviors and interoperability. The
two key components of our approach are 1) exposing structural metadata
associated with digital objects -- metadata about the labeled access points
within a digital object and 2) information intermediaries called context
brokers that match structural characteristics of digital objects with
mechanisms that produce behaviors. These context brokers allow for localized
rendering of digital information stored externally.
"
0112020,Concurrent computing machines and physical space-time,"  Concrete computing machines, either sequential or concurrent, rely on an
intimate relation between computation and time. We recall the general
characteristic properties of physical time and of present realizations of
computing systems. We emphasize the role of computing interferences, i.e. the
necessity to avoid them in order to give a causal implementation to logical
operations. We compare synchronous and asynchronous systems, and make a brief
survey of some methods used to deal with computing interferences. Using a
graphic representation, we show that synchronous and asynchronous circuits
reflect the same opposition as the Newtonian and relativistic causal structures
for physical space-time.
"
0112024,Media Objects in Time - A Multimedia Streaming System,"  The widespread availability of networked multimedia potentials embedded in an
infrastructure of qualitative superior kind gives rise to new approaches in the
areas of teleteaching and internet presentation: The distribution of
professionally styled multimedia streams has fallen in the realm of
possibility. This paper presents a prototype - both model and runtime
environment - of a time directed media system treating any kind of
presentational contribution as reusable media object components. The plug-in
free runtime system is based on a database and allows for a flexible support of
static media types as well as for easy extensions by streaming media servers.
The prototypic implementation includes a preliminary Web Authoring platform.
"
0201001,Lower Bounds for Matrix Product,"  We prove lower bounds on the number of product gates in bilinear and
quadratic circuits that compute the product of two $n \cross n$ matrices over
finite fields. In particular we obtain the following results:
  1. We show that the number of product gates in any bilinear (or quadratic)
circuit that computes the product of two $n \cross n$ matrices over $F_2$ is at
least $3 n^2 - o(n^2)$.
  2. We show that the number of product gates in any bilinear circuit that
computes the product of two $n \cross n$ matrices over $F_p$ is at least $(2.5
+ \frac{1.5}{p^3 -1})n^2 -o(n^2)$.
  These results improve the former results of Bshouty '89 and Blaser '99 who
proved lower bounds of $2.5 n^2 - o(n^2)$.
"
0201018,Long Proteins with Unique Optimal Foldings in the H-P Model,"  It is widely accepted that (1) the natural or folded state of proteins is a
global energy minimum, and (2) in most cases proteins fold to a unique state
determined by their amino acid sequence. The H-P (hydrophobic-hydrophilic)
model is a simple combinatorial model designed to answer qualitative questions
about the protein folding process. In this paper we consider a problem
suggested by Brian Hayes in 1998: what proteins in the two-dimensional H-P
model have unique optimal (minimum energy) foldings? In particular, we prove
that there are closed chains of monomers (amino acids) with this property for
all (even) lengths; and that there are open monomer chains with this property
for all lengths divisible by four.
"
0202012,Logic program specialisation through partial deduction: Control issues,"  Program specialisation aims at improving the overall performance of programs
by performing source to source transformations. A common approach within
functional and logic programming, known respectively as partial evaluation and
partial deduction, is to exploit partial knowledge about the input. It is
achieved through a well-automated application of parts of the
Burstall-Darlington unfold/fold transformation framework. The main challenge in
developing systems is to design automatic control that ensures correctness,
efficiency, and termination. This survey and tutorial presents the main
developments in controlling partial deduction over the past 10 years and
analyses their respective merits and shortcomings. It ends with an assessment
of current achievements and sketches some remaining research challenges.
"
0202023,Expected Qualitative Utility Maximization,"  A model for decision making that generalizes Expected Utility Maximization is
presented. This model, Expected Qualitative Utility Maximization, encompasses
the Maximin criterion. It relaxes both the Independence and the Continuity
postulates. Its main ingredient is the definition of a qualitative order on
nonstandard models of the real numbers and the consideration of nonstandard
utilities. Expected Qualitative Utility Maximization is characterized by an
original weakening of von Neumann-Morgenstern's postulates. Subjective
probabilities may be defined from those weakened postulates, as Anscombe and
Aumann did from the original postulates. Subjective probabilities are numbers,
not matrices as in the Subjective Expected Lexicographic Utility approach. JEL
no.: D81 Keywords: Utility Theory, Non-Standard Utilities, Qualitative Decision
Theory
"
0203001,Towards Generic Refactoring,"  We study program refactoring while considering the language or even the
programming paradigm as a parameter. We use typed functional programs, namely
Haskell programs, as the specification medium for a corresponding refactoring
framework. In order to detach ourselves from language syntax, our
specifications adhere to the following style. (I) As for primitive algorithms
for program analysis and transformation, we employ generic function combinators
supporting generic traversal and polymorphic functions refined by ad-hoc cases.
(II) As for the language abstractions involved in refactorings, we design a
dedicated multi-parameter class. This class can be instantiated for
abstractions as present in various languages, e.g., Java, Prolog or Haskell.
"
0203002,Another perspective on Default Reasoning,"  The lexicographic closure of any given finite set D of normal defaults is
defined. A conditional assertion ""if a then b"" is in this lexicographic closure
if, given the defaults D and the fact a, one would conclude b. The
lexicographic closure is essentially a rational extension of D, and of its
rational closure, defined in a previous paper. It provides a logic of normal
defaults that is different from the one proposed by R. Reiter and that is rich
enough not to require the consideration of non-normal defaults. A large number
of examples are provided to show that the lexicographic closure corresponds to
the basic intuitions behind Reiter's logic of defaults.
"
0203007,Two results for proiritized logic programming,"  Prioritized default reasoning has illustrated its rich expressiveness and
flexibility in knowledge representation and reasoning. However, many important
aspects of prioritized default reasoning have yet to be thoroughly explored. In
this paper, we investigate two properties of prioritized logic programs in the
context of answer set semantics. Specifically, we reveal a close relationship
between mutual defeasibility and uniqueness of the answer set for a prioritized
logic program. We then explore how the splitting technique for extended logic
programs can be extended to prioritized logic programs. We prove splitting
theorems that can be used to simplify the evaluation of a prioritized logic
program under certain conditions.
"
0203011,"Capturing Knowledge of User Preferences: ontologies on recommender
  systems","  Tools for filtering the World Wide Web exist, but they are hampered by the
difficulty of capturing user preferences in such a dynamic environment. We
explore the acquisition of user profiles by unobtrusive monitoring of browsing
behaviour and application of supervised machine-learning techniques coupled
with an ontological representation to extract user preferences. A multi-class
approach to paper classification is used, allowing the paper topic taxonomy to
be utilised during profile construction. The Quickstep recommender system is
presented and two empirical studies evaluate it in a real work setting,
measuring the effectiveness of using a hierarchical topic ontology compared
with an extendable flat list.
"
0203022,Three Optimisations for Sharing,"  In order to improve precision and efficiency sharing analysis should track
both freeness and linearity. The abstract unification algorithms for these
combined domains are suboptimal, hence there is scope for improving precision.
This paper proposes three optimisations for tracing sharing in combination with
freeness and linearity. A novel connection between equations and sharing
abstractions is used to establish correctness of these optimisations even in
the presence of rational trees. A method for pruning intermediate sharing
abstractions to improve efficiency is also proposed. The optimisations are
lightweight and therefore some, if not all, of these optimisations will be of
interest to the implementor.
"
0203026,"Conformal Geometry, Euclidean Space and Geometric Algebra","  Projective geometry provides the preferred framework for most implementations
of Euclidean space in graphics applications. Translations and rotations are
both linear transformations in projective geometry, which helps when it comes
to programming complicated geometrical operations. But there is a fundamental
weakness in this approach - the Euclidean distance between points is not
handled in a straightforward manner. Here we discuss a solution to this
problem, based on conformal geometry. The language of geometric algebra is best
suited to exploiting this geometry, as it handles the interior and exterior
products in a single, unified framework. A number of applications are
discussed, including a compact formula for reflecting a line off a general
spherical surface.
"
0203027,The Algorithms of Updating Sequential Patterns,"  Because the data being mined in the temporal database will evolve with time,
many researchers have focused on the incremental mining of frequent sequences
in temporal database. In this paper, we propose an algorithm called IUS, using
the frequent and negative border sequences in the original database for
incremental sequence mining. To deal with the case where some data need to be
updated from the original database, we present an algorithm called DUS to
maintain sequential patterns in the updated database. We also define the
negative border sequence threshold: Min_nbd_supp to control the number of
sequences in the negative border.
"
0204003,Blind Normalization of Speech From Different Channels and Speakers,"  This paper describes representations of time-dependent signals that are
invariant under any invertible time-independent transformation of the signal
time series. Such a representation is created by rescaling the signal in a
non-linear dynamic manner that is determined by recently encountered signal
levels. This technique may make it possible to normalize signals that are
related by channel-dependent and speaker-dependent transformations, without
having to characterize the form of the signal transformations, which remain
unknown. The technique is illustrated by applying it to the time-dependent
spectra of speech that has been filtered to simulate the effects of different
channels. The experimental results show that the rescaled speech
representations are largely normalized (i.e., channel-independent), despite the
channel-dependence of the raw (unrescaled) speech.
"
0204006,"TableTrans, MultiTrans, InterTrans and TreeTrans: Diverse Tools Built on
  the Annotation Graph Toolkit","  Four diverse tools built on the Annotation Graph Toolkit are described. Each
tool associates linguistic codes and structures with time-series data. All are
based on the same software library and tool architecture. TableTrans is for
observational coding, using a spreadsheet whose rows are aligned to a signal.
MultiTrans is for transcribing multi-party communicative interactions recorded
using multi-channel signals. InterTrans is for creating interlinear text
aligned to audio. TreeTrans is for creating and manipulating syntactic trees.
This work demonstrates that the development of diverse tools and re-use of
software components is greatly facilitated by a common high-level application
programming interface for representing the data and managing input/output,
together with a common architecture for managing the interaction of multiple
components.
"
0204009,"New Results on Monotone Dualization and Generating Hypergraph
  Transversals","  We consider the problem of dualizing a monotone CNF (equivalently, computing
all minimal transversals of a hypergraph), whose associated decision problem is
a prominent open problem in NP-completeness. We present a number of new
polynomial time resp. output-polynomial time results for significant cases,
which largely advance the tractability frontier and improve on previous
results. Furthermore, we show that duality of two monotone CNFs can be
disproved with limited nondeterminism. More precisely, this is feasible in
polynomial time with O(chi(n) * log n) suitably guessed bits, where chi(n) is
given by \chi(n)^chi(n) = n; note that chi(n) = o(log n). This result sheds new
light on the complexity of this important problem.
"
0204015,Design Patterns for Functional Strategic Programming,"  In previous work, we introduced the fundamentals and a supporting combinator
library for \emph{strategic programming}. This an idiom for generic programming
based on the notion of a \emph{functional strategy}: a first-class generic
function that cannot only be applied to terms of any type, but which also
allows generic traversal into subterms and can be customized with type-specific
behaviour.
  This paper seeks to provide practicing functional programmers with pragmatic
guidance in crafting their own strategic programs. We present the fundamentals
and the support from a user's perspective, and we initiate a catalogue of
\emph{strategy design patterns}. These design patterns aim at consolidating
strategic programming expertise in accessible form.
"
0204026,Querying Databases of Annotated Speech,"  Annotated speech corpora are databases consisting of signal data along with
time-aligned symbolic `transcriptions'. Such databases are typically
multidimensional, heterogeneous and dynamic. These properties present a number
of tough challenges for representation and query. The temporal nature of the
data adds an additional layer of complexity. This paper presents and harmonises
two independent efforts to model annotated speech databases, one at Macquarie
University and one at the University of Pennsylvania. Various query languages
are described, along with illustrative applications to a variety of analytical
problems. The research reported here forms a part of several ongoing projects
to develop platform-independent open-source tools for creating, browsing,
searching, querying and transforming linguistic databases, and to disseminate
large linguistic databases over the internet.
"
0204028,Decision Lists for English and Basque,"  In this paper we describe the systems we developed for the English (lexical
and all-words) and Basque tasks. They were all supervised systems based on
Yarowsky's Decision Lists. We used Semcor for training in the English all-words
task. We defined different feature sets for each language. For Basque, in order
to extract all the information from the text, we defined features that have not
been used before in the literature, using a morphological analyzer. We also
implemented systems that selected automatically good features and were able to
obtain a prefixed precision (85%) at the cost of coverage. The systems that
used all the features were identified as BCU-ehu-dlist-all and the systems that
selected some features as BCU-ehu-dlist-best.
"
0204029,The Basque task: did systems perform in the upperbound?,"  In this paper we describe the Senseval 2 Basque lexical-sample task. The task
comprised 40 words (15 nouns, 15 verbs and 10 adjectives) selected from Euskal
Hiztegia, the main Basque dictionary. Most examples were taken from the
Egunkaria newspaper. The method used to hand-tag the examples produced low
inter-tagger agreement (75%) before arbitration. The four competing systems
attained results well above the most frequent baseline and the best system
scored 75% precision at 100% coverage. The paper includes an analysis of the
tagging procedure used, as well as the performance of the competing systems. In
particular, we argue that inter-tagger agreement is not a real upperbound for
the Basque WSD task.
"
0204031,"A Dynamic Approach to Characterizing Termination of General Logic
  Programs","  We present a new characterization of termination of general logic programs.
Most existing termination analysis approaches rely on some static information
about the structure of the source code of a logic program, such as modes/types,
norms/level mappings, models/interargument relations, and the like. We propose
a dynamic approach which employs some key dynamic features of an infinite
(generalized) SLDNF-derivation, such as repetition of selected subgoals and
recursive increase in term size. We also introduce a new formulation of
SLDNF-trees, called generalized SLDNF-trees. Generalized SLDNF-trees deal with
negative subgoals in the same way as Prolog and exist for any general logic
programs.
"
0204034,"Monitoring and Debugging Concurrent and Distributed Object-Oriented
  Systems","  A major part of debugging, testing, and analyzing a complex software system
is understanding what is happening within the system at run-time. Some
developers advocate running within a debugger to better understand the system
at this level. Others embed logging statements, even in the form of hard-coded
calls to print functions, throughout the code. These techniques are all
general, rough forms of what we call system monitoring, and, while they have
limited usefulness in simple, sequential systems, they are nearly useless in
complex, concurrent ones. We propose a set of new mechanisms, collectively
known as a monitoring system, for understanding such complex systems, and we
describe an example implementation of such a system, called IDebug, for the
Java programming language.
"
0204038,"Technology For Information Engineering (TIE): A New Way of Storing,
  Retrieving and Analyzing Information","  The theoretical foundations of a new model and paradigm (called TIE) for data
storage and access are introduced. Associations between data elements are
stored in a single Matrix table, which is usually kept entirely in RAM for
quick access. The model ties together a very intuitive ""guided"" GUI to the
Matrix structure, allowing extremely easy complex searches through the data.
Although it is an ""Associative Model"" in that it stores the data associations
separately from the data itself, in contrast to other implementations of that
model TIE guides the user to only the available information ensuring that every
search is always fruitful. Very many diverse applications of the technology are
reviewed.
"
0204041,Trust Brokerage Systems for the Internet,"  This thesis addresses the problem of providing trusted individuals with
confidential information about other individuals, in particular, granting
access to databases of personal records using the World-Wide Web. It proposes
an access rights management system for distributed databases which aims to
create and implement organisation structures based on the wishes of the owners
and of demands of the users of the databases. The dissertation describes how
current software components could be used to implement this system; it
re-examines the theory of collective choice to develop mechanisms for
generating hierarchies of authorities; it analyses organisational processes for
stability and develops a means of measuring the similarity of their
hierarchies.
"
0204045,Some applications of logic to feasibility in higher types,"  In this paper we demonstrate that the class of basic feasible functionals has
recursion theoretic properties which naturally generalize the corresponding
properties of the class of feasible functions. We also improve the Kapron -
Cook result on mashine representation of basic feasible functionals. Our proofs
are based on essential applications of logic. We introduce a weak fragment of
second order arithmetic with second order variables ranging over functions from
N into N which suitably characterizes basic feasible functionals, and show that
it is a useful tool for investigating the properties of basic feasible
functionals. In particular, we provide an example how one can extract feasible
""programs"" from mathematical proofs which use non-feasible functionals (like
second order polynomials).
"
0204046,Optimal Aggregation Algorithms for Middleware,"  Let D be a database of N objects where each object has m fields. The objects
are given in m sorted lists (where the ith list is sorted according to the ith
field). Our goal is to find the top k objects according to a monotone
aggregation function t, while minimizing access to the lists. The problem
arises in several contexts. In particular Fagin (JCSS 1999) considered it for
the purpose of aggregating information in a multimedia database system.
  We are interested in instance optimality, i.e. that our algorithm will be as
good as any other (correct) algorithm on any instance. We provide and analyze
several instance optimal algorithms for the task, with various access costs and
models.
"
0204053,Qualitative Analysis of Correspondence for Experimental Algorithmics,"  Correspondence identifies relationships among objects via similarities among
their components; it is ubiquitous in the analysis of spatial datasets,
including images, weather maps, and computational simulations. This paper
develops a novel multi-level mechanism for qualitative analysis of
correspondence. Operators leverage domain knowledge to establish
correspondence, evaluate implications for model selection, and leverage
identified weaknesses to focus additional data collection. The utility of the
mechanism is demonstrated in two applications from experimental algorithmics --
matrix spectral portrait analysis and graphical assessment of Jordan forms of
matrices. Results show that the mechanism efficiently samples computational
experiments and successfully uncovers high-level problem properties. It
overcomes noise and data sparsity by leveraging domain knowledge to detect
mutually reinforcing interpretations of spatial data.
"
0204055,"Intelligent Search of Correlated Alarms for GSM Networks with
  Model-based Constraints","  In order to control the process of data mining and focus on the things of
interest to us, many kinds of constraints have been added into the algorithms
of data mining. However, discovering the correlated alarms in the alarm
database needs deep domain constraints. Because the correlated alarms greatly
depend on the logical and physical architecture of networks. Thus we use the
network model as the constraints of algorithms, including Scope constraint,
Inter-correlated constraint and Intra-correlated constraint, in our proposed
algorithm called SMC (Search with Model-based Constraints). The experiments
show that the SMC algorithm with Inter-correlated or Intra-correlated
constraint is about two times faster than the algorithm with no constraints.
"
0205001,A Calculus for End-to-end Statistical Service Guarantees,"  The deterministic network calculus offers an elegant framework for
determining delays and backlog in a network with deterministic service
guarantees to individual traffic flows. This paper addresses the problem of
extending the network calculus to a probabilistic framework with statistical
service guarantees. Here, the key difficulty relates to expressing, in a
statistical setting, an end-to-end (network) service curve as a concatenation
of per-node service curves. The notion of an effective service curve is
developed as a probabilistic bound on the service received by an individual
flow. It is shown that per-node effective service curves can be concatenated to
yield a network effective service curve.
"
0205029,A Codebook Generation Algorithm for Document Image Compression,"  Pattern-matching-based document-compression systems (e.g. for faxing) rely on
finding a small set of patterns that can be used to represent all of the ink in
the document. Finding an optimal set of patterns is NP-hard; previous
compression schemes have resorted to heuristics. This paper describes an
extension of the cross-entropy approach, used previously for measuring pattern
similarity, to this problem. This approach reduces the problem to a k-medians
problem, for which the paper gives a new algorithm with a provably good
performance guarantee. In comparison to previous heuristics (First Fit, with
and without generalized Lloyd's/k-means postprocessing steps), the new
algorithm generates a better codebook, resulting in an overall improvement in
compression performance of almost 17%.
"
0205032,On-Line End-to-End Congestion Control,"  Congestion control in the current Internet is accomplished mainly by TCP/IP.
To understand the macroscopic network behavior that results from TCP/IP and
similar end-to-end protocols, one main analytic technique is to show that the
the protocol maximizes some global objective function of the network traffic.
Here we analyze a particular end-to-end, MIMD (multiplicative-increase,
multiplicative-decrease) protocol. We show that if all users of the network use
the protocol, and all connections last for at least logarithmically many
rounds, then the total weighted throughput (value of all packets received) is
near the maximum possible. Our analysis includes round-trip-times, and (in
contrast to most previous analyses) gives explicit convergence rates, allows
connections to start and stop, and allows capacities to change.
"
0205034,"Data-Collection for the Sloan Digital Sky Survey: a Network-Flow
  Heuristic","  The goal of the Sloan Digital Sky Survey is ``to map in detail one-quarter of
the entire sky, determining the positions and absolute brightnesses of more
than 100 million celestial objects''. The survey will be performed by taking
``snapshots'' through a large telescope. Each snapshot can capture up to 600
objects from a small circle of the sky. This paper describes the design and
implementation of the algorithm that is being used to determine the snapshots
so as to minimize their number. The problem is NP-hard in general; the
algorithm described is a heuristic, based on Lagriangian-relaxation and
min-cost network flow. It gets within 5-15% of a naive lower bound, whereas
using a ``uniform'' cover only gets within 25-35%.
"
0205042,Orienting Graphs to Optimize Reachability,"  The paper focuses on two problems: (i) how to orient the edges of an
undirected graph in order to maximize the number of ordered vertex pairs (x,y)
such that there is a directed path from x to y, and (ii) how to orient the
edges so as to minimize the number of such pairs. The paper describes a
quadratic-time algorithm for the first problem, and a proof that the second
problem is NP-hard to approximate within some constant 1+epsilon > 1. The
latter proof also shows that the second problem is equivalent to
``comparability graph completion''; neither problem was previously known to be
NP-hard.
"
0205045,Balancing Minimum Spanning and Shortest Path Trees,"  This paper give a simple linear-time algorithm that, given a weighted
digraph, finds a spanning tree that simultaneously approximates a shortest-path
tree and a minimum spanning tree. The algorithm provides a continuous
trade-off: given the two trees and epsilon > 0, the algorithm returns a
spanning tree in which the distance between any vertex and the root of the
shortest-path tree is at most 1+epsilon times the shortest-path distance, and
yet the total weight of the tree is at most 1+2/epsilon times the weight of a
minimum spanning tree. This is the best tradeoff possible. The paper also
describes a fast parallel implementation.
"
0205050,"A Network-Flow Technique for Finding Low-Weight Bounded-Degree Spanning
  Trees","  The problem considered is the following. Given a graph with edge weights
satisfying the triangle inequality, and a degree bound for each vertex, compute
a low-weight spanning tree such that the degree of each vertex is at most its
specified bound. The problem is NP-hard (it generalizes Traveling Salesman
(TSP)). This paper describes a network-flow heuristic for modifying a given
tree T to meet the constraints. Choosing T to be a minimum spanning tree (MST)
yields approximation algorithms with performance guarantee less than 2 for the
problem on geometric graphs with L_p-norms. The paper also describes a
Euclidean graph whose minimum TSP costs twice the MST, disproving a conjecture
made in ``Low-Degree Spanning Trees of Small Weight'' (1996).
"
0205052,Three-Tiered Specification of Micro-Architectures,"  A three-tiered specification approach is developed to formally specify
collections of collaborating objects, say micro-architectures. (i) The
structural properties to be maintained in the collaboration are specified in
the lowest tier. (ii) The behaviour of the object methods in the classes is
specified in the middle tier. (iii) The interaction of the objects in the
micro-architecture is specified in the third tier. The specification approach
is based on Larch and accompanying notations and tools. The approach enables
the unambiguous and complete specification of reusable collections of
collaborating objects. The layered, formal approach is compared to other
approaches including the mainstream UML approach.
"
0205080,Transforming the World Wide Web into a Complexity-Based Semantic Network,"  The aim of this paper is to introduce the idea of the Semantic Web to the
Complexity community and set a basic ground for a project resulting in creation
of Internet-based semantic network of Complexity-related information providers.
Implementation of the Semantic Web technology would be of mutual benefit to
both the participants and users and will confirm self-referencing power of the
community to apply the products of its own research to itself. We first explain
the logic of the transition and discuss important notions associated with the
Semantic Web technology. We then present a brief outline of the project
milestones.
"
0206007,"Using the Annotated Bibliography as a Resource for Indicative
  Summarization","  We report on a language resource consisting of 2000 annotated bibliography
entries, which is being analyzed as part of our research on indicative document
summarization. We show how annotated bibliographies cover certain aspects of
summarization that have not been well-covered by other summary corpora, and
motivate why they constitute an important form to study for information
retrieval. We detail our methodology for collecting the corpus, and overview
our document feature markup that we introduced to facilitate summary analysis.
We present the characteristics of the corpus, methods of collection, and show
its use in finding the distribution of types of information included in
indicative summaries and their relative ordering within the summaries.
"
0206019,Simultaneous Embedding of a Planar Graph and Its Dual on the Grid,"  Traditional representations of graphs and their duals suggest the requirement
that the dual vertices be placed inside their corresponding primal faces, and
the edges of the dual graph cross only their corresponding primal edges. We
consider the problem of simultaneously embedding a planar graph and its dual
into a small integer grid such that the edges are drawn as straight-line
segments and the only crossings are between primal-dual pairs of edges. We
provide a linear-time algorithm that simultaneously embeds a 3-connected planar
graph and its dual on a (2n-2) by (2n-2) integer grid, where n is the total
number of vertices in the graph and its dual. Furthermore our embedding
algorithm satisfies the two natural requirements mentioned above.
"
0206020,Multidimensional Network Monitoring for Intrusion Detection,"  An approach for real-time network monitoring in terms of numerical
time-dependant functions of protocol parameters is suggested. Applying complex
systems theory for information f{l}ow analysis of networks, the information
traffic is described as a trajectory in multi-dimensional parameter-time space
with about 10-12 dimensions. The network traffic description is synthesized by
applying methods of theoretical physics and complex systems theory, to provide
a robust approach for network monitoring that detects known intrusions, and
supports developing real systems for detection of unknown intrusions. The
methods of data analysis and pattern recognition presented are the basis of a
technology study for an automatic intrusion detection system that detects the
attack in the reconnaissance stage.
"
0206028,"Knowledge management for enterprises (Wissensmanagement fuer
  Unternehmen)","  Although knowledge is one of the most valuable resource of enterprises and an
important production and competition factor, this intellectual potential is
often used (or maintained) only inadequate by the enterprises. Therefore, in a
globalised and growing market the optimal usage of existing knowledge
represents a key factor for enterprises of the future. Here, knowledge
management systems should engage facilitating. Because geographically far
distributed establishments cause, however, a distributed system, this paper
should uncover the spectrum connected with it and present a possible basic
approach which is based on ontologies and modern, platform independent
technologies. Last but not least this attempt, as well as general questions of
the knowledge management, are discussed.
"
0206029,Computer-Generated Photorealistic Hair,"  This paper presents an efficient method for generating and rendering
photorealistic hair in two dimensional pictures. The method consists of three
major steps. Simulating an artist drawing is used to design the rough hair
shape. A convolution based filter is then used to generate photorealistic hair
patches. A refine procedure is finally used to blend the boundaries of the
patches with surrounding areas. This method can be used to create all types of
photorealistic human hair (head hair, facial hair and body hair). It is also
suitable for fur and grass generation. Applications of this method include:
hairstyle designing/editing, damaged hair image restoration, human hair
animation, virtual makeover of a human, and landscape creation.
"
0206039,"Hidden Markov model segmentation of hydrological and enviromental time
  series","  Motivated by Hubert's segmentation procedure we discuss the application of
hidden Markov models (HMM) to the segmentation of hydrological and enviromental
time series. We use a HMM algorithm which segments time series of several
hundred terms in a few seconds and is computationally feasible for even longer
time series. The segmentation algorithm computes the Maximum Likelihood
segmentation by use of an expectation / maximization iteration. We rigorously
prove algorithm convergence and use numerical experiments, involving
temperature and river discharge time series, to show that the algorithm usually
converges to the globally optimal segmentation. The relation of the proposed
algorithm to Hubert's segmentation procedure is also discussed.
"
0207004,Optimally cutting a surface into a disk,"  We consider the problem of cutting a set of edges on a polyhedral manifold
surface, possibly with boundary, to obtain a single topological disk,
minimizing either the total number of cut edges or their total length. We show
that this problem is NP-hard, even for manifolds without boundary and for
punctured spheres. We also describe an algorithm with running time n^{O(g+k)},
where n is the combinatorial complexity, g is the genus, and k is the number of
boundary components of the input surface. Finally, we describe a greedy
algorithm that outputs a O(log^2 g)-approximation of the minimum cut graph in
O(g^2 n log n) time.
"
0207006,"Orthonormal RBF wavelet and ridgelet-like series and transforms for
  high-dimensional problems","  This paper developed a systematic strategy establishing RBF on the wavelet
analysis, which includes continuous and discrete RBF orthonormal wavelet
transforms respectively in terms of singular fundamental solutions and
nonsingular general solutions of differential operators. In particular, the
harmonic Bessel RBF transforms were presented for high-dimensional data
processing. It was also found that the kernel functions of convection-diffusion
operator are feasible to construct some stable ridgelet-like RBF transforms. We
presented time-space RBF transforms based on non-singular solution and
fundamental solution of time-dependent differential operators. The present
methodology was further extended to analysis of some known RBFs such as the MQ,
Gaussian and pre-wavelet kernel RBFs.
"
0207007,"Evolutionary Circuit Design: Information Theory Perspective on Signal
  Propagation","  This paper presents case-study results on the application of information
theoretic approach to gate-level evolutionary circuit design. We introduce
information measures to provide better estimates of synthesis criteria of
digital circuits. For example, the analysis of signal propagation during
evolving gate-level synthesis can be improved by using information theoretic
measures that will make it possible to find the most effective geometry and
therefore predict the cost of the final design solution. The problem is
considered from the information engine point of view. That is, the process of
evolutionary gate-level circuit design is presented via such measures as
entropy, logical work and information vitality. Some examples of geometry
driven synthesis are provided to prove the above idea.
"
0207012,"Synthesis of Low-Power Digital Circuits Derived from Binary Decision
  Diagrams","  This paper introduces a novel method for synthesizing digital circuits
derived from Binary Decision Diagrams (BDDs) that can yield to reduction in
power dissipation. The power reduction is achieved by decreasing the switching
activity in a circuit while paying close attention to information measures as
an optimization criterion. We first present the technique of efficient
BDD-based computation of information measures which are used to guide the power
optimization procedures. Using this technique, we have developed an algorithm
of BDD reordering which leads to reducing the power consumption of the circuits
derived from BDDs. Results produced by the synthesis on the ISCAS benchmark
circuits are very encouraging.
"
0207014,On the Information Engine of Circuit Design,"  This paper addresses a new approach to find a spectrum of information
measures for the process of digital circuit synthesis. We consider the problem
from the information engine point of view. The circuit synthesis as a whole and
different steps of the design process (an example of decision diagram is given)
are presented via such measurements as entropy, logical work and information
vitality. We also introduce new information measures to provide better
estimates of synthesis criteria. We show that the basic properties of
information engine, such as the conservation law of information flow and the
equilibrium law of information can be formulated.
"
0207032,Alternative Characterizations for Strong Equivalence of Logic Programs,"  In this work we present additional results related to the property of strong
equivalence of logic programs. This property asserts that two programs share
the same set of stable models, even under the addition of new rules. As shown
in a recent work by Lifschitz, Pearce and Valverde, strong equivalence can be
simply reduced to equivalence in the logic of Here-and-There (HT). In this
paper we provide two alternatives respectively based on classical logic and
3-valued logic. The former is applicable to general rules, but not for nested
expressions, whereas the latter is applicable for nested expressions but, when
moving to an unrestricted syntax, it generally yields different results from
HT.
"
0207037,Some logics of belief and disbelief,"  The introduction of explicit notions of rejection, or disbelief, into logics
for knowledge representation can be justified in a number of ways. Motivations
range from the need for versions of negation weaker than classical negation, to
the explicit recording of classic belief contraction operations in the area of
belief change, and the additional levels of expressivity obtained from an
extended version of belief change which includes disbelief contraction. In this
paper we present four logics of disbelief which address some or all of these
intuitions. Soundness and completeness results are supplied and the logics are
compared with respect to applicability and utility.
"
0207042,Logic Programming with Ordered Disjunction,"  Logic programs with ordered disjunction (LPODs) combine ideas underlying
Qualitative Choice Logic (Brewka et al. KR 2002) and answer set programming.
Logic programming under answer set semantics is extended with a new connective
called ordered disjunction. The new connective allows us to represent
alternative, ranked options for problem solutions in the heads of rules: A
\times B intuitively means: if possible A, but if A is not possible then at
least B. The semantics of logic programs with ordered disjunction is based on a
preference relation on answer sets. LPODs are useful for applications in design
and configuration and can serve as a basis for qualitative decision making.
"
0207047,Tracing and Explaining Execution of CLP(FD) Programs,"  Previous work in the area of tracing CLP(FD) programs mainly focuses on
providing information about control of execution and domain modification. In
this paper, we present a trace structure that provides information about
additional important aspects. We incorporate explanations in the trace
structure, i.e. reasons for why certain solver actions occur. Furthermore, we
come up with a format for describing the execution of the filtering algorithms
of global constraints. Some new ideas about the design of the trace are also
presented. For example, we have modeled our trace as a nested block structure
in order to achieve a hierarchical view. Also, new ways about how to represent
and identify different entities such as constraints and domain variables are
presented.
"
0207054,"Enhancing Usefulness of Declarative Programming Frameworks through
  Complete Integration","  The Gisela framework for declarative programming was developed with the
specific aim of providing a tool that would be useful for knowledge
representation and reasoning within real-world applications. To achieve this, a
complete integration into an object-oriented application development
environment was used. The framework and methodology developed provide two
alternative application programming interfaces (APIs): Programming using
objects or programming using a traditional equational declarative style. In
addition to providing complete integration, Gisela also allows extensions and
modifications due to the general computation model and well-defined APIs. We
give a brief overview of the declarative model underlying Gisela and we present
the methodology proposed for building applications together with some real
examples.
"
0207055,The Rise and Fall of the Church-Turing Thesis,"  The essay consists of three parts. In the first part, it is explained how
theory of algorithms and computations evaluates the contemporary situation with
computers and global networks. In the second part, it is demonstrated what new
perspectives this theory opens through its new direction that is called theory
of super-recursive algorithms. These algorithms have much higher computing
power than conventional algorithmic schemes. In the third part, we explicate
how realization of what this theory suggests might influence life of people in
future. It is demonstrated that now the theory is far ahead computing practice
and practice has to catch up with the theory. We conclude with a comparison of
different approaches to the development of information technology.
"
0207058,Question Answering over Unstructured Data without Domain Restrictions,"  Information needs are naturally represented as questions. Automatic
Natural-Language Question Answering (NLQA) has only recently become a practical
task on a larger scale and without domain constraints.
  This paper gives a brief introduction to the field, its history and the
impact of systematic evaluation competitions.
  It is then demonstrated that an NLQA system for English can be built and
evaluated in a very short time using off-the-shelf parsers and thesauri. The
system is based on Robust Minimal Recursion Semantics (RMRS) and is portable
with respect to the parser used as a frontend. It applies atomic term
unification supported by question classification and WordNet lookup for
semantic similarity matching of parsed question representation and free text.
"
0207066,Polynomial Time Data Reduction for Dominating Set,"  Dealing with the NP-complete Dominating Set problem on undirected graphs, we
demonstrate the power of data reduction by preprocessing from a theoretical as
well as a practical side. In particular, we prove that Dominating Set
restricted to planar graphs has a so-called problem kernel of linear size,
achieved by two simple and easy to implement reduction rules. Moreover, having
implemented our reduction rules, first experiments indicate the impressive
practical potential of these rules. Thus, this work seems to open up a new and
prospective way how to cope with one of the most important problems in graph
theory and combinatorial optimization.
"
0207067,"On the existence and multiplicity of extensions in dialectical
  argumentation","  In the present paper, the existence and multiplicity problems of extensions
are addressed. The focus is on extension of the stable type. The main result of
the paper is an elegant characterization of the existence and multiplicity of
extensions in terms of the notion of dialectical justification, a close cousin
of the notion of admissibility. The characterization is given in the context of
the particular logic for dialectical argumentation DEFLOG. The results are of
direct relevance for several well-established models of defeasible reasoning
(like default logic, logic programming and argumentation frameworks), since
elsewhere dialectical argumentation has been shown to have close formal
connections with these models.
"
0207084,"Paraconsistent Reasoning via Quantified Boolean Formulas,I: Axiomatising
  Signed Systems","  Signed systems were introduced as a general, syntax-independent framework for
paraconsistent reasoning, that is, non-trivialised reasoning from inconsistent
information. In this paper, we show how the family of corresponding
paraconsistent consequence relations can be axiomatised by means of quantified
Boolean formulas. This approach has several benefits. First, it furnishes an
axiomatic specification of paraconsistent reasoning within the framework of
signed systems. Second, this axiomatisation allows us to identify upper bounds
for the complexity of the different signed consequence relations. We strengthen
these upper bounds by providing strict complexity results for the considered
reasoning tasks. Finally, we obtain an implementation of different forms of
paraconsistent reasoning by appeal to the existing system QUIP.
"
0207091,"An Almost Classical Logic for Logic Programming and Nonmonotonic
  Reasoning","  The model theory of a first-order logic called N^4 is introduced. N^4 does
not eliminate double negations, as classical logic does, but instead reduces
fourfold negations. N^4 is very close to classical logic: N^4 has two truth
values; implications in N^4 are material, like in classical logic; and negation
distributes over compound formulas in N^4 as it does in classical logic.
Results suggest that the semantics of normal logic programs is conveniently
formalized in N^4: Classical logic Herbrand interpretations generalize
straightforwardly to N^4; the classical minimal Herbrand model of a positive
logic program coincides with its unique minimal N^4 Herbrand model; the stable
models of a normal logic program and its so-called complete minimal N^4
Herbrand models coincide.
"
0208010,TerraService.NET: An Introduction to Web Services,"  This article explores the design and construction of a geo-spatial Internet
web service application from the host web site perspective and from the
perspective of an application using the web service. The TerraService.NET web
service was added to the popular TerraServer database and web site with no
major structural changes to the database. The article discusses web service
design, implementation, and deployment concepts and design guidelines. Web
services enable applications that aggregate and interact with information and
resources from Internet-scale distributed servers. The article presents the
design of two USDA applications that interoperate with database and web service
resources in Fort Collins Colorado and the TerraService web service located in
Tukwila Washington.
"
0208012,"Online Scientific Data Curation, Publication, and Archiving","  Science projects are data publishers. The scale and complexity of current and
future science data changes the nature of the publication process. Publication
is becoming a major project component. At a minimum, a project must preserve
the ephemeral data it gathers. Derived data can be reconstructed from metadata,
but metadata is ephemeral. Longer term, a project should expect some archive to
preserve the data. We observe that pub-lished scientific data needs to be
available forever ? this gives rise to the data pyramid of versions and to data
inflation where the derived data volumes explode. As an example, this article
describes the Sloan Digital Sky Survey (SDSS) strategies for data publication,
data access, curation, and preservation.
"
0208014,Web Services for the Virtual Observatory,"  Web Services form a new, emerging paradigm to handle distributed access to
resources over the Internet. There are platform independent standards (SOAP,
WSDL), which make the developers? task considerably easier. This article
discusses how web services could be used in the context of the Virtual
Observatory. We envisage a multi-layer architecture, with interoperating
services. A well-designed lower layer consisting of simple, standard services
implemented by most data providers will go a long way towards establishing a
modular architecture. More complex applications can be built upon this core
layer. We present two prototype applications, the SdssCutout and the SkyQuery
as examples of this layered architecture.
"
0208022,"Symbolic Methodology in Numeric Data Mining: Relational Techniques for
  Financial Applications","  Currently statistical and artificial neural network methods dominate in
financial data mining. Alternative relational (symbolic) data mining methods
have shown their effectiveness in robotics, drug design and other applications.
Traditionally symbolic methods prevail in the areas with significant
non-numeric (symbolic) knowledge, such as relative location in robot
navigation. At first glance, stock market forecast looks as a pure numeric area
irrelevant to symbolic methods. One of our major goals is to show that
financial time series can benefit significantly from relational data mining
based on symbolic methods. The paper overviews relational data mining
methodology and develops this techniques for financial data mining.
"
0208027,A Unified Theory of Shared Memory Consistency,"  Memory consistency models have been developed to specify what values may be
returned by a read given that, in a distributed system, memory operations may
only be partially ordered. Before this work, consistency models were defined
independently. Each model followed a set of rules which was separate from the
rules of every other model. In our work we have defined a set of four
consistency properties. Any subset of the four properties yields a set of rules
which constitute a consistency model. Every consistency model previously
described in the literature can be defined based on our four properties.
Therefore, we present these properties as a unfied theory of shared memory
consistency.
"
0208037,"Cooperation between Pronoun and Reference Resolution for Unrestricted
  Texts","  Anaphora resolution is envisaged in this paper as part of the reference
resolution process. A general open architecture is proposed, which can be
particularized and configured in order to simulate some classic anaphora
resolution methods. With the aim of improving pronoun resolution, the system
takes advantage of elementary cues about characters of the text, which are
represented through a particular data structure. In its most robust
configuration, the system uses only a general lexicon, a local morpho-syntactic
parser and a dictionary of synonyms. A short comparative corpus analysis shows
that narrative texts are the most suitable for testing such a system.
"
0209014,Randomized protocols for asynchronous consensus,"  The famous Fischer, Lynch, and Paterson impossibility proof shows that it is
impossible to solve the consensus problem in a natural model of an asynchronous
distributed system if even a single process can fail. Since its publication,
two decades of work on fault-tolerant asynchronous consensus algorithms have
evaded this impossibility result by using extended models that provide (a)
randomization, (b) additional timing assumptions, (c) failure detectors, or (d)
stronger synchronization mechanisms than are available in the basic model.
Concentrating on the first of these approaches, we illustrate the history and
structure of randomized asynchronous consensus protocols by giving detailed
descriptions of several such protocols.
"
0209016,Sorting with a forklift,"  A fork stack is a generalised stack which allows pushes and pops of several
items at a time. We consider the problem of determining which input streams can
be sorted using a single forkstack, or dually, which permutations of a fixed
input stream can be produced using a single forkstack. An algorithm is given to
solve the sorting problem and the minimal unsortable sequences are found. The
results are extended to fork stacks where there are bounds on how many items
can be pushed and popped at one time. In this context we also establish how to
enumerate the collection of sortable sequences.
"
0209031,Locating Data in (Small-World?) Peer-to-Peer Scientific Collaborations,"  Data-sharing scientific collaborations have particular characteristics,
potentially different from the current peer-to-peer environments. In this paper
we advocate the benefits of exploiting emergent patterns in self-configuring
networks specialized for scientific data-sharing collaborations. We speculate
that a peer-to-peer scientific collaboration network will exhibit small-world
topology, as do a large number of social networks for which the same pattern
has been documented. We propose a solution for locating data in decentralized,
scientific, data-sharing environments that exploits the small-worlds topology.
The research challenge we raise is: what protocols should be used to allow a
self-configuring peer-to-peer network to form small worlds similar to the way
in which the humans that use the network do in their social interactions?
"
0210004,Revising Partially Ordered Beliefs,"  This paper deals with the revision of partially ordered beliefs. It proposes
a semantic representation of epistemic states by partial pre-orders on
interpretations and a syntactic representation by partially ordered belief
bases. Two revision operations, the revision stemming from the history of
observations and the possibilistic revision, defined when the epistemic state
is represented by a total pre-order, are generalized, at a semantic level, to
the case of a partial pre-order on interpretations, and at a syntactic level,
to the case of a partially ordered belief base. The equivalence between the two
representations is shown for the two revision operations.
"
0210016,Compact Floor-Planning via Orderly Spanning Trees,"  Floor-planning is a fundamental step in VLSI chip design. Based upon the
concept of orderly spanning trees, we present a simple O(n)-time algorithm to
construct a floor-plan for any n-node plane triangulation. In comparison with
previous floor-planning algorithms in the literature, our solution is not only
simpler in the algorithm itself, but also produces floor-plans which require
fewer module types. An equally important aspect of our new algorithm lies in
its ability to fit the floor-plan area in a rectangle of size (n-1)x(2n+1)/3.
Lower bounds on the worst-case area for floor-planning any plane triangulation
are also provided in the paper.
"
0210024,The Lazy Bureaucrat Scheduling Problem,"  We introduce a new class of scheduling problems in which the optimization is
performed by the worker (single ``machine'') who performs the tasks. A typical
worker's objective is to minimize the amount of work he does (he is ``lazy''),
or more generally, to schedule as inefficiently (in some sense) as possible.
The worker is subject to the constraint that he must be busy when there is work
that he can do; we make this notion precise both in the preemptive and
nonpreemptive settings. The resulting class of ``perverse'' scheduling
problems, which we denote ``Lazy Bureaucrat Problems,'' gives rise to a rich
set of new questions that explore the distinction between maximization and
minimization in computing optimal schedules.
"
0211001,Fast and Simple Computation of All Longest Common Subsequences,"  This paper shows that a simple algorithm produces the {\em
all-prefixes-LCSs-graph} in $O(mn)$ time for two input sequences of size $m$
and $n$. Given any prefix $p$ of the first input sequence and any prefix $q$ of
the second input sequence, all longest common subsequences (LCSs) of $p$ and
$q$ can be generated in time proportional to the output size, once the
all-prefixes-LCSs-graph has been constructed. The problem can be solved in the
context of generating all the distinct character strings that represent an LCS
or in the context of generating all ways of embedding an LCS in the two input
strings.
"
0211007,Approximating Incomplete Kernel Matrices by the em Algorithm,"  In biological data, it is often the case that observed data are available
only for a subset of samples. When a kernel matrix is derived from such data,
we have to leave the entries for unavailable samples as missing. In this paper,
we make use of a parametric model of kernel matrices, and estimate missing
entries by fitting the model to existing entries. The parametric model is
created as a set of spectral variants of a complete kernel matrix derived from
another information source. For model fitting, we adopt the em algorithm based
on the information geometry of positive definite matrices. We will report
promising results on bacteria clustering experiments using two marker
sequences: 16S and gyrB.
"
0211009,"Improved Phylogeny Comparisons: Non-Shared Edges Nearest Neighbor
  Interchanges, and Subtree Transfers","  The number of the non-shared edges of two phylogenies is a basic measure of
the dissimilarity between the phylogenies. The non-shared edges are also the
building block for approximating a more sophisticated metric called the nearest
neighbor interchange (NNI) distance. In this paper, we give the first
subquadratic-time algorithm for finding the non-shared edges, which are then
used to speed up the existing approximating algorithm for the NNI distance from
$O(n^2)$ time to $O(n \log n)$ time. Another popular distance metric for
phylogenies is the subtree transfer (STT) distance. Previous work on computing
the STT distance considered degree-3 trees only. We give an approximation
algorithm for the STT distance for degree-$d$ trees with arbitrary $d$ and with
generalized STT operations.
"
0211018,Indexing schemes for similarity search: an illustrated paradigm,"  We suggest a variation of the Hellerstein--Koutsoupias--Papadimitriou
indexability model for datasets equipped with a similarity measure, with the
aim of better understanding the structure of indexing schemes for
similarity-based search and the geometry of similarity workloads. This in
particular provides a unified approach to a great variety of schemes used to
index into metric spaces and facilitates their transfer to more general
similarity measures such as quasi-metrics. We discuss links between performance
of indexing schemes and high-dimensional geometry. The concepts and results are
illustrated on a very large concrete dataset of peptide fragments equipped with
a biologically significant similarity measure.
"
0211031,Redundancy in Logic I: CNF Propositional Formulae,"  A knowledge base is redundant if it contains parts that can be inferred from
the rest of it. We study the problem of checking whether a CNF formula (a set
of clauses) is redundant, that is, it contains clauses that can be derived from
the other ones. Any CNF formula can be made irredundant by deleting some of its
clauses: what results is an irredundant equivalent subset (I.E.S.) We study the
complexity of some related problems: verification, checking existence of a
I.E.S. with a given size, checking necessary and possible presence of clauses
in I.E.S.'s, and uniqueness. We also consider the problem of redundancy with
different definitions of equivalence.
"
0211035,Monadic Style Control Constructs for Inference Systems,"  Recent advances in programming languages study and design have established a
standard way of grounding computational systems representation in category
theory. These formal results led to a better understanding of issues of control
and side-effects in functional and imperative languages. Another benefit is a
better way of modelling computational effects in logical frameworks. With this
analogy in mind, we embark on an investigation of inference systems based on
considering inference behaviour as a form of computation. We delineate a
categorical formalisation of control constructs in inference systems. This
representation emphasises the parallel between the modular articulation of the
categorical building blocks (triples) used to account for the inference
architecture and the modular composition of cognitive processes.
"
0211041,"An Approach to Automatic Indexing of Scientific Publications in High
  Energy Physics for Database SPIRES HEP","  We introduce an approach to automatic indexing of e-prints based on a
pattern-matching technique making extensive use of an Associative Patterns
Dictionary (APD), developed by us. Entries in the APD consist of natural
language phrases with the same semantic interpretation as a set of keywords
from a controlled vocabulary. The method also allows to recognize within
e-prints formulae written in TeX notations that might also appear as keywords.
We present an automatic indexing system, AUTEX, which we have applied to
keyword index e-prints in selected areas in high energy physics (HEP) making
use of the DESY-HEPI thesaurus as a controlled vocabulary.
"
0212017,Classes of Spatiotemporal Objects and Their Closure Properties,"  We present a data model for spatio-temporal databases. In this model
spatio-temporal data is represented as a finite union of objects described by
means of a spatial reference object, a temporal object and a geometric
transformation function that determines the change or movement of the reference
object in time.
  We define a number of practically relevant classes of spatio-temporal
objects, and give complete results concerning closure under Boolean set
operators for these classes. Since only few classes are closed under all set
operators, we suggest an extension of the model, which leads to better closure
properties, and therefore increased practical applicability. We also discuss a
normal form for this extended data model.
"
0212026,A Generalization of the Lifting Lemma for Logic Programming,"  Since the seminal work of J. A. Robinson on resolution, many lifting lemmas
for simplifying proofs of completeness of resolution have been proposed in the
literature. In the logic programming framework, they may also help to detect
some infinite derivations while proving goals under the SLD-resolution. In this
paper, we first generalize a version of the lifting lemma, by extending the
relation ""is more general than"" so that it takes into account only some
arguments of the atoms. The other arguments, which we call neutral arguments,
are disregarded. Then we propose two syntactic conditions of increasing power
for identifying neutral arguments from mere inspection of the text of a logic
program.
"
0212028,Technical Note: Bias and the Quantification of Stability,"  Research on bias in machine learning algorithms has generally been concerned
with the impact of bias on predictive accuracy. We believe that there are other
factors that should also play a role in the evaluation of bias. One such factor
is the stability of the algorithm; in other words, the repeatability of the
results. If we obtain two sets of data from the same phenomenon, with the same
underlying probability distribution, then we would like our learning algorithm
to induce approximately the same concepts from both sets of data. This paper
introduces a method for quantifying stability, based on a measure of the
agreement between concepts. We also discuss the relationships among stability,
predictive accuracy, and bias.
"
0212043,Computing Conformal Structure of Surfaces,"  This paper solves the problem of computing conformal structures of general
2-manifolds represented as triangle meshes. We compute conformal structures in
the following way: first compute homology bases from simplicial complex
structures, then construct dual cohomology bases and diffuse them to harmonic
1-forms. Next, we construct bases of holomorphic differentials. We then obtain
period matrices by integrating holomorphic differentials along homology bases.
We also study the global conformal mapping between genus zero surfaces and
spheres, and between general meshes and planes. Our method of computing
conformal structures can be applied to tackle fundamental problems in computer
aid design and computer graphics, such as geometry classification and
identification, and surface global parametrization.
"
0212053,Merging Locally Correct Knowledge Bases: A Preliminary Report,"  Belief integration methods are often aimed at deriving a single and
consistent knowledge base that retains as much as possible of the knowledge
bases to integrate. The rationale behind this approach is the minimal change
principle: the result of the integration process should differ as less as
possible from the knowledge bases to integrate. We show that this principle can
be reformulated in terms of a more general model of belief revision, based on
the assumption that inconsistency is due to the mistakes the knowledge bases
contain. Current belief revision strategies are based on a specific kind of
mistakes, which however does not include all possible ones. Some alternative
possibilities are discussed.
"
0301009,A Script Language for Data Integration in Database,"  A Script Language in this paper is designed to transform the original data
into the target data by the computing formula. The Script Language can be
translated into the corresponding SQL Language, and the computation is finally
implemented by the first type of dynamic SQL. The Script Language has the
operations of insert, update, delete, union, intersect, and minus for the table
in the database.The Script Language is edited by a text file and you can easily
modify the computing formula in the text file to deal with the situations when
the computing formula have been changed. So you only need modify the text of
the script language, but needn't change the programs that have complied.
"
0302002,Optimizing GoTools' Search Heuristics using Genetic Algorithms,"  GoTools is a program which solves life & death problems in the game of Go.
This paper describes experiments using a Genetic Algorithm to optimize
heuristic weights used by GoTools' tree-search. The complete set of heuristic
weights is composed of different subgroups, each of which can be optimized with
a suitable fitness function. As a useful side product, an MPI interface for
FreePascal was implemented to allow the use of a parallelized fitness function
running on a Beowulf cluster. The aim of this exercise is to optimize the
current version of GoTools, and to make tools available in preparation of an
extension of GoTools for solving open boundary life & death problems, which
will introduce more heuristic parameters to be fine tuned.
"
0302003,"Approximate analysis of search algorithms with ""physical"" methods","  An overview of some methods of statistical physics applied to the analysis of
algorithms for optimization problems (satisfiability of Boolean constraints,
vertex cover of graphs, decoding, ...) with distributions of random inputs is
proposed. Two types of algorithms are analyzed: complete procedures with
backtracking (Davis-Putnam-Loveland-Logeman algorithm) and incomplete, local
search procedures (gradient descent, random walksat, ...). The study of
complete algorithms makes use of physical concepts such as phase transitions,
dynamical renormalization flow, growth processes, ... As for local search
procedures, the connection between computational complexity and the structure
of the cost function landscape is questioned, with emphasis on the notion of
metastability.
"
0302004,Unique Pattern Matching in Strings,"  Regular expression patterns are a key feature of document processing
languages like Perl and XDuce. It is in this context that the first and longest
match policies have been proposed to disambiguate the pattern matching process.
We formally define a matching semantics with these policies and show that the
generally accepted method of simulating longest match by first match and
recursion is incorrect. We continue by solving the associated type inference
problem, which consists in calculating for every subexpression the set of words
the subexpression can still match when these policies are in effect, and show
how this algorithm can be used to efficiently implement the matching process.
"
0302005,"Barnacle: An Assembly Algorithm for Clone-based Sequences of Whole
  Genomes","  We propose an assembly algorithm {\sc Barnacle} for sequences generated by
the clone-based approach. We illustrate our approach by assembling the human
genome. Our novel method abandons the original physical-mapping-first
framework. As we show, {\sc Barnacle} more effectively resolves conflicts due
to repeated sequences. The latter is the main difficulty of the sequence
assembly problem. Inaddition, we are able to detect inconsistencies in the
underlying data. We present and compare our results on the December 2001 freeze
of the public working draft of the human genome with NCBI's assembly (Build
28).
  The assembly of December 2001 freeze of the public working draft generated by
{\sc Barnacle} and the source code of {\sc Barnacle} are available at
(http://www.cs.rutgers.edu/~vchoi).
"
0302012,The New AI: General & Sound & Relevant for Physics,"  Most traditional artificial intelligence (AI) systems of the past 50 years
are either very limited, or based on heuristics, or both. The new millennium,
however, has brought substantial progress in the field of theoretically optimal
and practically feasible algorithms for prediction, search, inductive inference
based on Occam's razor, problem solving, decision making, and reinforcement
learning in environments of a very general type. Since inductive inference is
at the heart of all inductive sciences, some of the results are relevant not
only for AI and computer science but also for physics, provoking nontraditional
predictions based on Zuse's thesis of the computer-generated universe.
"
0302035,"Risk-Management Methods for the Libor Market Model Using Semidefinite
  Programming","  When interest rate dynamics are described by the Libor Market Model as in
BGM97, we show how some essential risk-management results can be obtained from
the dual of the calibration program. In particular, if the objetive is to
maximize another swaption's price, we show that the optimal dual variables
describe a hedging portfolio in the sense of \cite{Avel96}. In the general
case, the local sensitivity of the covariance matrix to all market movement
scenarios can be directly computed from the optimal dual solution. We also show
how semidefinite programming can be used to manage the Gamma exposure of a
portfolio.
"
0302036,Constraint-based analysis of composite solvers,"  Cooperative constraint solving is an area of constraint programming that
studies the interaction between constraint solvers with the aim of discovering
the interaction patterns that amplify the positive qualities of individual
solvers. Automatisation and formalisation of such studies is an important issue
of cooperative constraint solving.
  In this paper we present a constraint-based analysis of composite solvers
that integrates reasoning about the individual solvers and the processed data.
The idea is to approximate this reasoning by resolution of set constraints on
the finite sets representing the predicates that express all the necessary
properties. We illustrate application of our analysis to two important
cooperation patterns: deterministic choice and loop.
"
0303001,When Crossings Count - Approximating the Minimum Spanning Tree,"  In the first part of the paper, we present an (1+\mu)-approximation algorithm
to the minimum-spanning tree of points in a planar arrangement of lines, where
the metric is the number of crossings between the spanning tree and the lines.
The expected running time is O((n/\mu^5) alpha^3(n) log^5 n), where \mu > 0 is
a prescribed constant.
  In the second part of our paper, we show how to embed such a crossing metric,
into high-dimensions, so that the distances are preserved. As a result, we can
deploy a large collection of subquadratic approximations algorithms \cite
im-anntr-98,giv-rahdg-99 for problems involving points with the crossing metric
as a distance function. Applications include matching, clustering,
nearest-neighbor, and furthest-neighbor.
"
0303006,On the Notion of Cognition,"  We discuss philosophical issues concerning the notion of cognition basing
ourselves in experimental results in cognitive sciences, especially in computer
simulations of cognitive systems. There have been debates on the ""proper""
approach for studying cognition, but we have realized that all approaches can
be in theory equivalent. Different approaches model different properties of
cognitive systems from different perspectives, so we can only learn from all of
them. We also integrate ideas from several perspectives for enhancing the
notion of cognition, such that it can contain other definitions of cognition as
special cases. This allows us to propose a simple classification of different
types of cognition.
"
0303014,Theoretical study of cache syatems,"  The aim of this paper is a theoretical study of a cache system in order to
optimize proxy cache systems and to modernize construction principles including
prefetching schemes. Two types of correlations, Zipf-like distribution and
normalizing conditions, play a role of the fundamental laws. A corresponding
system of equations allows to describe the basic effects like ratio between
construction parts, steady-state performance, optimal size, long-term
prefetching, etc. A modification of the fundamental laws leads to the
description of new effects of documents' renewal in the global network. An
internet traffic caching system based on Zipf-like distribution (ZBS) is
invented. The additional module to the cache construction gives an effective
prefetching by lifetime.
"
0303026,Preserving Peer Replicas By Rate-Limited Sampled Voting in LOCKSS,"  The LOCKSS project has developed and deployed in a world-wide test a
peer-to-peer system for preserving access to journals and other archival
information published on the Web. It consists of a large number of independent,
low-cost, persistent web caches that cooperate to detect and repair damage to
their content by voting in ""opinion polls."" Based on this experience, we
present a design for and simulations of a novel protocol for voting in systems
of this kind. It incorporates rate limitation and intrusion detection to ensure
that even some very powerful adversaries attacking over many years have only a
small probability of causing irrecoverable damage before being detected.
"
0304014,Commitment Capacity of Discrete Memoryless Channels,"  In extension of the bit commitment task and following work initiated by
Crepeau and Kilian, we introduce and solve the problem of characterising the
optimal rate at which a discrete memoryless channel can be used for bit
commitment. It turns out that the answer is very intuitive: it is the maximum
equivocation of the channel (after removing trivial redundancy), even when
unlimited noiseless bidirectional side communication is allowed.
  By a well-known reduction, this result provides a lower bound on the
channel's capacity for implementing coin tossing, which we conjecture to be an
equality.
  The method of proving this relates the problem to Wyner's wire--tap channel
in an amusing way. We also discuss extensions to quantum channels.
"
0304018,Quasiconvex Analysis of Backtracking Algorithms,"  We consider a class of multivariate recurrences frequently arising in the
worst case analysis of Davis-Putnam-style exponential time backtracking
algorithms for NP-hard problems. We describe a technique for proving asymptotic
upper bounds on these recurrences, by using a suitable weight function to
reduce the problem to that of solving univariate linear recurrences; show how
to use quasiconvex programming to determine the weight function yielding the
smallest upper bound; and prove that the resulting upper bounds are within a
polynomial factor of the true asymptotics of the recurrence. We develop and
implement a multiple-gradient descent algorithm for the resulting quasiconvex
programs, using a real-number arithmetic package for guaranteed accuracy of the
computed worst case time bounds.
"
0304032,"Growth in the ""New Economy"": U.S. Bandwidth Use and Pricing Across the
  1990s","  An acceleration in the growth of communications bandwidth in use and a rapid
reduction in bandwidth prices have not accompanied the U.S. economy's strong
performance in the second half of the 1990s. Overall U.S. bandwidth in use has
grown robustly throughout the 1990s, but growth has not significantly
accelerated in the second half of 1990s. Average prices for U.S. bandwidth in
use have fallen little in nominal terms in the second half of the 1990s. Policy
makers and policy analysts should recognize that institutional change, rather
than more competitors of established types, appears to be key to dramatic
improvements in bandwidth growth and prices. Such a development could provide a
significant additional impetus to aggregate growth and productivity.
"
0304041,"$P \ne NP$, propositional proof complexity, and resolution lower bounds
  for the weak pigeonhole principle","  Recent results established exponential lower bounds for the length of any
Resolution proof for the weak pigeonhole principle. More formally, it was
proved that any Resolution proof for the weak pigeonhole principle, with $n$
holes and any number of pigeons, is of length $\Omega(2^{n^{\epsilon}})$, (for
a constant $\epsilon = 1/3$). One corollary is that certain propositional
formulations of the statement $P \ne NP$ do not have short Resolution proofs.
After a short introduction to the problem of $P \ne NP$ and to the research
area of propositional proof complexity, I will discuss the above mentioned
lower bounds for the weak pigeonhole principle and the connections to the
hardness of proving $P \ne NP$.
"
0305003,The Ubiquitous Interactor - Device Independent Access to Mobile Services,"  The Ubiquitous Interactor (UBI) addresses the problems of design and
development that arise around services that need to be accessed from many
different devices. In UBI, the same service can present itself with different
user interfaces on different devices. This is done by separating interaction
between users and services from presentation. The interaction is kept the same
for all devices, and different presentation information is provided for
different devices. This way, tailored user interfaces for many different
devices can be created without multiplying development and maintenance work. In
this paper we describe the system design of UBI, the system implementation, and
two services implemented for the system: a calendar service and a stockbroker
service.
"
0305004,Approximate Grammar for Information Extraction,"  In this paper, we present the concept of Approximate grammar and how it can
be used to extract information from a documemt. As the structure of
informational strings cannot be defined well in a document, we cannot use the
conventional grammar rules to represent the information. Hence, the need arises
to design an approximate grammar that can be used effectively to accomplish the
task of Information extraction. Approximate grammars are a novel step in this
direction. The rules of an approximate grammar can be given by a user or the
machine can learn the rules from an annotated document. We have performed our
experiments in both the above areas and the results have been impressive.
"
0305007,Computing only minimal answers in disjunctive deductive databases,"  A method is presented for computing minimal answers in disjunctive deductive
databases under the disjunctive stable model semantics. Such answers are
constructed by repeatedly extending partial answers. Our method is complete (in
that every minimal answer can be computed) and does not admit redundancy (in
the sense that every partial answer generated can be extended to a minimal
answer), whence no non-minimal answer is generated. For stratified databases,
the method does not (necessarily) require the computation of models of the
database in their entirety. Compilation is proposed as a tool by which problems
relating to computational efficiency and the non-existence of disjunctive
stable models can be overcome. The extension of our method to other semantics
is also considered.
"
0305013,On Nonspecific Evidence,"  When simultaneously reasoning with evidences about several different events
it is necessary to separate the evidence according to event. These events
should then be handled independently. However, when propositions of evidences
are weakly specified in the sense that it may not be certain to which event
they are referring, this may not be directly possible. In this paper a
criterion for partitioning evidences into subsets representing events is
established. This criterion, derived from the conflict within each subset,
involves minimising a criterion function for the overall conflict of the
partition. An algorithm based on characteristics of the criterion function and
an iterative optimisation among partitionings of evidences is proposed.
"
0305023,Fast Dempster-Shafer clustering using a neural network structure,"  In this paper we study a problem within Dempster-Shafer theory where 2**n - 1
pieces of evidence are clustered by a neural structure into n clusters. The
clustering is done by minimizing a metaconflict function. Previously we
developed a method based on iterative optimization. However, for large scale
problems we need a method with lower computational complexity. The neural
structure was found to be effective and much faster than iterative optimization
for larger problems. While the growth in metaconflict was faster for the neural
structure compared with iterative optimization in medium sized problems, the
metaconflict per cluster and evidence was moderate. The neural structure was
able to find a global minimum over ten runs for problem sizes up to six
clusters.
"
0305026,Fast Dempster-Shafer clustering using a neural network structure,"  In this article we study a problem within Dempster-Shafer theory where 2**n -
1 pieces of evidence are clustered by a neural structure into n clusters. The
clustering is done by minimizing a metaconflict function. Previously we
developed a method based on iterative optimization. However, for large scale
problems we need a method with lower computational complexity. The neural
structure was found to be effective and much faster than iterative optimization
for larger problems. While the growth in metaconflict was faster for the neural
structure compared with iterative optimization in medium sized problems, the
metaconflict per cluster and evidence was moderate. The neural structure was
able to find a global minimum over ten runs for problem sizes up to six
clusters.
"
0305037,Power Law Distributions in Class Relationships,"  Power law distributions have been found in many natural and social phenomena,
and more recently in the source code and run-time characteristics of
Object-Oriented (OO) systems. A power law implies that small values are
extremely common, whereas large values are extremely rare. In this paper, we
identify twelve new power laws relating to the static graph structures of Java
programs. The graph structures analyzed represented different forms of OO
coupling, namely, inheritance, aggregation, interface, parameter type and
return type. Identification of these new laws provide the basis for predicting
likely features of classes in future developments. The research in this paper
ties together work in object-based coupling and World Wide Web structures.
"
0305056,Configuration Database for BaBar On-line,"  The configuration database is one of the vital systems in the BaBar on-line
system. It provides services for the different parts of the data acquisition
system and control system, which require run-time parameters. The original
design and implementation of the configuration database played a significant
role in the successful BaBar operations since the beginning of experiment.
Recent additions to the design of the configuration database provide better
means for the management of data and add new tools to simplify main
configuration tasks. We describe the design of the configuration database, its
implementation with the Objectivity/DB object-oriented database, and our
experience collected during the years of operation.
"
0305059,EU DataGRID testbed management and support at CERN,"  In this paper we report on the first two years of running the CERN testbed
site for the EU DataGRID project. The site consists of about 120 dual-processor
PCs distributed over several testbeds used for different purposes: software
development, system integration, and application tests. Activities at the site
included test productions of MonteCarlo data for LHC experiments, tutorials and
demonstrations of GRID technologies, and support for individual users analysis.
This paper focuses on node installation and configuration techniques, service
management, user support in a gridified environment, and includes
considerations on scalability and security issues and comparisons with
""traditional"" production systems, as seen from the administrator point of view.
"
0306005,The Virtual Monte Carlo,"  The concept of Virtual Monte Carlo (VMC) has been developed by the ALICE
Software Project to allow different Monte Carlo simulation programs to run
without changing the user code, such as the geometry definition, the detector
response simulation or input and output formats. Recently, the VMC classes have
been integrated into the ROOT framework, and the other relevant packages have
been separated from the AliRoot framework and can be used individually by any
other HEP project. The general concept of the VMC and its set of base classes
provided in ROOT will be presented. Existing implementations for Geant3, Geant4
and FLUKA and simple examples of usage will be described.
"
0306010,"On multiple connectedness of regions visible due to multiple diffuse
  reflections","  It is known that the region $V(s)$ of a simple polygon $P$, directly visible
(illuminable) from an internal point $s$, is simply connected. Aronov et al.
\cite{addpp981} established that the region $V_1(s)$ of a simple polygon
visible from an internal point $s$ due to at most one diffuse reflection on the
boundary of the polygon $P$, is also simply connected. In this paper we
establish that the region $V_2(s)$, visible from $s$ due to at most two diffuse
reflections may be multiply connected; we demonstrate the construction of an
$n$-sided simple polygon with a point $s$ inside it so that and the region of
$P$ visible from $s$ after at most two diffuse reflections is multiple
connected.
"
0306014,"SCRAM: Software configuration and management for the LHC Computing Grid
  project","  Recently SCRAM (Software Configuration And Management) has been adopted by
the applications area of the LHC computing grid project as baseline
configuration management and build support infrastructure tool.
  SCRAM is a software engineering tool, that supports the configuration
management and management processes for software development. It resolves the
issues of configuration definition, assembly break-down, build, project
organization, run-time environment, installation, distribution, deployment, and
source code distribution. It was designed with a focus on supporting a
distributed, multi-project development work-model.
  We will describe the underlying technology, and the solutions SCRAM offers to
the above software engineering processes, while taking a users view of the
system under configuration management.
"
0306020,"On the Verge of One Petabyte - the Story Behind the BaBar Database
  System","  The BaBar database has pioneered the use of a commercial ODBMS within the HEP
community. The unique object-oriented architecture of Objectivity/DB has made
it possible to manage over 700 terabytes of production data generated since
May'99, making the BaBar database the world's largest known database. The
ongoing development includes new features, addressing the ever-increasing
luminosity of the detector as well as other changing physics requirements.
Significant efforts are focused on reducing space requirements and operational
costs. The paper discusses our experience with developing a large scale
database system, emphasizing universal aspects which may be applied to any
large scale system, independently of underlying technology used.
"
0306024,Monitoring Systems and Services,"  The DESY Computer Center is the home of O(1000) computers supplying a wide
range of different services Monitoring such a large installation is a
challenge. After a long time running a SNMP based commercial Network Management
System, the evaluation of a new System was started. There are a lot of
different commercial and freeware products on the market, but none of them
fully satisfied all our requirements. After re-valuating our original
requirements we selected NAGIOS as our monitoring and alarming tool. After a
successful test we are in production since autumn 2002 and are extending the
service to fully support a distributed monitoring and alarming.
"
0306026,BdbServer++: A User Driven Data Location and Retrieval Tool,"  The adoption of Grid technology has the potential to greatly aid the BaBar
experiment. BdbServer was originally designed to extract copies of data from
the Objectivity/DB database at SLAC and IN2P3. With data now stored in multiple
locations in a variety of data formats, we are enhancing this tool. This will
enable users to extract selected deep copies of event collections and ship them
to the requested site using the facilities offered by the existing Grid
infrastructure. By building on the work done by various groups in BaBar, and
the European DataGrid, we have successfully expanded the capabilities of the
BdbServer software. This should provide a framework for future work in data
distribution.
"
0306042,"IGUANA Architecture, Framework and Toolkit for Interactive Graphics","  IGUANA is a generic interactive visualisation framework based on a C++
component model. It provides powerful user interface and visualisation
primitives in a way that is not tied to any particular physics experiment or
detector design. The article describes interactive visualisation tools built
using IGUANA for the CMS and D0 experiments, as well as generic GEANT4 and
GEANT3 applications. It covers features of the graphical user interfaces, 3D
and 2D graphics, high-quality vector graphics output for print media, various
textual, tabular and hierarchical data views, and integration with the
application through control panels, a command line and different
multi-threading models.
"
0306051,A data Grid testbed environment in Gigabit WAN with HPSS,"  For data analysis of large-scale experiments such as LHC Atlas and other
Japanese high energy and nuclear physics projects, we have constructed a Grid
test bed at ICEPP and KEK. These institutes are connected to national
scientific gigabit network backbone called SuperSINET. In our test bed, we have
installed NorduGrid middleware based on Globus, and connected 120TB HPSS at KEK
as a large scale data store. Atlas simulation data at ICEPP has been
transferred and accessed using SuperSINET. We have tested various performances
and characteristics of HPSS through this high speed WAN. The measurement
includes comparison between computing and storage resources are tightly coupled
with low latency LAN and long distant WAN.
"
0306061,Operational Aspects of Dealing with the Large BaBar Data Set,"  To date, the BaBar experiment has stored over 0.7PB of data in an
Objectivity/DB database. Approximately half this data-set comprises simulated
data of which more than 70% has been produced at more than 20 collaborating
institutes outside of SLAC. The operational aspects of managing such a large
data set and providing access to the physicists in a timely manner is a
challenging and complex problem. We describe the operational aspects of
managing such a large distributed data-set as well as importing and exporting
data from geographically spread BaBar collaborators. We also describe problems
common to dealing with such large datasets.
"
0306072,"The EU DataGrid Workload Management System: towards the second major
  release","  In the first phase of the European DataGrid project, the 'workload
management' package (WP1) implemented a working prototype, providing users with
an environment allowing to define and submit jobs to the Grid, and able to find
and use the ``best'' resources for these jobs. Application users have now been
experiencing for about a year now with this first release of the workload
management system. The experiences acquired, the feedback received by the user
and the need to plug new components implementing new functionalities, triggered
an update of the existing architecture. A description of this revised and
complemented workload management system is given.
"
0306073,"GridMonitor: Integration of Large Scale Facility Fabric Monitoring with
  Meta Data Service in Grid Environment","  Grid computing consists of the coordinated use of large sets of diverse,
geographically distributed resources for high performance computation.
Effective monitoring of these computing resources is extremely important to
allow efficient use on the Grid. The large number of heterogeneous computing
entities available in Grids makes the task challenging. In this work, we
describe a Grid monitoring system, called GridMonitor, that captures and makes
available the most important information from a large computing facility. The
Grid monitoring system consists of four tiers: local monitoring, archiving,
publishing and harnessing. This architecture was applied on a large scale linux
farm and network infrastructure. It can be used by many higher-level Grid
services including scheduling services and resource brokering.
"
0306080,BOA: Framework for Automated Builds,"  Managing large-scale software products is a complex software engineering
task. The automation of the software development, release and distribution
process is most beneficial in the large collaborations, where the big number of
developers, multiple platforms and distributed environment are typical factors.
This paper describes Build and Output Analyzer framework and its components
that have been developed in CMS to facilitate software maintenance and improve
software quality. The system allows to generate, control and analyze various
types of automated software builds and tests, such as regular rebuilds of the
development code, software integration for releases and installation of the
existing versions.
"
0306082,The Community Authorization Service: Status and Future,"  Virtual organizations (VOs) are communities of resource providers and users
distributed over multiple policy domains. These VOs often wish to define and
enforce consistent policies in addition to the policies of their underlying
domains. This is challenging, not only because of the problems in distributing
the policy to the domains, but also because of the fact that those domains may
each have different capabilities for enforcing the policy. The Community
Authorization Service (CAS) solves this problem by allowing resource providers
to delegate some policy authority to the VO while maintaining ultimate control
over their resources. In this paper we describe CAS and our past and current
implementations of CAS, and we discuss our plans for CAS-related research.
"
0306112,Adapting SAM for CDF,"  The CDF and D0 experiments probe the high-energy frontier and as they do so
have accumulated hundreds of Terabytes of data on the way to petabytes of data
over the next two years. The experiments have made a commitment to use the
developing Grid based on the SAM system to handle these data. The D0 SAM has
been extended for use in CDF as common patterns of design emerged to meet the
similar requirements of these experiments. The process by which the merger was
achieved is explained with particular emphasis on lessons learned concerning
the database design patterns plus realization of the use cases.
"
0306115,D0 Regional Analysis Center Concepts,"  The D0 experiment is facing many exciting challenges providing a computing
environment for its worldwide collaboration. Transparent access to data for
processing and analysis has been enabled through deployment of its SAM system
to collaborating sites and additional functionality will be provided soon with
SAMGrid components. In order to maximize access to global storage,
computational and intellectual resources, and to enable the system to scale to
the large demands soon to be realized, several strategic sites have been
identified as Regional Analysis Centers (RAC's). These sites play an expanded
role within the system. The philosophy and function of these centers is
discussed and details of their composition and operation are outlined. The plan
for future additional centers is also addressed.
"
0306127,Development of a Java Package for Matrix Programming,"  We had assembled a Java package, known as MatrixPak, of four classes for the
purpose of numerical matrix computation. The classes are matrix,
matrix_operations, StrToMatrix, and MatrixToStr; all of which are inherited
from java.lang.Object class. Class matrix defines a matrix as a two-dimensional
array of float types, and contains the following mathematical methods:
transpose, adjoint, determinant, inverse, minor and cofactor. Class
matrix_operations contains the following mathematical methods: matrix addition,
matrix subtraction, matrix multiplication, and matrix exponential. Class
StrToMatrix contains methods necessary to parse a string representation (for
example, [[2 3 4]-[5 6 7]]) of a matrix into a matrix definition, whereas class
MatrixToStr does the reverse.
"
0307004,State complexes for metamorphic robots,"  A metamorphic robotic system is an aggregate of homogeneous robot units which
can individually and selectively locomote in such a way as to change the global
shape of the system. We introduce a mathematical framework for defining and
analyzing general metamorphic robots. This formal structure, combined with
ideas from geometric group theory, leads to a natural extension of a
configuration space for metamorphic robots -- the state complex -- which is
especially adapted to parallelization. We present an algorithm for optimizing
reconfiguration sequences with respect to elapsed time. A universal geometric
property of state complexes -- non-positive curvature -- is the key to proving
convergence to the globally time-optimal solution.
"
0307011,Supporting Out-of-turn Interactions in a Multimodal Web Interface,"  Multimodal interfaces are becoming increasingly important with the advent of
mobile devices, accessibility considerations, and novel software technologies
that combine diverse interaction media. This article investigates systems
support for web browsing in a multimodal interface. Specifically, we outline
the design and implementation of a software framework that integrates hyperlink
and speech modes of interaction. Instead of viewing speech as merely an
alternative interaction medium, the framework uses it to support out-of-turn
interaction, providing a flexibility of information access not possible with
hyperlinks alone. This approach enables the creation of websites that adapt to
the needs of users, yet permits the designer fine-grained control over what
interactions to support. Design methodology, implementation details, and two
case studies are presented.
"
0307021,"Tools and Techniques for Managing Clusters for SciDAC Lattice QCD at
  Fermilab","  Fermilab operates several clusters for lattice gauge computing. Minimal
manpower is available to manage these clusters. We have written a number of
tools and developed techniques to cope with this task. We describe our tools
which use the IPMI facilities of our systems for hardware management tasks such
as remote power control, remote system resets, and health monitoring. We
discuss our techniques involving network booting for installation and upgrades
of the operating system on these computers, and for reloading BIOS and other
firmware. Finally, we discuss our tools for parallel command processing and
their use in monitoring and administrating the PBS batch queue system used on
our clusters.
"
0307027,Deterministic Sampling and Range Counting in Geometric Data Streams,"  We present memory-efficient deterministic algorithms for constructing
epsilon-nets and epsilon-approximations of streams of geometric data. Unlike
probabilistic approaches, these deterministic samples provide guaranteed bounds
on their approximation factors. We show how our deterministic samples can be
used to answer approximate online iceberg geometric queries on data streams. We
use these techniques to approximate several robust statistics of geometric data
streams, including Tukey depth, simplicial depth, regression depth, the
Thiel-Sen estimator, and the least median of squares. Our algorithms use only a
polylogarithmic amount of memory, provided the desired approximation factors
are inverse-polylogarithmic. We also include a lower bound for non-iceberg
geometric queries.
"
0307029,"The ray attack, an inefficient trial to break RSA cryptosystems","  The basic properties of RSA cryptosystems and some classical attacks on them
are described. Derived from geometric properties of the Euler functions, the
Euler function rays, a new ansatz to attack RSA cryptosystems is presented. A
resulting, albeit inefficient, algorithm is given. It essentially consists of a
loop with starting value determined by the Euler function ray and with step
width given by a function $\omega_e(n)$ being a multiple of the order
$\mathrm{ord}_n(e)$, where $e$ denotes the public key exponent and $n$ the RSA
modulus. For $n=pq$ and an estimate $r<\sqrt{pq}$ for the smaller prime factor
$p$, the running time is given by $T(e,n,r) = O((r-p)\ln e \ln n \ln r).$
"
0307033,Excellence in Computer Simulation,"  Excellent computer simulations are done for a purpose. The most valid
purposes are to explore uncharted territory, to resolve a well-posed scientific
or technical question, or to make a design choice. Stand-alone modeling can
serve the first purpose. The other two goals need a full integration of the
modeling effort into a scientific or engineering program.
  Some excellent work, much of it related to the Department of Energy
Laboratories, is reviewed. Some less happy stories are recounted.
  In the past, some of the most impressive work has involved complexity and
chaos. Prediction in a complex world requires a first principles understanding
based upon the intersection of theory, experiment and simulation.
"
0307048,"Integrating cardinal direction relations and other orientation relations
  in Qualitative Spatial Reasoning","  We propose a calculus integrating two calculi well-known in Qualitative
Spatial Reasoning (QSR): Frank's projection-based cardinal direction calculus,
and a coarser version of Freksa's relative orientation calculus. An original
constraint propagation procedure is presented, which implements the interaction
between the two integrated calculi. The importance of taking into account the
interaction is shown with a real example providing an inconsistent knowledge
base, whose inconsistency (a) cannot be detected by reasoning separately about
each of the two components of the knowledge, just because, taken separately,
each is consistent, but (b) is detected by the proposed algorithm, thanks to
the interaction knowledge propagated from each of the two compnents to the
other.
"
0307049,Limit groups and groups acting freely on $\bbR^n$-trees,"  We give a simple proof of the finite presentation of Sela's limit groups by
using free actions on $\bbR^n$-trees. We first prove that Sela's limit groups
do have a free action on an $\bbR^n$-tree. We then prove that a finitely
generated group having a free action on an $\bbR^n$-tree can be obtained from
free abelian groups and surface groups by a finite sequence of free products
and amalgamations over cyclic groups. As a corollary, such a group is finitely
presented, has a finite classifying space, its abelian subgroups are finitely
generated and contains only finitely many conjugacy classes of non-cyclic
maximal abelian subgroups.
"
0307053,"Hamevol1.0: a C++ code for differential equations based on Runge-Kutta
  algorithm. An application to matter enhanced neutrino oscillation","  We present a C++ implementation of a fifth order semi-implicit Runge-Kutta
algorithm for solving Ordinary Differential Equations. This algorithm can be
used for studying many different problems and in particular it can be applied
for computing the evolution of any system whose Hamiltonian is known. We
consider in particular the problem of calculating the neutrino oscillation
probabilities in presence of matter interactions. The time performance and the
accuracy of this implementation is competitive with respect to the other
analytical and numerical techniques used in literature. The algorithm design
and the salient features of the code are presented and discussed and some
explicit examples of code application are given.
"
0307062,Euclidean algorithms are Gaussian,"  This study provides new results about the probabilistic behaviour of a class
of Euclidean algorithms: the asymptotic distribution of a whole class of
cost-parameters associated to these algorithms is normal. For the cost
corresponding to the number of steps Hensley already has proved a Local Limit
Theorem; we give a new proof, and extend his result to other euclidean
algorithms and to a large class of digit costs, obtaining a faster, optimal,
rate of convergence. The paper is based on the dynamical systems methodology,
and the main tool is the transfer operator. In particular, we use recent
results of Dolgopyat.
"
0307068,Web Access to Cultural Heritage for the Disabled,"  Physical disabled access is something that most cultural institutions such as
museums consider very seriously. Indeed, there are normally legal requirements
to do so. However, online disabled access is still a relatively novel and
developing field. Many cultural organizations have not yet considered the
issues in depth and web developers are not necessarily experts either. The
interface for websites is normally tested with major browsers, but not with
specialist software like text to audio converters for the blind or against the
relevant accessibility and validation standards. We consider the current state
of the art in this area, especially with respect to aspects of particular
importance to the access of cultural heritage.
"
0308008,A Grid Based Architecture for High-Performance NLP,"  We describe the design and early implementation of an extensible,
component-based software architecture for natural language engineering
applications which interfaces with high performance distributed computing
services. The architecture leverages existing linguistic resource description
and discovery mechanisms based on metadata descriptions, combining these in a
compatible fashion with other software definition abstractions. Within this
architecture, application design is highly flexible, allowing disparate
components to be combined to suit the overall application functionality, and
formally described independently of processing concerns. An application
specification language provides abstraction from the programming environment
and allows ease of interface with high performance computational grids via a
broker.
"
0308026,Improvements to time bracketed authentication,"  We describe a collection of techniques whereby audiovisual or other
recordings of significant events can be made in a way that hinders
falsification, pre-dating, or post-dating by interested parties, even by the
makers and operators of the recording equipment. A central feature of these
techniques is the interplay between private information, which by its nature is
untrustworthy and susceptible to suppression or manipulation by interested
parties, and public information, which is too widely known to be manipulated by
anyone. While authenticated recordings may be infeasible to falsify, they can
be abused in other ways, such as being used for blackmail or harassment; but
susceptibility to these abuses can be reduced by encryption and secret sharing.
"
0308028,Finding Traitors in Secure Networks Using Byzantine Agreements,"  Secure networks rely upon players to maintain security and reliability.
However not every player can be assumed to have total loyalty and one must use
methods to uncover traitors in such networks. We use the original concept of
the Byzantine Generals Problem by Lamport, and the more formal Byzantine
Agreement describe by Linial, to nd traitors in secure networks. By applying
general fault-tolerance methods to develop a more formal design of secure
networks we are able to uncover traitors amongst a group of players. We also
propose methods to integrate this system with insecure channels. This new
resiliency can be applied to broadcast and peer-to-peer secure communication
systems where agents may be traitors or become unreliable due to faults.
"
0308030,"Learning in Multiagent Systems: An Introduction from a Game-Theoretic
  Perspective","  We introduce the topic of learning in multiagent systems. We first provide a
quick introduction to the field of game theory, focusing on the equilibrium
concepts of iterated dominance, and Nash equilibrium. We show some of the most
relevant findings in the theory of learning in games, including theorems on
fictitious play, replicator dynamics, and evolutionary stable strategies. The
CLRI theory and n-level learning agents are introduced as attempts to apply
some of these findings to the problem of engineering multiagent systems with
learning agents. Finally, we summarize some of the remaining challenges in the
field of learning in multiagent systems.
"
0308036,The Rich-Club Phenomenon In The Internet Topology,"  We show that the Internet topology at the Autonomous System (AS) level has a
rich--club phenomenon. The rich nodes, which are a small number of nodes with
large numbers of links, are very well connected to each other. The rich--club
is a core tier that we measured using the rich--club connectivity and the
node--node link distribution. We obtained this core tier without any heuristic
assumption between the ASes. The rich--club phenomenon is a simple qualitative
way to differentiate between power law topologies and provides a criterion for
new network models. To show this, we compared the measured rich--club of the AS
graph with networks obtained using the Barab\'asi--Albert (BA) scale--free
network model, the Fitness BA model and the Inet--3.0 model.
"
0308038,Image Analysis in Astronomy for very large vision machine,"  It is developed a very complex system (hardware/software) to detect
luminosity variations connected with the discovery of new planets outside the
Solar System. Traditional imaging approaches are very demanding in terms of
computing time; then, the implementation of an automatic vision and decision
software architecture is presented. It allows to perform an on-line
discrimination of interesting events by using two levels of triggers. A
fundamental challenge was to work with very large CCD camera (even 16k*16k
pixels) in line with very large telescopes. Then, the architecture can use a
distributed parallel network system based on a maximum of 256 standard
workstations.
"
0308044,EqRank: A Self-Consistent Equivalence Relation on Graph Vertexes,"  A new method of hierarchical clustering of graph vertexes is suggested. In
the method, the graph partition is determined with an equivalence relation
satisfying a recursive definition stating that vertexes are equivalent if the
vertexes they point to (or vertexes pointing to them) are equivalent. Iterative
application of the partitioning yields a hierarchical clustering of graph
vertexes. The method is applied to the citation graph of hep-th. The outcome is
a two-level classification scheme for the subject field presented in hep-th,
and indexing of the papers from hep-th in this scheme. A number of tests show
that the classification obtained is adequate.
"
0309004,The Structure of Information,"  A formal model of the structure of information is presented in five axioms
which define identity, containment, and joins of infons. Joins are shown to be
commutative, associative, provide inverses of infons, and, potentially, have
many identity elements, two of which are multiplicative and additive. Those two
types of join are distributive. The other identity elements are for operators
on entwined states. Multiplicative joins correspond to adding or removing new
bits to a system while additive joins correspond to a change of state. The
order or size of an infon is defined. This groundwork is intended to be used to
model continuous and discreet information structures through time, especially
in closed systems.
"
0309005,"Indexing Schemes for Similarity Search In Datasets of Short Protein
  Fragments","  We propose a family of very efficient hierarchical indexing schemes for
ungapped, score matrix-based similarity search in large datasets of short (4-12
amino acid) protein fragments. This type of similarity search has importance in
both providing a building block to more complex algorithms and for possible use
in direct biological investigations where datasets are of the order of 60
million objects. Our scheme is based on the internal geometry of the amino acid
alphabet and performs exceptionally well, for example outputting 100 nearest
neighbours to any possible fragment of length 10 after scanning on average less
than one per cent of the entire dataset.
"
0309014,Optimal Covering Tours with Turn Costs,"  We give the first algorithmic study of a class of ``covering tour'' problems
related to the geometric Traveling Salesman Problem: Find a polygonal tour for
a cutter so that it sweeps out a specified region (``pocket''), in order to
minimize a cost that depends mainly on the number of em turns. These problems
arise naturally in manufacturing applications of computational geometry to
automatic tool path generation and automatic inspection systems, as well as arc
routing (``postman'') problems with turn penalties. We prove the
NP-completeness of minimum-turn milling and give efficient approximation
algorithms for several natural versions of the problem, including a
polynomial-time approximation scheme based on a novel adaptation of the
m-guillotine method.
"
0309016,"Using Simulated Annealing to Calculate the Trembles of Trembling Hand
  Perfection","  Within the literature on non-cooperative game theory, there have been a
number of attempts to propose logorithms which will compute Nash equilibria.
Rather than derive a new algorithm, this paper shows that the family of
algorithms known as Markov chain Monte Carlo (MCMC) can be used to calculate
Nash equilibria. MCMC is a type of Monte Carlo simulation that relies on Markov
chains to ensure its regularity conditions. MCMC has been widely used
throughout the statistics and optimization literature, where variants of this
algorithm are known as simulated annealing. This paper shows that there is
interesting connection between the trembles that underlie the functioning of
this algorithm and the type of Nash refinement known as trembling hand
perfection.
"
0309019,Building a Test Collection for Speech-Driven Web Retrieval,"  This paper describes a test collection (benchmark data) for retrieval systems
driven by spoken queries. This collection was produced in the subtask of the
NTCIR-3 Web retrieval task, which was performed in a TREC-style evaluation
workshop. The search topics and document collection for the Web retrieval task
were used to produce spoken queries and language models for speech recognition,
respectively. We used this collection to evaluate the performance of our
retrieval system. Experimental results showed that (a) the use of target
documents for language modeling and (b) enhancement of the vocabulary size in
speech recognition were effective in improving the system performance.
"
0309038,A novel evolutionary formulation of the maximum independent set problem,"  We introduce a novel evolutionary formulation of the problem of finding a
maximum independent set of a graph. The new formulation is based on the
relationship that exists between a graph's independence number and its acyclic
orientations. It views such orientations as individuals and evolves them with
the aid of evolutionary operators that are very heavily based on the structure
of the graph and its acyclic orientations. The resulting heuristic has been
tested on some of the Second DIMACS Implementation Challenge benchmark graphs,
and has been found to be competitive when compared to several of the other
heuristics that have also been tested on those graphs.
"
0309040,A distributed algorithm to find k-dominating sets,"  We consider a connected undirected graph $G(n,m)$ with $n$ nodes and $m$
edges. A $k$-dominating set $D$ in $G$ is a set of nodes having the property
that every node in $G$ is at most $k$ edges away from at least one node in $D$.
Finding a $k$-dominating set of minimum size is NP-hard. We give a new
synchronous distributed algorithm to find a $k$-dominating set in $G$ of size
no greater than $\lfloor n/(k+1)\rfloor$. Our algorithm requires $O(k\log^*n)$
time and $O(m\log k+n\log k\log^*n)$ messages to run. It has the same time
complexity as the best currently known algorithm, but improves on that
algorithm's message complexity and is, in addition, conceptually simpler.
"
0309053,A Hierarchical Situation Calculus,"  A situation calculus is presented that provides a solution to the frame
problem for hierarchical situations, that is, situations that have a modular
structure in which parts of the situation behave in a relatively independent
manner. This situation calculus is given in a relational, functional, and modal
logic form. Each form permits both a single level hierarchy or a multiple level
hierarchy, giving six versions of the formalism in all, and a number of
sub-versions of these. For multiple level hierarchies, it is possible to give
equations between parts of the situation to impose additional structure on the
problem. This approach is compared to others in the literature.
"
0310004,Determination of the Topology of a Directed Network,"  We consider strongly-connected directed networks of identical synchronous,
finite-state processors with in- and out-degree uniformly bounded by a network
constant. Via a straightforward extension of Ostrovsky and Wilkerson's
Backwards Communication Algorithm in [OW], we exhibit a protocol which solves
the Global Topology Determination Problem, the problem of having the root
processor map the global topology of a network of unknown size and topology,
with running time O(ND) where N represents the number of processors and D
represents the diameter of the network. A simple counting argument suffices to
show that the Global Topology Determination Problem has time-complexity Omega(N
logN) which makes the protocol presented asymptotically time-optimal for many
large networks.
"
0310006,The Lowell Database Research Self Assessment,"  A group of senior database researchers gathers every few years to assess the
state of database research and to point out problem areas that deserve
additional focus. This report summarizes the discussion and conclusions of the
sixth ad-hoc meeting held May 4-6, 2003 in Lowell, Mass. It observes that
information management continues to be a critical component of most complex
software systems. It recommends that database researchers increase focus on:
integration of text, data, code, and streams; fusion of information from
heterogeneous data sources; reasoning about uncertain data; unsupervised data
mining for interesting correlations; information privacy; and self-adaptation
and repair.
"
0310009,"On Interference of Signals and Generalization in Feedforward Neural
  Networks","  This paper studies how the generalization ability of neurons can be affected
by mutual processing of different signals. This study is done on the basis of a
feedforward artificial neural network. The mutual processing of signals can
possibly be a good model of patterns in a set generalized by a neural network
and in effect may improve generalization. In this paper it is discussed that
the interference may also cause a highly random generalization. Adaptive
activation functions are discussed as a way of reducing that type of
generalization. A test of a feedforward neural network is performed that shows
the discussed random generalization.
"
0310026,Generalized Systematic Debugging for Attribute Grammars,"  Attribute grammars (AGs) are known to be a useful formalism for semantic
analysis and translation. However, debugging AGs is complex owing to inherent
difficulties of AGs, such as recursive grammar structure and attribute
dependency. In this paper, a new systematic method of debugging AGs is
proposed. Our approach is, in principle, based on previously proposed
algorithmic debugging of AGs, but is more general. This easily enables
integration of various query-based systematic debugging methods, including the
slice-based method. The proposed method has been implemented in Aki, a debugger
for AG description. We evaluated our new approach experimentally using Aki,
which demonstrates the usability of our debugging method.
"
0310037,Maximum dispersion and geometric maximum weight cliques,"  We consider a facility location problem, where the objective is to
``disperse'' a number of facilities, i.e., select a given number k of locations
from a discrete set of n candidates, such that the average distance between
selected locations is maximized. In particular, we present algorithmic results
for the case where vertices are represented by points in d-dimensional space,
and edge weights correspond to rectilinear distances. Problems of this type
have been considered before, with the best result being an approximation
algorithm with performance ratio 2. For the case where k is fixed, we establish
a linear-time algorithm that finds an optimal solution. For the case where k is
part of the input, we present a polynomial-time approximation scheme.
"
0310043,"Value-at-Risk and Expected Shortfall for Quadratic portfolio of
  securities with mixture of elliptic Distributed Risk Factors","  Generally, in the financial literature, the notion of quadratic VaR is
implicitly confused with the Delta-Gamma VaR, because more authors dealt with
portfolios that contains derivatives instruments.
  In this paper, we postpone to estimate the Value-at-Risk of a quadratic
portfolio of securities (i.e equities) without the Delta and Gamma greeks, when
the joint log-returns changes with multivariate elliptic distribution. We have
reduced the estimation of the quadratic VaR of such portfolio to a resolution
of one dimensional integral equation. To illustrate our method, we give special
attention to the mixture of normal and mixture of t-student distribution. For
given VaR, when joint Risk Factors changes with elliptic distribution, we show
how to estimate an Expected Shortfall .
"
0310053,"Secret Sharing for n-Colorable Graphs with Application to Public Key
  Cryptography","  At the beginning some results from the field of graph theory are presented.
Next we show how to share a secret that is proper n-coloring of the graph, with
the known structure. The graph is described and converted to the form, where
colors assigned to vertices form the number with entries from Zn. A secret
sharing scheme (SSS) for the graph coloring is proposed. The proposed method is
applied to the public-key cryptosystem called ""Polly Cracker"". In this case the
graph structure is a public key, while proper 3-colouring of the graph is a
private key. We show how to share the private key. Sharing particular
n-coloring (color-to-vertex assignment) for the known-structure graph is
presented next.
"
0310055,Mace4 Reference Manual and Guide,"  Mace4 is a program that searches for finite models of first-order formulas.
For a given domain size, all instances of the formulas over the domain are
constructed. The result is a set of ground clauses with equality. Then, a
decision procedure based on ground equational rewriting is applied. If
satisfiability is detected, one or more models are printed. Mace4 is a useful
complement to first-order theorem provers, with the prover searching for proofs
and Mace4 looking for countermodels, and it is useful for work on finite
algebras. Mace4 performs better on equational problems than did our previous
model-searching program Mace2.
"
0310061,"Local-search techniques for propositional logic extended with
  cardinality constraints","  We study local-search satisfiability solvers for propositional logic extended
with cardinality atoms, that is, expressions that provide explicit ways to
model constraints on cardinalities of sets. Adding cardinality atoms to the
language of propositional logic facilitates modeling search problems and often
results in concise encodings. We propose two ``native'' local-search solvers
for theories in the extended language. We also describe techniques to reduce
the problem to standard propositional satisfiability and allow us to use
off-the-shelf SAT solvers. We study these methods experimentally. Our general
finding is that native solvers designed specifically for the extended language
perform better than indirect methods relying on SAT solvers.
"
0310063,Logic programs with monotone cardinality atoms,"  We investigate mca-programs, that is, logic programs with clauses built of
monotone cardinality atoms of the form kX, where k is a non-negative integer
and X is a finite set of propositional atoms. We develop a theory of
mca-programs. We demonstrate that the operational concept of the one-step
provability operator generalizes to mca-programs, but the generalization
involves nondeterminism. Our main results show that the formalism of
mca-programs is a common generalization of (1) normal logic programming with
its semantics of models, supported models and stable models, (2) logic
programming with cardinality atoms and with the semantics of stable models, as
defined by Niemela, Simons and Soininen, and (3) of disjunctive logic
programming with the possible-model semantics of Sakama and Inoue.
"
0311001,"Modeling State in Software Debugging of VHDL-RTL Designs -- A
  Model-Based Diagnosis Approach","  In this paper we outline an approach of applying model-based diagnosis to the
field of automatic software debugging of hardware designs. We present our
value-level model for debugging VHDL-RTL designs and show how to localize the
erroneous component responsible for an observed misbehavior. Furthermore, we
discuss an extension of our model that supports the debugging of sequential
circuits, not only at a given point in time, but also allows for considering
the temporal behavior of VHDL-RTL designs. The introduced model is capable of
handling state inherently present in every sequential circuit. The principal
applicability of the new model is outlined briefly and we use industrial-sized
real world examples from the ISCAS'85 benchmark suite to discuss the
scalability of our approach.
"
0311031,"Towards an Intelligent Database System Founded on the SP Theory of
  Computing and Cognition","  The SP theory of computing and cognition, described in previous publications,
is an attractive model for intelligent databases because it provides a simple
but versatile format for different kinds of knowledge, it has capabilities in
artificial intelligence, and it can also function like established database
models when that is required.
  This paper describes how the SP model can emulate other models used in
database applications and compares the SP model with those other models. The
artificial intelligence capabilities of the SP model are reviewed and its
relationship with other artificial intelligence systems is described. Also
considered are ways in which current prototypes may be translated into an
'industrial strength' working system.
"
0311039,Quantum m-out-of-n Oblivious Transfer,"  In the m-out-of-n oblivious transfer (OT) model, one party Alice sends n bits
to another party Bob, Bob can get only m bits from the n bits. However, Alice
cannot know which m bits Bob received. Y.Mu[MJV02]} and Naor[Naor01] presented
classical m-out-of-n oblivious transfer based on discrete logarithm. As the
work of Shor [Shor94], the discrete logarithm can be solved in polynomial time
by quantum computers, so such OTs are unsafe to the quantum computer. In this
paper, we construct a quantum m-out-of-n OT (QOT) scheme based on the
transmission of polarized light and show that the scheme is robust to general
attacks, i.e. the QOT scheme satisfies statistical correctness and statistical
privacy.
"
0311041,S-ToPSS: Semantic Toronto Publish/Subscribe System,"  The increase in the amount of data on the Internet has led to the development
of a new generation of applications based on selective information
dissemination where, data is distributed only to interested clients. Such
applications require a new middleware architecture that can efficiently match
user interests with available information. Middleware that can satisfy this
requirement include event-based architectures such as publish-subscribe
systems. In this demonstration paper we address the problem of semantic
matching. We investigate how current publish/subscribe systems can be extended
with semantic capabilities. Our main contribution is the development and
validation (through demonstration) of a semantic pub/sub system prototype
S-ToPSS (Semantic Toronto Publish/Subscribe System).
"
0311045,"Unsupervised Grammar Induction in a Framework of Information Compression
  by Multiple Alignment, Unification and Search","  This paper describes a novel approach to grammar induction that has been
developed within a framework designed to integrate learning with other aspects
of computing, AI, mathematics and logic. This framework, called ""information
compression by multiple alignment, unification and search"" (ICMAUS), is founded
on principles of Minimum Length Encoding pioneered by Solomonoff and others.
Most of the paper describes SP70, a computer model of the ICMAUS framework that
incorporates processes for unsupervised learning of grammars. An example is
presented to show how the model can infer a plausible grammar from appropriate
input. Limitations of the current model and how they may be overcome are
briefly discussed.
"
0311046,Algebras for Agent Norm-Regulation,"  An abstract architecture for idealized multi-agent systems whose behaviour is
regulated by normative systems is developed and discussed. Agent choices are
determined partially by the preference ordering of possible states and
partially by normative considerations: The agent chooses that act which leads
to the best outcome of all permissible actions. If an action is non-permissible
depends on if the result of performing that action leads to a state satisfying
a condition which is forbidden, according to the norms regulating the
multi-agent system. This idea is formalized by defining set-theoretic
predicates characterizing multi-agent systems. The definition of the predicate
uses decision theory, the Kanger-Lindahl theory of normative positions, and an
algebraic representation of normative systems.
"
0311047,"I know what you mean: semantic issues in Internet-scale
  publish/subscribe systems","  In recent years, the amount of information on the Internet has increased
exponentially developing great interest in selective information dissemination
systems. The publish/subscribe paradigm is particularly suited for designing
systems for routing information and requests according to their content
throughout wide-area network of brokers. Current publish/subscribe systems use
limited syntax-based content routing but since publishers and subscribers are
anonymous and decoupled in time, space and location, often over wide-area
network boundary, they do not necessarily speak the same language.
Consequently, adding semantics to current publish/subscribe systems is
important. In this paper we identify and examine the issues in developing
semantic-based content routing for publish/subscribe broker networks.
"
0311053,Weak Bezout inequality for D-modules,"  Let $\{w_{i,j}\}_{1\leq i\leq n, 1\leq j\leq s} \subset
L_m=F(X_1,...,X_m)[{\partial \over \partial X_1},..., {\partial \over \partial
X_m}]$ be linear partial differential operators of orders with respect to
${\partial \over \partial X_1},..., {\partial \over \partial X_m}$ at most $d$.
We prove an upper bound n(4m^2d\min\{n,s\})^{4^{m-t-1}(2(m-t))} on the leading
coefficient of the Hilbert-Kolchin polynomial of the left $L_m$-module
$<\{w_{1,j}, ..., w_{n,j}\}_{1\leq j \leq s} > \subset L_m^n$ having the
differential type $t$ (also being equal to the degree of the Hilbert-Kolchin
polynomial). The main technical tool is the complexity bound on solving systems
of linear equations over {\it algebras of fractions} of the form
$$L_m(F[X_1,..., X_m, {\partial \over \partial X_1},..., {\partial \over
\partial X_k}])^{-1}.$$
"
0312012,Methods to Model-Check Parallel Systems Software,"  We report on an effort to develop methodologies for formal verification of
parts of the Multi-Purpose Daemon (MPD) parallel process management system. MPD
is a distributed collection of communicating processes. While the individual
components of the collection execute simple algorithms, their interaction leads
to unexpected errors that are difficult to uncover by conventional means. Two
verification approaches are discussed here: the standard model checking
approach using the software model checker SPIN and the nonstandard use of a
general-purpose first-order resolution-style theorem prover OTTER to conduct
the traditional state space exploration. We compare modeling methodology and
analyze performance and scalability of the two methods with respect to
verification of MPD.
"
0312019,Verification of recursive parallel systems,"  In this paper we consider the problem of proving properties of infinite
behaviour of formalisms suitable to describe (infinite state) systems with
recursion and parallelism. As a formal setting, we consider the framework of
Process Rewriting Systems (PRSs). For a meaningfull fragment of PRSs, allowing
to accommodate both Pushdown Automata and Petri Nets, we state decidability
results for a class of properties about infinite derivations (infinite term
rewritings). The given results can be exploited for the automatic verification
of some classes of linear time properties of infinite state systems described
by PRSs. In order to exemplify the assessed results, we introduce a meaningful
automaton based formalism which allows to express both recursion and
multi--treading.
"
0312022,"GridEmail: A Case for Economically Regulated Internet-based
  Interpersonal Communications","  Email has emerged as a dominant form of electronic communication between
people. Spam is a major problem for email users, with estimates of up to 56% of
email falling into that category. Control of Spam is being attempted with
technical and legislative methods. In this paper we look at email and spam from
a supply-demand perspective. We propose Gridemail, an email system based on an
economy of communicating parties, where participants? motivations are
represented as pricing policies and profiles. This system is expected to help
people regulate their personal communications to suit their conditions, and
help in removing unwanted messages.
"
0312023,"Inferring Termination Conditions for Logic Programs using Backwards
  Analysis","  This paper focuses on the inference of modes for which a logic program is
guaranteed to terminate. This generalises traditional termination analysis
where an analyser tries to verify termination for a specified mode. Our
contribution is a methodology in which components of traditional termination
analysis are combined with backwards analysis to obtain an analyser for
termination inference. We identify a condition on the components of the
analyser which guarantees that termination inference will infer all modes which
can be checked to terminate. The application of this methodology to enhance a
traditional termination analyser to perform also termination inference is
demonstrated.
"
0312024,Evolution: Google vs. DRIS,"  This paper gives an absolute new search system that builds the information
retrieval infrastructure for Internet. Now most search engine companies are
mainly concerned with how to make profit from company users by advertisement
and ranking prominence, but never consider what its real customers will feel.
Few web search engines can sell billions dollars just at the cost of
inconvenience of most Internet users, but not its high quality of search
service. When we have to bear the bothersome advertisements in the awful
results and have no choices, Internet as the kind of public good will surely be
undermined. If current Internet can't fully ensure our right to know, it may
need some sound improvements or a revolution.
"
0312027,An Open Ended Tree,"  An open ended list is a well known data structure in Prolog programs. It is
frequently used to represent a value changing over time, while this value is
referred to from several places in the data structure of the application. A
weak point in this technique is that the time complexity is linear in the
number of updates to the value represented by the open ended list. In this
programming pearl we present a variant of the open ended list, namely an open
ended tree, with an update and access time complexity logarithmic in the number
of updates to the value.
"
0312030,"CSIEC (Computer Simulator in Educational Communication): An Intelligent
  Web-Based Teaching System for Foreign Language Learning","  In this paper we present an innovative intelligent web-based computer-aided
instruction system for foreign language learning: CSIEC (Computer Simulator in
Educational Communication). This system can not only grammatically understand
the sentences in English given from the users via Internet, but also reasonably
and individually speak with the users. At first the related works in this
research field are analyzed. Then we introduce the system goals and the system
framework, i.e., the natural language understanding mechanism (NLML, NLOMJ and
NLDB) and the communicational response (CR). Finally we give the syntactic and
semantic content of this instruction system, i.e. some important notations of
English grammar used in it and their relations with the NLOMJ.
"
0312038,Responsibility and blame: a structural-model approach,"  Causality is typically treated an all-or-nothing concept; either A is a cause
of B or it is not. We extend the definition of causality introduced by Halpern
and Pearl [2001] to take into account the degree of responsibility of A for B.
For example, if someone wins an election 11--0, then each person who votes for
him is less responsible for the victory than if he had won 6--5. We then define
a notion of degree of blame, which takes into account an agent's epistemic
state. Roughly speaking, the degree of blame of A for B is the expected degree
of responsibility of A for B, taken over the epistemic state of an agent.
"
0312042,Declarative Semantics for Active Rules,"  In this paper we analyze declarative deterministic and non-deterministic
semantics for active rules. In particular we consider several (partial) stable
model semantics, previously defined for deductive rules, such as well-founded,
max deterministic, unique total stable model, total stable model, and maximal
stable model semantics. The semantics of an active program AP is given by first
rewriting it into a deductive program P, then computing a model M defining the
declarative semantics of P and, finally, applying `consistent' updates
contained in M to the source database. The framework we propose permits a
natural integration of deductive and active rules and can also be applied to
queries with function symbols or to queries over infinite databases.
"
0312051,"Towards Automated Generation of Scripted Dialogue: Some Time-Honoured
  Strategies","  The main aim of this paper is to introduce automated generation of scripted
dialogue as a worthwhile topic of investigation. In particular the fact that
scripted dialogue involves two layers of communication, i.e., uni-directional
communication between the author and the audience of a scripted dialogue and
bi-directional pretended communication between the characters featuring in the
dialogue, is argued to raise some interesting issues. Our hope is that the
combined study of the two layers will forge links between research in text
generation and dialogue processing. The paper presents a first attempt at
creating such links by studying three types of strategies for the automated
generation of scripted dialogue. The strategies are derived from examples of
human-authored and naturally occurring dialogue.
"
0312056,The Geometric Thickness of Low Degree Graphs,"  We prove that the geometric thickness of graphs whose maximum degree is no
more than four is two. All of our algorithms run in O(n) time, where n is the
number of vertices in the graph. In our proofs, we present an embedding
algorithm for graphs with maximum degree three that uses an n x n grid and a
more complex algorithm for embedding a graph with maximum degree four. We also
show a variation using orthogonal edges for maximum degree four graphs that
also uses an n x n grid. The results have implications in graph theory, graph
drawing, and VLSI design.
"
0312058,Acquiring Lexical Paraphrases from a Single Corpus,"  This paper studies the potential of identifying lexical paraphrases within a
single corpus, focusing on the extraction of verb paraphrases. Most previous
approaches detect individual paraphrase instances within a pair (or set) of
comparable corpora, each of them containing roughly the same information, and
rely on the substantial level of correspondence of such corpora. We present a
novel method that successfully detects isolated paraphrase instances within a
single corpus without relying on any a-priori structure and information. A
comparison suggests that an instance-based approach may be combined with a
vector based approach in order to assess better the paraphrase likelihood for
many verb pairs.
"
0401006,"Cluster computing performances using virtual processors and mathematical
  software","  In this paper I describe some results on the use of virtual processors
technology for parallelize some SPMD computational programs in a cluster
environment. The tested technology is the INTEL Hyper Threading on real
processors, and the programs are MATLAB 6.5 Release 13 scripts for floating
points computation. By the use of this technology, I tested that a cluster can
run with benefit a number of concurrent processes double the amount of physical
processors. The conclusions of the work concern on the utility and limits of
the used approach. The main result is that using virtual processors is a good
technique for improving parallel programs not only for memory-based
computations, but in the case of massive disk-storage operations too.
"
0401009,Unifying Computing and Cognition: The SP Theory and its Applications,"  This book develops the conjecture that all kinds of information processing in
computers and in brains may usefully be understood as ""information compression
by multiple alignment, unification and search"". This ""SP theory"", which has
been under development since 1987, provides a unified view of such things as
the workings of a universal Turing machine, the nature of 'knowledge', the
interpretation and production of natural language, pattern recognition and
best-match information retrieval, several kinds of probabilistic reasoning,
planning and problem solving, unsupervised learning, and a range of concepts in
mathematics and logic. The theory also provides a basis for the design of an
'SP' computer with several potential advantages compared with traditional
digital computers.
"
0401014,Nested Intervals with Farey Fractions,"  Relational Databases are universally conceived as an advance over their
predecessors Network and Hierarchical models. Superior in every querying
respect, they turned out to be surprisingly incomplete when modeling transitive
dependencies. Almost every couple of months a question how to model a tree in
the database surfaces at comp.database.theory newsgroup. This article completes
a series of articles exploring Nested Intervals Model. Previous articles
introduced tree encoding with Binary Rational Numbers. However, binary encoding
grows exponentially, both in breadth and in depth. In this article, we'll
leverage Farey fractions in order to overcome this problem. We'll also
demonstrate that our implementation scales to a tree with 1M nodes.
"
0401017,Better Foreground Segmentation Through Graph Cuts,"  For many tracking and surveillance applications, background subtraction
provides an effective means of segmenting objects moving in front of a static
background. Researchers have traditionally used combinations of morphological
operations to remove the noise inherent in the background-subtracted result.
Such techniques can effectively isolate foreground objects, but tend to lose
fidelity around the borders of the segmentation, especially for noisy input.
This paper explores the use of a minimum graph cut algorithm to segment the
foreground, resulting in qualitatively and quantitiatively cleaner
segmentations. Experiments on both artificial and real data show that the
graph-based method reduces the error around segmented foreground objects. A
MATLAB code implementation is available at
http://www.cs.smith.edu/~nhowe/research/code/#fgseg
"
0401029,"Dynamic Linking of Smart Digital Objects Based on User Navigation
  Patterns","  We discuss a methodology to dynamically generate links among digital objects
by means of an unsupervised learning mechanism which analyzes user link
traversal patterns. We performed an experiment with a test bed of 150 complex
data objects, referred to as buckets. Each bucket manages its own content,
provides methods to interact with users and individually maintains a set of
links to other buckets. We demonstrate that buckets were capable of dynamically
adjusting their links to other buckets according to user link selections,
thereby generating a meaningful network of bucket relations. Our results
indicate such adaptive networks of linked buckets approximate the collective
link preferences of a community of user
"
0402004,Baptista-type chaotic cryptosystems: Problems and countermeasures,"  In 1998, M. S. Baptista proposed a chaotic cryptosystem, which has attracted
much attention from the chaotic cryptography community: some of its
modifications and also attacks have been reported in recent years. In [Phys.
Lett. A 307 (2003) 22], we suggested a method to enhance the security of
Baptista-type cryptosystem, which can successfully resist all proposed attacks.
However, the enhanced Baptista-type cryptosystem has a nontrivial defect, which
produces errors in the decrypted data with a generally small but nonzero
probability, and the consequent error propagation exists. In this Letter, we
analyze this defect and discuss how to rectify it. In addition, we point out
some newly-found problems existing in all Baptista-type cryptosystems and
consequently propose corresponding countermeasures.
"
0402010,Encapsulation for Practical Simplification Procedures,"  ACL2 was used to prove properties of two simplification procedures. The
procedures differ in complexity but solve the same programming problem that
arises in the context of a resolution/paramodulation theorem proving system.
Term rewriting is at the core of the two procedures, but details of the
rewriting procedure itself are irrelevant. The ACL2 encapsulate construct was
used to assert the existence of the rewriting function and to state some of its
properties. Termination, irreducibility, and soundness properties were
established for each procedure. The availability of the encapsulation mechanism
in ACL2 is considered essential to rapid and efficient verification of this
kind of algorithm.
"
0402011,Accurately modeling the Internet topology,"  Based on measurements of the Internet topology data, we found out that there
are two mechanisms which are necessary for the correct modeling of the Internet
topology at the Autonomous Systems (AS) level: the Interactive Growth of new
nodes and new internal links, and a nonlinear preferential attachment, where
the preference probability is described by a positive-feedback mechanism. Based
on the above mechanisms, we introduce the Positive-Feedback Preference (PFP)
model which accurately reproduces many topological properties of the AS-level
Internet, including: degree distribution, rich-club connectivity, the maximum
degree, shortest path length, short cycles, disassortative mixing and
betweenness centrality. The PFP model is a phenomenological model which
provides a novel insight into the evolutionary dynamics of real complex
networks.
"
0402012,"A Knowledge-Theoretic Analysis of Uniform Distributed Coordination and
  Failure Detectors","  It is shown that, in a precise sense, if there is no bound on the number of
faulty processes in a system with unreliable but fair communication, Uniform
Distributed Coordination (UDC) can be attained if and only if a system has
perfect failure detectors. This result is generalized to the case where there
is a bound t on the number of faulty processes. It is shown that a certain type
of generalized failure detector is necessary and sufficient for achieving UDC
in a context with at most t faulty processes. Reasoning about processes'
knowledge as to which other processes are faulty plays a key role in the
analysis.
"
0402013,"Corollaries on the fixpoint completion: studying the stable semantics by
  means of the Clark completion","  The fixpoint completion fix(P) of a normal logic program P is a program
transformation such that the stable models of P are exactly the models of the
Clark completion of fix(P). This is well-known and was studied by Dung and
Kanchanasut (1989). The correspondence, however, goes much further: The
Gelfond-Lifschitz operator of P coincides with the immediate consequence
operator of fix(P), as shown by Wendt (2002), and even carries over to standard
operators used for characterizing the well-founded and the Kripke-Kleene
semantics. We will apply this knowledge to the study of the stable semantics,
and this will allow us to almost effortlessly derive new results concerning
fixed-point and metric-based semantics, and neural-symbolic integration.
"
0402021,A Numerical Example on the Principles of Stochastic Discrimination,"  Studies on ensemble methods for classification suffer from the difficulty of
modeling the complementary strengths of the components. Kleinberg's theory of
stochastic discrimination (SD) addresses this rigorously via mathematical
notions of enrichment, uniformity, and projectability of an ensemble. We
explain these concepts via a very simple numerical example that captures the
basic principles of the SD theory and method. We focus on a fundamental
symmetry in point set covering that is the key observation leading to the
foundation of the theory. We believe a better understanding of the SD method
will lead to developments of better tools for analyzing other ensemble methods.
"
0402035,Memory As A Monadic Control Construct In Problem-Solving,"  Recent advances in programming languages study and design have established a
standard way of grounding computational systems representation in category
theory. These formal results led to a better understanding of issues of control
and side-effects in functional and imperative languages. This framework can be
successfully applied to the investigation of the performance of Artificial
Intelligence (AI) inference and cognitive systems. In this paper, we delineate
a categorical formalisation of memory as a control structure driving
performance in inference systems. Abstracting away control mechanisms from
three widely used representations of memory in cognitive systems (scripts,
production rules and clusters) we explain how categorical triples capture the
interaction between learning and problem-solving.
"
0402037,The pre-history of quantum computation,"  The main ideas behind developments in the theory and technology of quantum
computation were formulated in the late 1970s and early 1980s by two physicists
in the West and a mathematician in the former Soviet Union. It is not generally
known in the West that the subject has roots in the Russian technical
literature. The author hopes to present as impartial a synthesis as possible of
the early history of thought on this subject. The role of reversible and
irreversible computational processes is examined briefly as it relates to the
origins of quantum computing and the so-called Information Paradox in physics.
"
0402044,"A General Framework for Bounds for Higher-Dimensional Orthogonal Packing
  Problems","  Higher-dimensional orthogonal packing problems have a wide range of practical
applications, including packing, cutting, and scheduling. In the context of a
branch-and-bound framework for solving these packing problems to optimality, it
is of crucial importance to have good and easy bounds for an optimal solution.
Previous efforts have produced a number of special classes of such bounds.
Unfortunately, some of these bounds are somewhat complicated and hard to
generalize. We present a new approach for obtaining classes of lower bounds for
higher-dimensional packing problems; our bounds improve and simplify several
well-known bounds from previous literature. In addition, our approach provides
an easy framework for proving correctness of new bounds.
"
0402054,On the Security of the Yi-Tan-Siew Chaos-Based Cipher,"  This paper presents a comprehensive analysis on the security of the
Yi-Tan-Siew chaotic cipher proposed in [IEEE TCAS-I 49(12):1826-1829 (2002)]. A
differential chosen-plaintext attack and a differential chosen-ciphertext
attack are suggested to break the sub-key K, under the assumption that the time
stamp can be altered by the attacker, which is reasonable in such attacks.
Also, some security Problems about the sub-keys $\alpha$ and $\beta$ are
clarified, from both theoretical and experimental points of view. Further
analysis shows that the security of this cipher is independent of the use of
the chaotic tent map, once the sub-key $K$ is removed via the proposed
suggested differential chosen-plaintext attack.
"
0402059,Light types for polynomial time computation in lambda-calculus,"  We propose a new type system for lambda-calculus ensuring that well-typed
programs can be executed in polynomial time: Dual light affine logic (DLAL).
  DLAL has a simple type language with a linear and an intuitionistic type
arrow, and one modality. It corresponds to a fragment of Light affine logic
(LAL). We show that contrarily to LAL, DLAL ensures good properties on
lambda-terms: subject reduction is satisfied and a well-typed term admits a
polynomial bound on the reduction by any strategy. We establish that as LAL,
DLAL allows to represent all polytime functions. Finally we give a type
inference procedure for propositional DLAL.
"
0403013,Predictable Software -- A Shortcut to Dependable Computing ?,"  Many dependability techniques expect certain behaviors from the underlying
subsystems and fail in chaotic ways if these expectations are not met. Under
expected circumstances, however, software tends to work quite well. This paper
suggests that, instead of fixing elusive bugs or rewriting software, we improve
the predictability of conditions faced by our programs. This approach might be
a cheaper and faster way to improve dependability of software. After
identifying some of the common triggers of unpredictability, the paper
describes three engineering principles that hold promise in combating
unpredictability, suggests a way to benchmark predictability, and outlines a
brief research agenda.
"
0403014,Search Efficiency in Indexing Structures for Similarity Searching,"  Similarity searching finds application in a wide variety of domains including
multilingual databases, computational biology, pattern recognition and text
retrieval. Similarity is measured in terms of a distance function, edit
distance, in general metric spaces, which is expensive to compute. Indexing
techniques can be used reduce the number of distance computations. We present
an analysis of various existing similarity indexing structures for the same.
The performance obtained using the index structures studied was found to be
unsatisfactory . We propose an indexing technique that combines the features of
clustering with M tree(MTB) and the results indicate that this gives better
performance.
"
0403015,Belle Computing System,"  We describe the present status of the computing system in the Belle
experiment at the KEKB $e^+e^-$ asymmetric-energy collider. So far, we have
logged more than 160 fb$^{-1}$ of data, corresponding to the world's largest
data sample of 170M $B\bar{B}$ pairs at the $\Upsilon(4S)$ energy region. A
large amount of event data has to be processed to produce an analysis event
sample in a timely fashion. In addition, Monte Carlo events have to be created
to control systematic errors accurately. This requires stable and efficient
usage of computing resources. Here we review our computing model and then
describe how we efficiently proceed DST/MC productions in our system.
"
0403018,The World Wide Telescope: An Archetype for Online Science,"  Most scientific data will never be directly examined by scientists; rather it
will be put into online databases where it will be analyzed and summarized by
computer programs. Scientists increasingly see their instruments through online
scientific archives and analysis tools, rather than examining the raw data.
Today this analysis is primarily driven by scientists asking queries, but
scientific archives are becoming active databases that self-organize and
recognize interesting and anomalous facts as data arrives. In some fields, data
from many different archives can be cross-correlated to produce new insights.
Astronomy presents an excellent example of these trends; and, federating
Astronomy archives presents interesting challenges for computer scientists.
"
0403028,"An Application of Rational Trees in a Logic Programming Interpreter for
  a Procedural Language","  We describe here a simple application of rational trees to the implementation
of an interpreter for a procedural language written in a logic programming
language. This is possible in languages designed to support rational trees
(such as Prolog II and its descendants), but also in traditional Prolog, whose
data structures are initially based on Herbrand terms, but in which
implementations often omit the occurs check needed to avoid the creation of
infinite data structures. We provide code implementing two interpreters, one of
which needs non-occurs-check unification, which makes it faster (and more
economic). We provide experimental data supporting this, and we argue that
rational trees are interesting enough as to receive thorough support inside the
language.
"
0403034,Phantom Types and Subtyping,"  We investigate a technique from the literature, called the phantom-types
technique, that uses parametric polymorphism, type constraints, and unification
of polymorphic types to model a subtyping hierarchy. Hindley-Milner type
systems, such as the one found in Standard ML, can be used to enforce the
subtyping relation, at least for first-order values. We show that this
technique can be used to encode any finite subtyping hierarchy (including
hierarchies arising from multiple interface inheritance). We formally
demonstrate the suitability of the phantom-types technique for capturing
first-order subtyping by exhibiting a type-preserving translation from a simple
calculus with bounded polymorphism to a calculus embodying the type system of
SML.
"
0403038,Tournament versus Fitness Uniform Selection,"  In evolutionary algorithms a critical parameter that must be tuned is that of
selection pressure. If it is set too low then the rate of convergence towards
the optimum is likely to be slow. Alternatively if the selection pressure is
set too high the system is likely to become stuck in a local optimum due to a
loss of diversity in the population. The recent Fitness Uniform Selection
Scheme (FUSS) is a conceptually simple but somewhat radical approach to
addressing this problem - rather than biasing the selection towards higher
fitness, FUSS biases selection towards sparsely populated fitness levels. In
this paper we compare the relative performance of FUSS with the well known
tournament selection scheme on a range of problems.
"
0404004,Dealing With Curious Players in Secure Networks,"  In secure communications networks there are a great number of user
behavioural problems, which need to be dealt with. Curious players pose a very
real and serious threat to the integrity of such a network. By traversing a
network a Curious player could uncover secret information, which that user has
no need to know, by simply posing as a loyalty check. Loyalty checks are done
simply to gauge the integrity of the network with respect to players who act in
a malicious manner. We wish to propose a method, which can deal with Curious
players trying to obtain ""Need to Know"" information using a combined
Fault-tolerant, Cryptographic and Game Theoretic Approach.
"
0404010,On the universality of rank distributions of website popularity,"  We present an extensive analysis of long-term statistics of the queries to
websites using logs collected on several web caches in Russian academic
networks and on US IRCache caches. We check the sensitivity of the statistics
to several parameters: (1) duration of data collection, (2) geographical
location of the cache server collecting data, and (3) the year of data
collection. We propose a two-parameter modification of the Zipf law and
interpret the parameters. We find that the rank distribution of websites is
stable when approximated by the modified Zipf law. We suggest that website
popularity may be a universal property of Internet.
"
0404018,NLML--a Markup Language to Describe the Unlimited English Grammar,"  In this paper we present NLML (Natural Language Markup Language), a markup
language to describe the syntactic and semantic structure of any grammatically
correct English expression. At first the related works are analyzed to
demonstrate the necessity of the NLML: simple form, easy management and direct
storage. Then the description of the English grammar with NLML is introduced in
details in three levels: sentences (with different complexities, voices, moods,
and tenses), clause (relative clause and noun clause) and phrase (noun phrase,
verb phrase, prepositional phrase, adjective phrase, adverb phrase and
predicate phrase). At last the application fields of the NLML in NLP are shown
with two typical examples: NLOJM (Natural Language Object Modal in Java) and
NLDB (Natural Language Database).
"
0404019,Optimizing genetic algorithm strategies for evolving networks,"  This paper explores the use of genetic algorithms for the design of networks,
where the demands on the network fluctuate in time. For varying network
constraints, we find the best network using the standard genetic algorithm
operators such as inversion, mutation and crossover. We also examine how the
choice of genetic algorithm operators affects the quality of the best network
found. Such networks typically contain redundancy in servers, where several
servers perform the same task and pleiotropy, where servers perform multiple
tasks. We explore this trade-off between pleiotropy versus redundancy on the
cost versus reliability as a measure of the quality of the network.
"
0404026,DAB Content Annotation and Receiver Hardware Control with XML,"  The Eureka-147 Digital Audio Broadcasting (DAB) standard defines the 'dynamic
labels' data field for holding information about the transmission content.
However, this information does not follow a well-defined structure since it is
designed to carry text for direct output to displays, for human interpretation.
This poses a problem when machine interpretation of DAB content information is
desired. Extensible Markup Language (XML) was developed to allow for the
well-defined, structured machine-to-machine exchange of data over computer
networks. This article proposes a novel technique of machine-interpretable DAB
content annotation and receiver hardware control, involving the utilisation of
XML as metadata in the transmitted DAB frames.
"
0404033,The Persistent Buffer Tree : An I/O-efficient Index for Temporal Data,"  In a variety of applications, we need to keep track of the development of a
data set over time. For maintaining and querying this multi version data
I/O-efficiently, external memory data structures are required. In this paper,
we present a probabilistic self-balancing persistent data structure in external
memory called the persistent buffer tree, which supports insertions, updates
and deletions of data items at the present version and range queries for any
version, past or present. The persistent buffer tree is I/O-optimal in the
sense that the expected amortized I/O performance bounds are asymptotically the
same as the deterministic amortized bounds of the (single version) buffer tree
in the worst case.
"
0404035,Elements for Response Time Statistics in ERP Transaction Systems,"  We present some measurements and ideas for response time statistics in ERP
systems. It is shown that the response time distribution of a given transaction
in a given system is generically a log-normal distribution or, in some
situations, a sum of two or more log-normal distributions. We present some
arguments for this form of the distribution based on heuristic rules for
response times, and we show data from performance measurements in actual
systems to support the log-normal form. Deviations of the log-normal form can
often be traced back to performance problems in the system. Consequences for
the interpretation of response time data and for service level agreements are
discussed.
"
0404036,Online Searching with an Autonomous Robot,"  We discuss online strategies for visibility-based searching for an object
hidden behind a corner, using Kurt3D, a real autonomous mobile robot. This task
is closely related to a number of well-studied problems. Our robot uses a
three-dimensional laser scanner in a stop, scan, plan, go fashion for building
a virtual three-dimensional environment. Besides planning trajectories and
avoiding obstacles, Kurt3D is capable of identifying objects like a chair. We
derive a practically useful and asymptotically optimal strategy that guarantees
a competitive ratio of 2, which differs remarkably from the well-studied
scenario without the need of stopping for surveying the environment. Our
strategy is used by Kurt3D, documented in a separate video.
"
0404039,"Algorithms for Estimating Information Distance with Application to
  Bioinformatics and Linguistics","  After reviewing unnormalized and normalized information distances based on
incomputable notions of Kolmogorov complexity, we discuss how Kolmogorov
complexity can be approximated by data compression algorithms. We argue that
optimal algorithms for data compression with side information can be
successfully used to approximate the normalized distance. Next, we discuss an
alternative information distance, which is based on relative entropy rate (also
known as Kullback-Leibler divergence), and compression-based algorithms for its
estimation. Based on available biological and linguistic data, we arrive to
unexpected conclusion that in Bioinformatics and Computational Linguistics this
alternative distance is more relevant and important than the ones based on
Kolmogorov complexity.
"
0404045,"Speculation on graph computation architectures and computing via
  synchronization","  A speculative overview of a future topic of research. The paper is a
collection of ideas concerning two related areas:
  1) Graph computation machines (""computing with graphs""). This is the class of
models of computation in which the state of the computation is represented as a
graph or network.
  2) Arc-based neural networks, which store information not as activation in
the nodes, but rather by adding and deleting arcs. Sometimes the arcs may be
interpreted as synchronization.
  Warnings to readers: this is not the sort of thing that one might submit to a
journal or conference. No proofs are presented. The presentation is informal,
and written at an introductory level. You'll probably want to wait for a more
concise presentation.
"
0404049,"Exploiting Cross-Document Relations for Multi-document Evolving
  Summarization","  This paper presents a methodology for summarization from multiple documents
which are about a specific topic. It is based on the specification and
identification of the cross-document relations that occur among textual
elements within those documents. Our methodology involves the specification of
the topic-specific entities, the messages conveyed for the specific entities by
certain textual elements and the specification of the relations that can hold
among these messages. The above resources are necessary for setting up a
specific topic for our query-based summarization approach which uses these
resources to identify the query-specific messages within the documents and the
query-specific relations that connect these messages across documents.
"
0405003,"Model checking for Process Rewrite Systems and a class of action--based
  regular properties","  We consider the model checking problem for Process Rewrite Systems (PRSs), an
infinite-state formalism (non Turing-powerful) which subsumes many common
models such as Pushdown Processes and Petri Nets. PRSs can be adopted as formal
models for programs with dynamic creation and synchronization of concurrent
processes, and with recursive procedures. The model-checking problem for PRSs
and action-based linear temporal logic (ALTL) is undecidable. However,
decidability for some interesting fragment of ALTL remains an open question. In
this paper we state decidability results concerning generalized acceptance
properties about infinite derivations (infinite term rewriting) in PRSs. As a
consequence, we obtain decidability of the model-checking (restricted to
infinite runs) for PRSs and a meaningful fragment of ALTL.
"
0405016,Intrusion Detection Systems Using Adaptive Regression Splines,"  Past few years have witnessed a growing recognition of intelligent techniques
for the construction of efficient and reliable intrusion detection systems. Due
to increasing incidents of cyber attacks, building effective intrusion
detection systems (IDS) are essential for protecting information systems
security, and yet it remains an elusive goal and a great challenge. In this
paper, we report a performance analysis between Multivariate Adaptive
Regression Splines (MARS), neural networks and support vector machines. The
MARS procedure builds flexible regression models by fitting separate splines to
distinct intervals of the predictor variables. A brief comparison of different
neural network learning algorithms is also given.
"
0405021,Computing Multi-Homogeneous Bezout Numbers is Hard,"  The multi-homogeneous Bezout number is a bound for the number of solutions of
a system of multi-homogeneous polynomial equations, in a suitable product of
projective spaces.
  Given an arbitrary, not necessarily multi-homogeneous system, one can ask for
the optimal multi-homogenization that would minimize the Bezout number.
  In this paper, it is proved that the problem of computing, or even estimating
the optimal multi-homogeneous Bezout number is actually NP-hard.
  In terms of approximation theory for combinatorial optimization, the problem
of computing the best multi-homogeneous structure does not belong to APX,
unless P = NP.
  Moreover, polynomial time algorithms for estimating the minimal
multi-homogeneous Bezout number up to a fixed factor cannot exist even in a
randomized setting, unless BPP contains NP.
"
0405026,A Concurrent Fuzzy-Neural Network Approach for Decision Support Systems,"  Decision-making is a process of choosing among alternative courses of action
for solving complicated problems where multi-criteria objectives are involved.
The past few years have witnessed a growing recognition of Soft Computing
technologies that underlie the conception, design and utilization of
intelligent systems. Several works have been done where engineers and
scientists have applied intelligent techniques and heuristics to obtain optimal
decisions from imprecise information. In this paper, we present a concurrent
fuzzy-neural network approach combining unsupervised and supervised learning
techniques to develop the Tactical Air Combat Decision Support System (TACDSS).
Experiment results clearly demonstrate the efficiency of the proposed
technique.
"
0405029,A New Computational Framework For 2D Shape-Enclosing Contours,"  In this paper, a new framework for one-dimensional contour extraction from
discrete two-dimensional data sets is presented. Contour extraction is
important in many scientific fields such as digital image processing, computer
vision, pattern recognition, etc. This novel framework includes (but is not
limited to) algorithms for dilated contour extraction, contour displacement,
shape skeleton extraction, contour continuation, shape feature based contour
refinement and contour simplification. Many of the new techniques depend
strongly on the application of a Delaunay tessellation. In order to demonstrate
the versatility of this novel toolbox approach, the contour extraction
techniques presented here are applied to scientific problems in material
science, biology and heavy ion physics.
"
0405031,"Adaptation of Mamdani Fuzzy Inference System Using Neuro - Genetic
  Approach for Tactical Air Combat Decision Support System","  Normally a decision support system is build to solve problem where
multi-criteria decisions are involved. The knowledge base is the vital part of
the decision support containing the information or data that is used in
decision-making process. This is the field where engineers and scientists have
applied several intelligent techniques and heuristics to obtain optimal
decisions from imprecise information. In this paper, we present a hybrid
neuro-genetic learning approach for the adaptation a Mamdani fuzzy inference
system for the Tactical Air Combat Decision Support System (TACDSS). Some
simulation results demonstrating the difference of the learning techniques and
are also provided.
"
0405043,"Prediction with Expert Advice by Following the Perturbed Leader for
  General Weights","  When applying aggregating strategies to Prediction with Expert Advice, the
learning rate must be adaptively tuned. The natural choice of
sqrt(complexity/current loss) renders the analysis of Weighted Majority
derivatives quite complicated. In particular, for arbitrary weights there have
been no results proven so far. The analysis of the alternative ""Follow the
Perturbed Leader"" (FPL) algorithm from Kalai (2003} (based on Hannan's
algorithm) is easier. We derive loss bounds for adaptive learning rate and both
finite expert classes with uniform weights and countable expert classes with
arbitrary weights. For the former setup, our loss bounds match the best known
results so far, while for the latter our results are (to our knowledge) new.
"
0405049,Export Behaviour Modeling Using EvoNF Approach,"  The academic literature suggests that the extent of exporting by
multinational corporation subsidiaries (MCS) depends on their product
manufactured, resources, tax protection, customers and markets, involvement
strategy, financial independence and suppliers' relationship with a
multinational corporation (MNC). The aim of this paper is to model the complex
export pattern behaviour using a Takagi-Sugeno fuzzy inference system in order
to determine the actual volume of MCS export output (sales exported). The
proposed fuzzy inference system is optimised by using neural network learning
and evolutionary computation. Empirical results clearly show that the proposed
approach could model the export behaviour reasonable well compared to a direct
neural network approach.
"
0405050,Traffic Accident Analysis Using Decision Trees and Neural Networks,"  The costs of fatalities and injuries due to traffic accident have a great
impact on society. This paper presents our research to model the severity of
injury resulting from traffic accidents using artificial neural networks and
decision trees. We have applied them to an actual data set obtained from the
National Automotive Sampling System (NASS) General Estimates System (GES).
Experiment results reveal that in all the cases the decision tree outperforms
the neural network. Our research analysis also shows that the three most
important factors in fatal injury are: driver's seat belt usage, light
condition of the roadway, and driver's alcohol usage.
"
0405051,"Short Term Load Forecasting Models in Czech Republic Using Soft
  Computing Paradigms","  This paper presents a comparative study of six soft computing models namely
multilayer perceptron networks, Elman recurrent neural network, radial basis
function network, Hopfield model, fuzzy inference system and hybrid fuzzy
neural network for the hourly electricity demand forecast of Czech Republic.
The soft computing models were trained and tested using the actual hourly load
data for seven years. A comparison of the proposed techniques is presented for
predicting 2 day ahead demands for electricity. Simulation results indicate
that hybrid fuzzy neural network and radial basis function networks are the
best candidates for the analysis and forecasting of electricity demand.
"
0405052,Decision Support Systems Using Intelligent Paradigms,"  Decision-making is a process of choosing among alternative courses of action
for solving complicated problems where multi-criteria objectives are involved.
The past few years have witnessed a growing recognition of Soft Computing (SC)
technologies that underlie the conception, design and utilization of
intelligent systems. In this paper, we present different SC paradigms involving
an artificial neural network trained using the scaled conjugate gradient
algorithm, two different fuzzy inference methods optimised using neural network
learning/evolutionary algorithms and regression trees for developing
intelligent decision support systems. We demonstrate the efficiency of the
different algorithms by developing a decision support system for a Tactical Air
Combat Environment (TACE). Some empirical comparisons between the different
algorithms are also provided.
"
0405053,Synchronous Relaxation for Parallel Ising Spin Simulations,"  A new parallel algorithm for simulating Ising spin systems is presented. The
sequential prototype is the n-fold way algorithm cite{BKL75}, which is
efficient but is hard to parallelize using conservative methods. Our parallel
algorithm is optimistic. Unlike other optimistic algorithms, e.g., Time Warp,
our algorithm is synchronous. It also belongs to the class of simulations known
as ``relaxation'' cite{CS8 hence it is named ``synchronous relaxation.'' We
derive performance guarantees for this algorithm. If N is the number of PEs,
then under weak assumptions we show that the number of correct events processed
per unit of time is, on average, at least of order N/log(N). All communication
delays, processing time, and busy waits are taken into account.
"
0405064,"Designing Competent Mutation Operators via Probabilistic Model Building
  of Neighborhoods","  This paper presents a competent selectomutative genetic algorithm (GA), that
adapts linkage and solves hard problems quickly, reliably, and accurately. A
probabilistic model building process is used to automatically identify key
building blocks (BBs) of the search problem. The mutation operator uses the
probabilistic model of linkage groups to find the best among competing building
blocks. The competent selectomutative GA successfully solves additively
separable problems of bounded difficulty, requiring only subquadratic number of
function evaluations. The results show that for additively separable problems
the probabilistic model building BB-wise mutation scales as O(2^km^{1.5}), and
requires O(k^{0.5}logm) less function evaluations than its selectorecombinative
counterpart, confirming theoretical results reported elsewhere (Sastry &
Goldberg, 2004).
"
0405065,"Efficiency Enhancement of Genetic Algorithms via Building-Block-Wise
  Fitness Estimation","  This paper studies fitness inheritance as an efficiency enhancement technique
for a class of competent genetic algorithms called estimation distribution
algorithms. Probabilistic models of important sub-solutions are developed to
estimate the fitness of a proportion of individuals in the population, thereby
avoiding computationally expensive function evaluations. The effect of fitness
inheritance on the convergence time and population sizing are modeled and the
speed-up obtained through inheritance is predicted. The results show that a
fitness-inheritance mechanism which utilizes information on building-block
fitnesses provides significant efficiency enhancement. For additively separable
problems, fitness inheritance reduces the number of function evaluations to
about half and yields a speed-up of about 1.75--2.25.
"
0405093,Computerized Face Detection and Recognition,"  This publication presents methods for face detection, analysis and
recognition: fast normalized cross-correlation (fast correlation coefficient)
between multiple templates based face pre-detection method, method for
detection of exact face contour based on snakes and Generalized Gradient Vector
Flow field, method for combining recognition algorithms based on Cumulative
Match Characteristics in order to increase recognition speed and accuracy, and
face recognition method based on Principal Component Analysis of the Wavelet
Packet Decomposition allowing to use PCA - based recognition method with large
number of training images. For all the methods are presented experimental
results and comparisons of speed and accuracy with large face databases.
"
0405097,A Coalgebraic Approach to Kleene Algebra with Tests,"  Kleene algebra with tests is an extension of Kleene algebra, the algebra of
regular expressions, which can be used to reason about programs. We develop a
coalgebraic theory of Kleene algebra with tests, along the lines of the
coalgebraic theory of regular expressions based on deterministic automata.
Since the known automata-theoretic presentation of Kleene algebra with tests
does not lend itself to a coalgebraic theory, we define a new interpretation of
Kleene algebra with tests expressions and a corresponding automata-theoretic
presentation. One outcome of the theory is a coinductive proof principle, that
can be used to establish equivalence of our Kleene algebra with tests
expressions.
"
0405099,Web search engine based on DNS,"  Now no web search engine can cover more than 60 percent of all the pages on
Internet. The update interval of most pages database is almost one month. This
condition hasn't changed for many years. Converge and recency problems have
become the bottleneck problem of current web search engine. To solve these
problems, a new system, search engine based on DNS is proposed in this paper.
This system adopts the hierarchical distributed architecture like DNS, which is
different from any current commercial search engine. In theory, this system can
cover all the web pages on Internet. Its update interval could even be one day.
The original idea, detailed content and implementation of this system all are
introduced in this paper.
"
0406011,"Blind Construction of Optimal Nonlinear Recursive Predictors for
  Discrete Sequences","  We present a new method for nonlinear prediction of discrete random sequences
under minimal structural assumptions. We give a mathematical construction for
optimal predictors of such processes, in the form of hidden Markov models. We
then describe an algorithm, CSSR (Causal-State Splitting Reconstruction), which
approximates the ideal predictor from data. We discuss the reliability of CSSR,
its data requirements, and its performance in simulations. Finally, we compare
our approach to existing methods using variable-length Markov models and
cross-validated hidden Markov models, and show theoretically and experimentally
that our method delivers results superior to the former and at least comparable
to the latter.
"
0406016,"Schema-based Scheduling of Event Processors and Buffer Minimization for
  Queries on Structured Data Streams","  We introduce an extension of the XQuery language, FluX, that supports
event-based query processing and the conscious handling of main memory buffers.
Purely event-based queries of this language can be executed on streaming XML
data in a very direct way. We then develop an algorithm that allows to
efficiently rewrite XQueries into the event-based FluX language. This algorithm
uses order constraints from a DTD to schedule event handlers and to thus
minimize the amount of buffering required for evaluating a query. We discuss
the various technical aspects of query optimization and query evaluation within
our framework. This is complemented with an experimental evaluation of our
approach.
"
0406018,Effects of wireless computing technology,"  Wireless technology can provide many benefits to computing including faster
response to queries, reduced time spent on paperwork, increased online time for
users, just-in-time and real time control, tighter communications between
clients and hosts. Wireless Computing is governed by two general forces:
Technology, which provides a set of basic building blocks and User
Applications, which determine a set of operations that must be carried out
efficiently on demand. This paper summarizes technological changes that are
underway and describes their impact on wireless computing development and
implementation. It also describes the applications that influence the
development and implementation of wireless computing and shows what current
systems offer.
"
0406021,A direct formulation for sparse PCA using semidefinite programming,"  We examine the problem of approximating, in the Frobenius-norm sense, a
positive, semidefinite symmetric matrix by a rank-one matrix, with an upper
bound on the cardinality of its eigenvector. The problem arises in the
decomposition of a covariance matrix into sparse factors, and has wide
applications ranging from biology to finance. We use a modification of the
classical variational representation of the largest eigenvalue of a symmetric
matrix, where cardinality is constrained, and derive a semidefinite programming
based relaxation for our problem. We also discuss Nesterov's smooth
minimization technique applied to the SDP arising in the direct sparse PCA
method.
"
0406031,"A Public Reference Implementation of the RAP Anaphora Resolution
  Algorithm","  This paper describes a standalone, publicly-available implementation of the
Resolution of Anaphora Procedure (RAP) given by Lappin and Leass (1994). The
RAP algorithm resolves third person pronouns, lexical anaphors, and identifies
pleonastic pronouns. Our implementation, JavaRAP, fills a current need in
anaphora resolution research by providing a reference implementation that can
be benchmarked against current algorithms. The implementation uses the
standard, publicly available Charniak (2000) parser as input, and generates a
list of anaphora-antecedent pairs as output. Alternately, an in-place
annotation or substitution of the anaphors with their antecedents can be
produced. Evaluation on the MUC-6 co-reference task shows that JavaRAP has an
accuracy of 57.9%, similar to the performance given previously in the
literature (e.g., Preiss 2002).
"
0406035,"Optimal Free-Space Management and Routing-Conscious Dynamic Placement
  for Reconfigurable Devices","  We describe algorithmic results for two crucial aspects of allocating
resources on computational hardware devices with partial reconfigurability. By
using methods from the field of computational geometry, we derive a method that
allows correct maintainance of free and occupied space of a set of n
rectangular modules in optimal time Theta(n log n); previous approaches needed
a time of O(n^2) for correct results and O(n) for heuristic results. We also
show that finding an optimal feasible communication-conscious placement (which
minimizes the total weighted Manhattan distance between the new module and
existing demand points) can be computed in Theta(n log n). Both resulting
algorithms are practically easy to implement and show convincing experimental
behavior.
"
0406051,Stable Outcomes for Two-Sided Contract Choice Problems,"  We show, that a simple generalization of the Deferred Acceptance Procedure
with firms proposing due to Gale and Shapley(1962), yeild outcomes for a
two-sided contract choice problem, which necessarily belong to the core and are
Weakly Pareto Optimal for firms. Under additional assumptions: (a) given any
two distinct workers, the set of yields acheivable by a firm with the first
worker is disjoint from the set of yields acheivable by it with the second, and
(b) the contract choice problem is pair-wise efficient, we prove that there is
no stable outcome at which a firm can get more than what it gets at the unique
outcome of our procedure.
"
0407004,Zero-error communication over networks,"  Zero-Error communication investigates communication without any error. By
defining channels without probabilities, results from Elias can be used to
completely characterize which channel can simulate which other channels. We
introduce the ambiguity of a channel, which completely characterizes the
possibility in principle of a channel to simulate any other channel. In the
second part we will look at networks of players connected by channels, while
some players may be corrupted. We will show how the ambiguity of a virtual
channel connecting two arbitrary players can be calculated. This means that we
can exactly specify what kind of zero-error communication is possible between
two players in any network of players connected by channels.
"
0407008,"Autogenic Training With Natural Language Processing Modules: A Recent
  Tool For Certain Neuro Cognitive Studies","  Learning to respond to voice-text input involves the subject's ability in
understanding the phonetic and text based contents and his/her ability to
communicate based on his/her experience. The neuro-cognitive facility of the
subject has to support two important domains in order to make the learning
process complete. In many cases, though the understanding is complete, the
response is partial. This is one valid reason why we need to support the
information from the subject with scalable techniques such as Natural Language
Processing (NLP) for abstraction of the contents from the output. This paper
explores the feasibility of using NLP modules interlaced with Neural Networks
to perform the required task in autogenic training related to medical
applications.
"
0407024,An agent-based intelligent environmental monitoring system,"  Fairly rapid environmental changes call for continuous surveillance and
on-line decision making. There are two main areas where IT technologies can be
valuable. In this paper we present a multi-agent system for monitoring and
assessing air-quality attributes, which uses data coming from a meteorological
station. A community of software agents is assigned to monitor and validate
measurements coming from several sensors, to assess air-quality, and, finally,
to fire alarms to appropriate recipients, when needed. Data mining techniques
have been used for adding data-driven, customized intelligence into agents. The
architecture of the developed system, its domain ontology, and typical agent
interactions are presented. Finally, the deployment of a real-world test case
is demonstrated.
"
0407027,Unsupervised Topic Adaptation for Lecture Speech Retrieval,"  We are developing a cross-media information retrieval system, in which users
can view specific segments of lecture videos by submitting text queries. To
produce a text index, the audio track is extracted from a lecture video and a
transcription is generated by automatic speech recognition. In this paper, to
improve the quality of our retrieval system, we extensively investigate the
effects of adapting acoustic and language models on speech recognition. We
perform an MLLR-based method to adapt an acoustic model. To obtain a corpus for
language model adaptation, we use the textbook for a target lecture to search a
Web collection for the pages associated with the lecture topic. We show the
effectiveness of our method by means of experiments.
"
0407029,Static versus Dynamic Arbitrage Bounds on Multivariate Option Prices,"  We compare static arbitrage price bounds on basket calls, i.e. bounds that
only involve buy-and-hold trading strategies, with the price range obtained
within a multi-variate generalization of the Black-Scholes model. While there
is no gap between these two sets of prices in the univariate case, we observe
here that contrary to our intuition about model risk for at-the-money calls,
there is a somewhat large gap between model prices and static arbitrage prices,
hence a similarly large set of prices on which a multivariate Black-Scholes
model cannot be calibrated but where no conclusion can be drawn on the presence
or not of a static arbitrage opportunity.
"
0407038,Model Checking of Statechart Models: Survey and Research Directions,"  We survey existing approaches to the formal verification of statecharts using
model checking. Although the semantics and subset of statecharts used in each
approach varies considerably, along with the model checkers and their
specification languages, most approaches rely on translating the hierarchical
structure into the flat representation of the input language of the model
checker. This makes model checking difficult to scale to industrial models, as
the state space grows exponentially with flattening. We look at current
approaches to model checking hierarchical structures and find that their
semantics is significantly different from statecharts. We propose to address
the problem of state space explosion using a combination of techniques, which
are proposed as directions for further research.
"
0407045,The First-Order Theory of Sets with Cardinality Constraints is Decidable,"  We show that the decidability of the first-order theory of the language that
combines Boolean algebras of sets of uninterpreted elements with Presburger
arithmetic operations. We thereby disprove a recent conjecture that this theory
is undecidable. Our language allows relating the cardinalities of sets to the
values of integer variables, and can distinguish finite and infinite sets. We
use quantifier elimination to show the decidability and obtain an elementary
upper bound on the complexity.
  Precise program analyses can use our decidability result to verify
representation invariants of data structures that use an integer field to
represent the number of stored elements.
"
0407053,Design of a Parallel and Distributed Web Search Engine,"  This paper describes the architecture of MOSE (My Own Search Engine), a
scalable parallel and distributed engine for searching the web. MOSE was
specifically designed to efficiently exploit affordable parallel architectures,
such as clusters of workstations. Its modular and scalable architecture can
easily be tuned to fulfill the bandwidth requirements of the application at
hand. Both task-parallel and data-parallel approaches are exploited within MOSE
in order to increase the throughput and efficiently use communication, storing
and computational resources. We used a collection of html documents as a
benchmark, and conducted preliminary experiments on a cluster of three SMP
Linux PCs.
"
0407060,Tight bounds for LDPC and LDGM codes under MAP decoding,"  A new method for analyzing low density parity check (LDPC) codes and low
density generator matrix (LDGM) codes under bit maximum a posteriori
probability (MAP) decoding is introduced. The method is based on a rigorous
approach to spin glasses developed by Francesco Guerra. It allows to construct
lower bounds on the entropy of the transmitted message conditional to the
received one. Based on heuristic statistical mechanics calculations, we
conjecture such bounds to be tight. The result holds for standard irregular
ensembles when used over binary input output symmetric channels. The method is
first developed for Tanner graph ensembles with Poisson left degree
distribution. It is then generalized to `multi-Poisson' graphs, and, by a
completion procedure, to arbitrary degree distribution.
"
0407065,"Word Sense Disambiguation by Web Mining for Word Co-occurrence
  Probabilities","  This paper describes the National Research Council (NRC) Word Sense
Disambiguation (WSD) system, as applied to the English Lexical Sample (ELS)
task in Senseval-3. The NRC system approaches WSD as a classical supervised
machine learning problem, using familiar tools such as the Weka machine
learning software and Brill's rule-based part-of-speech tagger. Head words are
represented as feature vectors with several hundred features. Approximately
half of the features are syntactic and the other half are semantic. The main
novelty in the system is the method for generating the semantic features, based
on word \hbox{co-occurrence} probabilities. The probabilities are estimated
using the Waterloo MultiText System with a corpus of about one terabyte of
unlabeled text, collected by a web crawler.
"
0408032,Performance Characterisation of Intra-Cluster Collective Communications,"  Although recent works try to improve collective communication in grid systems
by separating intra and inter-cluster communication, the optimisation of
communications focus only on inter-cluster communications. We believe, instead,
that the overall performance of the application may be improved if
intra-cluster collective communications performance is known in advance. Hence,
it is important to have an accurate model of the intra-cluster collective
communications, which provides the necessary evidences to tune and to predict
their performance correctly. In this paper we present our experience on
modelling such communication strategies. We describe and compare different
implementation strategies with their communication models, evaluating the
models' accuracy and describing the practical challenges that can be found when
modelling collective communications.
"
0408033,"Identifying Logical Homogeneous Clusters for Efficient Wide-area
  Communications","  Recently, many works focus on the implementation of collective communication
operations adapted to wide area computational systems, like computational Grids
or global-computing. Due to the inherently heterogeneity of such environments,
most works separate ""clusters"" in different hierarchy levels. to better model
the communication. However, in our opinion, such works do not give enough
attention to the delimitation of such clusters, as they normally use the
locality or the IP subnet from the machines to delimit a cluster without
verifying the ""homogeneity"" of such clusters. In this paper, we describe a
strategy to gather network information from different local-area networks and
to construct ""logical homogeneous clusters"", better suited to the performance
modelling.
"
0408034,Fast Tuning of Intra-Cluster Collective Communications,"  Recent works try to optimise collective communication in grid systems
focusing mostly on the optimisation of communications among different clusters.
We believe that intra-cluster collective communications should also be
optimised, as a way to improve the overall efficiency and to allow the
construction of multi-level collective operations. Indeed, inside homogeneous
clusters, a simple optimisation approach rely on the comparison from different
implementation strategies, through their communication models. In this paper we
evaluate this approach, comparing different implementation strategies with
their predicted performances. As a result, we are able to choose the
communication strategy that better adapts to each network environment.
"
0408036,Consensus on Transaction Commit,"  The distributed transaction commit problem requires reaching agreement on
whether a transaction is committed or aborted. The classic Two-Phase Commit
protocol blocks if the coordinator fails. Fault-tolerant consensus algorithms
also reach agreement, but do not block whenever any majority of the processes
are working. Running a Paxos consensus algorithm on the commit/abort decision
of each participant yields a transaction commit protocol that uses 2F +1
coordinators and makes progress if at least F +1 of them are working. In the
fault-free case, this algorithm requires one extra message delay but has the
same stable-storage write delay as Two-Phase Commit. The classic Two-Phase
Commit algorithm is obtained as the special F = 0 case of the general Paxos
Commit algorithm.
"
0408048,Journal of New Democratic Methods: An Introduction,"  This paper describes a new breed of academic journals that use statistical
machine learning techniques to make them more democratic. In particular, not
only can anyone submit an article, but anyone can also become a reviewer.
Machine learning is used to decide which reviewers accurately represent the
views of the journal's readers and thus deserve to have their opinions carry
more weight. The paper concentrates on describing a specific experimental
prototype of a democratic journal called the Journal of New Democratic Methods
(JNDM). The paper also mentions the wider implications that machine learning
and the techniques used in the JNDM may have for representative democracy in
general.
"
0408069,"The Integration of Connectionism and First-Order Knowledge
  Representation and Reasoning as a Challenge for Artificial Intelligence","  Intelligent systems based on first-order logic on the one hand, and on
artificial neural networks (also called connectionist systems) on the other,
differ substantially. It would be very desirable to combine the robust neural
networking machinery with symbolic knowledge representation and reasoning
paradigms like logic programming in such a way that the strengths of either
paradigm will be retained. Current state-of-the-art research, however, fails by
far to achieve this ultimate goal. As one of the main obstacles to be overcome
we perceive the question how symbolic knowledge can be encoded by means of
connectionist systems: Satisfactory answers to this will naturally lead the way
to knowledge extraction algorithms and to integrated neural-symbolic systems.
"
0409001,Probabilistic heuristics for disseminating information in networks,"  We study the problem of disseminating a piece of information through all the
nodes of a network, given that it is known originally only to a single node. In
the absence of any structural knowledge on the network other than the nodes'
neighborhoods, this problem is traditionally solved by flooding all the
network's edges. We analyze a recently introduced probabilistic algorithm for
flooding and give an alternative probabilistic heuristic that can lead to some
cost-effective improvements, like better trade-offs between the message and
time complexities involved. We analyze the two algorithms both mathematically
and by means of simulations, always within a random-graph framework and
considering relevant node-degree distributions.
"
0409002,Default reasoning over domains and concept hierarchies,"  W.C. Rounds and G.-Q. Zhang (2001) have proposed to study a form of
disjunctive logic programming generalized to algebraic domains. This system
allows reasoning with information which is hierarchically structured and forms
a (suitable) domain. We extend this framework to include reasoning with default
negation, giving rise to a new nonmonotonic reasoning framework on hierarchical
knowledge which encompasses answer set programming with extended disjunctive
logic programs. We also show that the hierarchically structured knowledge on
which programming in this paradigm can be done, arises very naturally from
formal concept analysis. Together, we obtain a default reasoning paradigm for
conceptual knowledge which is in accordance with mainstream developments in
nonmonotonic reasoning.
"
0409008,A Model for Fine-Grained Alignment of Multilingual Texts,"  While alignment of texts on the sentential level is often seen as being too
coarse, and word alignment as being too fine-grained, bi- or multilingual texts
which are aligned on a level in-between are a useful resource for many
purposes. Starting from a number of examples of non-literal translations, which
tend to make alignment difficult, we describe an alignment model which copes
with these cases by explicitly coding them. The model is based on
predicate-argument structures and thus covers the middle ground between
sentence and word alignment. The model is currently used in a recently
initiated project of a parallel English-German treebank (FuSe), which can in
principle be extended with additional languages.
"
0409020,"A Generalized Disjunctive Paraconsistent Data Model for Negative and
  Disjunctive Information","  This paper presents a generalization of the disjunctive paraconsistent
relational data model in which disjunctive positive and negative information
can be represented explicitly and manipulated. There are situations where the
closed world assumption to infer negative facts is not valid or undesirable and
there is a need to represent and reason with negation explicitly. We consider
explicit disjunctive negation in the context of disjunctive databases as there
is an interesting interplay between these two types of information. Generalized
disjunctive paraconsistent relation is introduced as the main structure in this
model. The relational algebra is appropriately generalized to work on
generalized disjunctive paraconsistent relations and their correctness is
established.
"
0409022,Two Models for the Study of Congested Internet Connections,"  In this paper, we introduce two deterministic models aimed at capturing the
dynamics of congested Internet connections. The first model is a
continuous-time model that combines a system of differential equations with a
sudden change in one of the state variables. The second model is a
discrete-time model with a time step that arises naturally from the system.
Results from these models show good agreement with the well-known ns network
simulator, better than the results of a previous, similar model. This is due in
large part to the use of the sudden change to reflect the impact of lost data
packets. We also discuss the potential use of this model in network traffic
state estimation.
"
0409028,Incentive Systems in Multi-Level Markets for Virtual Goods,"  As an alternative to rigid DRM measures, ways of marketing virtual goods
through multi-level or networked marketing have raised some interest. This
report is a first approach to multi-level markets for virtual goods from the
viewpoint of theoretical economy. A generic, kinematic model for the monetary
flow in multi-level markets, which quantitatively describes the incentives that
buyers receive through resales revenues, is devised. Building on it, the
competition of goods is examined in a dynamical, utility-theoretic model
enabling, in particular, a treatment of the free-rider problem. The most
important implications for the design of multi-level market mechanisms for
virtual goods, or multi-level incentive management systems, are outlined.
"
0409040,Unification of Fusion Theories,"  Since no fusion theory neither rule fully satisfy all needed applications,
the author proposes a Unification of Fusion Theories and a combination of
fusion rules in solving problems/applications. For each particular application,
one selects the most appropriate model, rule(s), and algorithm of
implementation. We are working in the unification of the fusion theories and
rules, which looks like a cooking recipe, better we'd say like a logical chart
for a computer programmer, but we don't see another method to comprise/unify
all things. The unification scenario presented herein, which is now in an
incipient form, should periodically be updated incorporating new discoveries
from the fusion and engineering research.
"
0409044,Some Applications of Coding Theory in Computational Complexity,"  Error-correcting codes and related combinatorial constructs play an important
role in several recent (and old) results in computational complexity theory. In
this paper we survey results on locally-testable and locally-decodable
error-correcting codes, and their applications to complexity theory and to
cryptography.
  Locally decodable codes are error-correcting codes with sub-linear time
error-correcting algorithms. They are related to private information retrieval
(a type of cryptographic protocol), and they are used in average-case
complexity and to construct ``hard-core predicates'' for one-way permutations.
  Locally testable codes are error-correcting codes with sub-linear time
error-detection algorithms, and they are the combinatorial core of
probabilistically checkable proofs.
"
0409051,Quantum Complexity Classes,"  In our thesis, we try to shed more light onto the complexity of quantum
complexity classes by refining the related part of the hierarchy. First, we
review the basic concepts of quantum computing in general. Then, inspired by
BQP, we define new complexity classes. They are placed between BPP and PSPACE.
We show that they incorporate the current important quantum algorithms.
Furthermore, the importance of the unitarity constraint given by quantum
mechanics is revealed. Without this requirement, we naturally arrive at the
class AWPP, which was up to now thought to be just an artificially defined
class. We hope that some of our newly defined classes could find their use in
proving results about BQP.
"
0409056,"Using sparse matrices and splines-based interpolation in computational
  fluid dynamics simulations","  In this relation I present a technique of construction and fast evaluation of
a family of cubic polynomials for analytic smoothing and graphical rendering of
particles trajectories for flows in a generic geometry. The principal result of
the work was implementation and test of a method for interpolating 3D points by
regular parametric curves and their fast and efficient evaluation for a good
resolution of rendering. For the purpose a parallel environment using a
multiprocessor cluster architecture has been used. This work has been developed
for the Research and Development Department of my company for planning advanced
customized models of industrial burners.
"
0410002,Shannon Information and Kolmogorov Complexity,"  We compare the elementary theories of Shannon information and Kolmogorov
complexity, the extent to which they have a common purpose, and where they are
fundamentally different. We discuss and relate the basic notions of both
theories: Shannon entropy versus Kolmogorov complexity, the relation of both to
universal coding, Shannon mutual information versus Kolmogorov (`algorithmic')
mutual information, probabilistic sufficient statistic versus algorithmic
sufficient statistic (related to lossy compression in the Shannon theory versus
meaningful information in the Kolmogorov theory), and rate distortion theory
versus Kolmogorov's structure function. Part of the material has appeared in
print before, scattered through various publications, but this is the first
comprehensive systematic comparison. The last mentioned relations are new.
"
0410012,DiPerF: an automated DIstributed PERformance testing Framework,"  We present DiPerF, a distributed performance testing framework, aimed at
simplifying and automating service performance evaluation. DiPerF coordinates a
pool of machines that test a target service, collects and aggregates
performance metrics, and generates performance statistics. The aggregate data
collected provide information on service throughput, on service ""fairness"" when
serving multiple clients concurrently, and on the impact of network latency on
service performance. Furthermore, using this data, it is possible to build
predictive models that estimate a service performance given the service load.
We have tested DiPerF on 100+ machines on two testbeds, Grid3 and PlanetLab,
and explored the performance of job submission services (pre WS GRAM and WS
GRAM) included with Globus Toolkit 3.2.
"
0410015,"L1 regularization is better than L2 for learning and predicting chaotic
  systems","  Emergent behaviors are in the focus of recent research interest. It is then
of considerable importance to investigate what optimizations suit the learning
and prediction of chaotic systems, the putative candidates for emergence. We
have compared L1 and L2 regularizations on predicting chaotic time series using
linear recurrent neural networks. The internal representation and the weights
of the networks were optimized in a unifying framework. Computational tests on
different problems indicate considerable advantages for the L1 regularization:
It had considerably better learning time and better interpolating capabilities.
We shall argue that optimization viewed as a maximum likelihood estimation
justifies our results, because L1 regularization fits heavy-tailed
distributions -- an apparently general feature of emergent systems -- better.
"
0410024,"The Key Authority - Secure Key Management in Hierarchical Public Key
  Infrastructures","  We model a private key`s life cycle as a finite state machine. The states are
the key`s phases of life and the transition functions describe tasks to be done
with the key. Based on this we define and describe the key authority, a trust
center module, which potentiates the easy enforcement of secure management of
private keys in hierarchical public key infrastructures. This is done by
assembling all trust center tasks concerning the crucial handling of private
keys within one centralized module. As this module resides under full control
of the trust center`s carrier it can easily be protected by well-known
organizational and technical measures.
"
0410025,Outflanking and securely using the PIN/TAN-System,"  The PIN/TAN-system is an authentication and authorization scheme used in
e-business. Like other similar schemes it is successfully attacked by
criminals. After shortly classifying the various kinds of attacks we accomplish
malicious code attacks on real World Wide Web transaction systems. In doing so
we find that it is really easy to outflank these systems. This is even
supported by the users' behavior. We give a few simple behavior rules to
improve this situation. But their impact is limited. Also the providers support
the attacks by having implementation flaws in their installations. Finally we
show that the PIN/TAN-system is not suitable for usage in highly secure
applications.
"
0410028,Life Above Threshold: From List Decoding to Area Theorem and MSE,"  We consider communication over memoryless channels using low-density
parity-check code ensembles above the iterative (belief propagation) threshold.
What is the computational complexity of decoding (i.e., of reconstructing all
the typical input codewords for a given channel output) in this regime? We
define an algorithm accomplishing this task and analyze its typical
performance. The behavior of the new algorithm can be expressed in purely
information-theoretical terms. Its analysis provides an alternative proof of
the area theorem for the binary erasure channel. Finally, we explain how the
area theorem is generalized to arbitrary memoryless channels. We note that the
recently discovered relation between mutual information and minimal square
error is an instance of the area theorem in the setting of Gaussian channels.
"
0410034,"P-time Completeness of Light Linear Logic and its Nondeterministic
  Extension","  In CSL'99 Roversi pointed out that the Turing machine encoding of Girard's
seminal paper ""Light Linear Logic"" has a flaw. Moreover he presented a working
version of the encoding in Light Affine Logic, but not in Light Linear Logic.
In this paper we present a working version of the encoding in Light Linear
Logic. The idea of the encoding is based on a remark of Girard's tutorial paper
on Linear Logic. The encoding is also an example which shows usefulness of
additive connectives. Moreover we also consider a nondeterministic extension of
Light Linear Logic. We show that the extended system is NP-complete in the same
meaning as P-completeness of Light Linear Logic.
"
0410035,"Overhead-Free Computation, DCFLs, and CFLs","  We study Turing machines that are allowed absolutely no space overhead. The
only work space the machines have, beyond the fixed amount of memory implicit
in their finite-state control, is that which they can create by cannibalizing
the input bits' own space. This model more closely reflects the fixed-sized
memory of real computers than does the standard complexity-theoretic model of
linear space.
  Though some context-sensitive languages cannot be accepted by such machines,
we show that all context-free languages can be accepted nondeterministically in
polynomial time with absolutely no space overhead, and that all deterministic
context-free languages can be accepted deterministically in polynomial time
with absolutely no space overhead.
"
0410039,"Generating All Maximal Induced Subgraphs for Hereditary,
  Connected-Hereditary and Rooted-Hereditary Properties","  The problem of computing all maximal induced subgraphs of a graph G that have
a graph property P, also called the maximal P-subgraphs problem, is considered.
This problem is studied for hereditary, connected-hereditary and
rooted-hereditary graph properties. The maximal P-subgraphs problem is reduced
to restricted versions of this problem by providing algorithms that solve the
general problem, assuming that an algorithm for a restricted version is given.
The complexity of the algorithms are analyzed in terms of total polynomial
time, incremental polynomial time and the complexity class P-enumerable. The
general results presented allow simple proofs that the maximal P-subgraphs
problem can be solved efficiently (in terms of the input and output) for many
different properties.
"
0410049,Intransitivity and Vagueness,"  There are many examples in the literature that suggest that
indistinguishability is intransitive, despite the fact that the
indistinguishability relation is typically taken to be an equivalence relation
(and thus transitive). It is shown that if the uncertainty perception and the
question of when an agent reports that two things are indistinguishable are
both carefully modeled, the problems disappear, and indistinguishability can
indeed be taken to be an equivalence relation. Moreover, this model also
suggests a logic of vagueness that seems to solve many of the problems related
to vagueness discussed in the philosophical literature. In particular, it is
shown here how the logic can handle the sorites paradox.
"
0410060,"Semantic filtering by inference on domain knowledge in spoken dialogue
  systems","  General natural dialogue processing requires large amounts of domain
knowledge as well as linguistic knowledge in order to ensure acceptable
coverage and understanding. There are several ways of integrating lexical
resources (e.g. dictionaries, thesauri) and knowledge bases or ontologies at
different levels of dialogue processing. We concentrate in this paper on how to
exploit domain knowledge for filtering interpretation hypotheses generated by a
robust semantic parser. We use domain knowledge to semantically constrain the
hypothesis space. Moreover, adding an inference mechanism allows us to complete
the interpretation when information is not explicitly available. Further, we
discuss briefly how this can be generalized towards a predictive natural
interactive system.
"
0410061,An argumentative annotation schema for meeting discussions,"  In this article, we are interested in the annotation of transcriptions of
human-human dialogue taken from meeting records. We first propose a meeting
content model where conversational acts are interpreted with respect to their
argumentative force and their role in building the argumentative structure of
the meeting discussion. Argumentation in dialogue describes the way
participants take part in the discussion and argue their standpoints. Then, we
propose an annotation scheme based on such an argumentative dialogue model as
well as the evaluation of its adequacy. The obtained higher-level semantic
annotations are exploited in the conceptual indexing of the information
contained in meeting discussions.
"
0410062,"Automatic Keyword Extraction from Spoken Text. A Comparison of two
  Lexical Resources: the EDR and WordNet","  Lexical resources such as WordNet and the EDR electronic dictionary have been
used in several NLP tasks. Probably, partly due to the fact that the EDR is not
freely available, WordNet has been used far more often than the EDR. We have
used both resources on the same task in order to make a comparison possible.
The task is automatic assignment of keywords to multi-party dialogue episodes
(i.e. thematically coherent stretches of spoken text). We show that the use of
lexical resources in such a task results in slightly higher performances than
the use of a purely statistically based method.
"
0410063,"INSPIRE: Evaluation of a Smart-Home System for Infotainment Management
  and Device Control","  This paper gives an overview of the assessment and evaluation methods which
have been used to determine the quality of the INSPIRE smart home system. The
system allows different home appliances to be controlled via speech, and
consists of speech and speaker recognition, speech understanding, dialogue
management, and speech output components. The performance of these components
is first assessed individually, and then the entire system is evaluated in an
interaction experiment with test users. Initial results of the assessment and
evaluation are given, in particular with respect to the transmission channel
impact on speech and speaker recognition, and the assessment of speech output
for different system metaphors.
"
0410074,ReCord: A Distributed Hash Table with Recursive Structure,"  We propose a simple distributed hash table called ReCord, which is a
generalized version of Randomized-Chord and offers improved tradeoffs in
performance and topology maintenance over existing P2P systems. ReCord is
scalable and can be easily implemented as an overlay network, and offers a good
tradeoff between the node degree and query latency. For instance, an $n$-node
ReCord with $O(\log n)$ node degree has an expected latency of $\Theta(\log n)$
hops. Alternatively, it can also offer $\Theta(\frac{\log n}{\log \log n})$
hops latency at a higher cost of $O(\frac{\log^2 n}{\log
  \log n})$ node degree. Meanwhile, simulations of the dynamic behaviors of
ReCord are studied.
"
0411006,"Capacity Achieving Code Constructions for Two Classes of (d,k)
  Constraints","  In this paper, we present two low complexity algorithms that achieve capacity
for the noiseless (d,k) constrained channel when k=2d+1, or when k-d+1 is not
prime. The first algorithm, called symbol sliding, is a generalized version of
the bit flipping algorithm introduced by Aviran et al. [1]. In addition to
achieving capacity for (d,2d+1) constraints, it comes close to capacity in
other cases. The second algorithm is based on interleaving, and is a
generalized version of the bit stuffing algorithm introduced by Bender and Wolf
[2]. This method uses fewer than k-d biased bit streams to achieve capacity for
(d,k) constraints with k-d+1 not prime. In particular, the encoder for
(d,d+2^m-1) constraints, 1\le m<\infty, requires only m biased bit streams.
"
0411015,Bounded Input Bounded Predefined Control Bounded Output,"  The paper is an attempt to generalize a methodology, which is similar to the
bounded-input bounded-output method currently widely used for the system
stability studies. The presented earlier methodology allows decomposition of
input space into bounded subspaces and defining for each subspace its bounding
surface. It also defines a corresponding predefined control, which maps any
point of a bounded input into a desired bounded output subspace. This
methodology was improved by providing a mechanism for the fast defining a
bounded surface. This paper presents enhanced bounded-input
bounded-predefined-control bounded-output approach, which provides adaptability
feature to the control and allows transferring of a controlled system along a
suboptimal trajectory.
"
0411024,Space Robotics Part 2: Space-based Manipulators,"  In this second of three short papers, I introduce some of the basic concepts
of space robotics with an emphasis on some specific challenging areas of
research that are peculiar to the application of robotics to space
infrastructure development. The style of these short papers is pedagogical and
the concepts in this paper are developed from fundamental manipulator robotics.
This second paper considers the application of space manipulators to on-orbit
servicing (OOS), an application which has considerable commercial application.
I provide some background to the notion of robotic on-orbit servicing and
explore how manipulator control algorithms may be modified to accommodate space
manipulators which operate in the micro-gravity of space.
"
0411038,Impact of IT on Higher education Through Continuing Education,"  Information Technology is emerging to be the technology of 21st century. The
paradigm shift from industrial society to information society had already
become a reality! It is indeed high time to think about integrating IT in all
facets of education -- may it be in secondary level, or be it in reskilling the
employed ones. This paper discusses various issues in incorporating IT in
various levels of education, and the need to think about a task force to
counter the so-called slow down and recession in IT industry. The opportunities
for aspiring IT professionals were also discussed. The importance of reskilling
as a continuing education programme to make the people aware of the changing
trends in IT was also discussed.
"
0411047,"Numerical Solutions of 2-D Steady Incompressible Driven Cavity Flow at
  High Reynolds Numbers","  Numerical calculations of the 2-D steady incompressible driven cavity flow
are presented. The Navier-Stokes equations in streamfunction and vorticity
formulation are solved numerically using a fine uniform grid mesh of 601x601.
The steady driven cavity solutions are computed for Re<21,000 with a maximum
absolute residuals of the governing equations that were less than 10-10. A new
quaternary vortex at the bottom left corner and a new tertiary vortex at the
top left corner of the cavity are observed in the flow field as the Reynolds
number increases. Detailed results are presented and comparisons are made with
benchmark solutions found in the literature.
"
0411049,"Fourth Order Compact Formulation of Navier-Stokes Equations and Driven
  Cavity Flow at High Reynolds Numbers","  A new fourth order compact formulation for the steady 2-D incompressible
Navier-Stokes equations is presented. The formulation is in the same form of
the Navier-Stokes equations such that any numerical method that solve the
Navier-Stokes equations can also be applied to this fourth order compact
formulation. In particular in this work the formulation is solved with an
efficient numerical method that requires the solution of tridiagonal systems
using a fine grid mesh of 601x601. Using this formulation, the steady 2-D
incompressible flow in a driven cavity is solved up to Reynolds number of
20,000 with fourth order spatial accuracy. Detailed solutions are presented.
"
0411052,"Spontaneous Dynamics of Asymmetric Random Recurrent Spiking Neural
  Networks","  We study in this paper the effect of an unique initial stimulation on random
recurrent networks of leaky integrate and fire neurons. Indeed given a
stochastic connectivity this so-called spontaneous mode exhibits various non
trivial dynamics. This study brings forward a mathematical formalism that
allows us to examine the variability of the afterward dynamics according to the
parameters of the weight distribution. Provided independence hypothesis (e.g.
in the case of very large networks) we are able to compute the average number
of neurons that fire at a given time -- the spiking activity. In accordance
with numerical simulations, we prove that this spiking activity reaches a
steady-state, we characterize this steady-state and explore the transients.
"
0411056,Adaptation dynamique de services,"  This paper proposes a software architecture for dynamical service adaptation.
The services are constituted by reusable software components. The adaptation's
goal is to optimize the service function of their execution context. For a
first step, the context will take into account just the user needs but other
elements will be added. A particular feature in our proposition is the profiles
that are used not only to describe the context's elements but also the
components itself. An Adapter analyzes the compatibility between all these
profiles and detects the points where the profiles are not compatibles. The
same Adapter search and apply the possible adaptation solutions: component
customization, insertion, extraction or replacement.
"
0411057,Runtime Reconfiguration of J2EE Applications,"  Runtime reconfiguration considered as ""applying required changes to a running
system"" plays an important role for providing high availability not only of
safety- and mission-critical systems, but also for commercial web-applications
offering professional services. Hereby, the main concerns are maintaining the
consistency of the running system during reconfiguration and minimizing its
down-time caused by the reconfiguration. This paper focuses on the platform
independent subsystem that realises deployment and redeployment of J2EE modules
based on the new J2EE Deployment API as a part of the implementation of our
proposed system architecture enabling runtime reconfiguration of
component-based systems. Our ""controlled runtime redeployment"" comprises an
extension of hot deployment and dynamic reloading, complemented by allowing for
structural change
"
0411065,"An Evaluated Certification Services System for the German National Root
  CA - Legally Binding and Trustworthy Transactions in E-Business and
  E-Government","  National Root CAs enable legally binding E-Business and E-Government
transactions. This is a report about the development, the evaluation and the
certification of the new certification services system for the German National
Root CA. We illustrate why a new certification services system was necessary,
and which requirements to the new system existed. Then we derive the tasks to
be done from the mentioned requirements. After that we introduce the initial
situation at the beginning of the project. We report about the very process and
talk about some unfamiliar situations, special approaches and remarkable
experiences. Finally we present the ready IT system and its impact to
E-Business and E-Government.
"
0411078,Notes On The Design Of An Internet Adversary,"  The design of the defenses Internet systems can deploy against attack,
especially adaptive and resilient defenses, must start from a realistic model
of the threat. This requires an assessment of the capabilities of the
adversary. The design typically evolves through a process of simulating both
the system and the adversary. This requires the design and implementation of a
simulated adversary based on the capability assessment. Consensus on the
capabilities of a suitable adversary is not evident. Part of the recent
redesign of the protocol used by peers in the LOCKSS digital preservation
system included a conservative assessment of the adversary's capabilities. We
present our assessment and the implications we drew from it as a step towards a
reusable adversary specification.
"
0411082,"Support pour la reconfiguration d'implantation dans les applications a
  composants Java","  Nowadays, numerous component models are used for various purposes: to build
applications, middleware or even operating systems. Those models commonly
support structure reconfiguration, that is modification of application's
architecture at runtime. On the other hand, very few allow implementation
reconfiguration, that is runtime modification of the code of components
building the application. In this article we present the work we performed on
JULIA, a Java-based implementation of the FRACTAL component model, in order for
it to support implementation reconfigurations. We show how we overcame the
limitations of Java class loading mechanism to allow runtime modifications of
components' implementation and interfaces. We also describe the integration of
our solution with the JULIA ADL.
"
0411087,"Pandora : une plate-forme efficace pour la construction d'applications
  autonomes","  Autonomic computing has been proposed recently as a way to address the
difficult management of applications whose complexity is constantly increasing.
Autonomous applications will have to be especially flexible and be able to
monitor themselves permanently. This work presents a framework, Pandora, which
eases the construction of applications that satisfy this double goal. Pandora
relies on an original application programming pattern - based on stackable
layers and message passing - to obtain minimalist model and architecture that
allows to control the overhead imposed by the full reflexivity of the
framework. Besides, a prototype of the framework has been implemented in C++. A
detailed performance study, together with examples of use, complement this
presentation
"
0411100,A Decidable Probability Logic for Timed Probabilistic Systems,"  In this paper we extend the predicate logic introduced in [Beauquier et al.
2002] in order to deal with Semi-Markov Processes. We prove that with respect
to qualitative probabilistic properties, model checking is decidable for this
logic applied to Semi-Markov Processes. Furthermore we apply our logic to
Probabilistic Timed Automata considering classical and urgent semantics, and
considering also predicates on clock. We prove that results on Semi Markov
Processes hold also for Probabilistic Timed Automata for both the two semantics
considered. Moreover, we prove that results for Markov Processes shown in
[Beauquier et al. 2002] are extensible to Probabilistic Timed Automata where
urgent semantics is considered.
"
0412027,Correlated dynamics in human printing behavior,"  Arrival times of requests to print in a student laboratory were analyzed.
Inter-arrival times between subsequent requests follow a universal scaling law
relating time intervals and the size of the request, indicating a scale
invariant dynamics with respect to the size. The cumulative distribution of
file sizes is well-described by a modified power law often seen in
non-equilibrium critical systems. For each user, waiting times between their
individual requests show long range dependence and are broadly distributed from
seconds to weeks. All results are incompatible with Poisson models, and may
provide evidence of critical dynamics associated with voluntary thought
processes in the brain.
"
0412039,Security in Carrier Class Server Applications for All-IP Networks,"  A revolution is taking place in telecommunication networks. New services are
appearing on platforms such as third generation cellular phones (3G) and
broadband Internet access. This motivates the transition from mostly switched
to all-IP networks. The replacement of the traditional shallow and well-defined
interface to telephony networks brings accrued flexibility, but also makes the
network accordingly difficult to properly secure. This paper surveys the
implications of this transition on security issues in telecom applications. It
does not give an exhaustive list of security tools or security protocols. Its
goal is rather to initiate the reader to the security issues brought to carrier
class servers by this revolution.
"
0412044,TulaFale: A Security Tool for Web Services,"  Web services security specifications are typically expressed as a mixture of
XML schemas, example messages, and narrative explanations. We propose a new
specification language for writing complementary machine-checkable descriptions
of SOAP-based security protocols and their properties. Our TulaFale language is
based on the pi calculus (for writing collections of SOAP processors running in
parallel), plus XML syntax (to express SOAP messaging), logical predicates (to
construct and filter SOAP messages), and correspondence assertions (to specify
authentication goals of protocols). Our implementation compiles TulaFale into
the applied pi calculus, and then runs Blanchet's resolution-based protocol
verifier. Hence, we can automatically verify authentication properties of SOAP
protocols.
"
0412055,Robotic Applications in Cardiac Surgery,"  Traditionally, cardiac surgery has been performed through a median
sternotomy, which allows the surgeon generous access to the heart and
surrounding great vessels. As a paradigm shift in the size and location of
incisions occurs in cardiac surgery, new methods have been developed to allow
the surgeon the same amount of dexterity and accessibility to the heart in
confined spaces and in a less invasive manner. Initially, long instruments
without pivot points were used, however, more recent robotic telemanipulation
systems have been applied that allow for improved dexterity, enabling the
surgeon to perform cardiac surgery from a distance not previously possible. In
this rapidly evolving field, we review the recent history and clinical results
of using robotics in cardiac surgery.
"
0412059,"Vector Symbolic Architectures answer Jackendoff's challenges for
  cognitive neuroscience","  Jackendoff (2002) posed four challenges that linguistic combinatoriality and
rules of language present to theories of brain function. The essence of these
problems is the question of how to neurally instantiate the rapid construction
and transformation of the compositional structures that are typically taken to
be the domain of symbolic processing. He contended that typical connectionist
approaches fail to meet these challenges and that the dialogue between
linguistic theory and cognitive neuroscience will be relatively unproductive
until the importance of these problems is widely recognised and the challenges
answered by some technical innovation in connectionist modelling. This paper
claims that a little-known family of connectionist models (Vector Symbolic
Architectures) are able to meet Jackendoff's challenges.
"
0412070,Less is More - Genetic Optimisation of Nearest Neighbour Classifiers,"  The present paper deals with optimisation of Nearest Neighbour rule
Classifiers via Genetic Algorithms. The methodology consists on implement a
Genetic Algorithm capable of search the input feature space used by the NNR
classifier. Results show that is adequate to perform feature reduction and
simultaneous improve the Recognition Rate. Some practical examples prove that
is possible to Recognise Portuguese Granites in 100%, with only 3 morphological
features (from an original set of 117 features), which is well suited for real
time applications. Moreover, the present method represents a robust strategy to
understand the proper nature of the images treated, and their discriminant
features. KEYWORDS: Feature Reduction, Genetic Algorithms, Nearest Neighbour
Rule Classifiers (k-NNR).
"
0412077,"On the Implicit and on the Artificial - Morphogenesis and Emergent
  Aesthetics in Autonomous Collective Systems","  Imagine a ""machine"" where there is no pre-commitment to any particular
representational scheme: the desired behaviour is distributed and roughly
specified simultaneously among many parts, but there is minimal specification
of the mechanism required to generate that behaviour, i.e. the global behaviour
evolves from the many relations of multiple simple behaviours. A machine that
lives to and from/with Synergy. An artificial super-organism that avoids
specific constraints and emerges within multiple low-level implicit
bio-inspired mechanisms. KEYWORDS: Complex Science, ArtSBots Project, Swarm
Intelligence, Stigmergy, UnManned Art, Symbiotic Art, Swarm Paintings, Robot
Paintings, Non-Human Art, Painting Emergence and Cooperation, Art and
Complexity, ArtBots: The Robot Talent Show.
"
0412085,A class of one-dimensional MDS convolutional codes,"  A class of one-dimensional convolutional codes will be presented. They are
all MDS codes, i. e., have the largest distance among all one-dimensional codes
of the same length n and overall constraint length delta. Furthermore, their
extended row distances are computed, and they increase with slope n-delta. In
certain cases of the algebraic parameters, we will also derive parity check
matrices of Vandermonde type for these codes. Finally, cyclicity in the
convolutional sense will be discussed for our class of codes. It will turn out
that they are cyclic if and only if the field element used in the generator
matrix has order n. This can be regarded as a generalization of the block code
case.
"
0412102,Quantum Interactive Proofs with Competing Provers,"  This paper studies quantum refereed games, which are quantum interactive
proof systems with two competing provers: one that tries to convince the
verifier to accept and the other that tries to convince the verifier to reject.
We prove that every language having an ordinary quantum interactive proof
system also has a quantum refereed game in which the verifier exchanges just
one round of messages with each prover. A key part of our proof is the fact
that there exists a single quantum measurement that reliably distinguishes
between mixed states chosen arbitrarily from disjoint convex sets having large
minimal trace distance from one another. We also show how to reduce the
probability of error for some classes of quantum refereed games.
"
0412120,"An estimate of accuracy for interpolant numerical solutions of a PDE
  problem","  In this paper we present an estimate of accuracy for a piecewise polynomial
approximation of a classical numerical solution to a non linear differential
problem. We suppose the numerical solution U is computed using a grid with a
small linear step and interval time Tu, while the polynomial approximation V is
an interpolation of the values of a numerical solution on a less fine grid and
interval time Tv << Tu. The estimate shows that the interpolant solution V can
be, under suitable hypotheses, a good approximation and in general its
computational cost is much lower of the cost of the fine numerical solution. We
present two possible applications to linear case and periodic case.
"
0412121,A Distributed Economics-based Infrastructure for Utility Computing,"  Existing attempts at utility computing revolve around two approaches. The
first consists of proprietary solutions involving renting time on dedicated
utility computing machines. The second requires the use of heavy, monolithic
applications that are difficult to deploy, maintain, and use.
  We propose a distributed, community-oriented approach to utility computing.
Our approach provides an infrastructure built on Web Services in which modular
components are combined to create a seemingly simple, yet powerful system. The
community-oriented nature generates an economic environment which results in
fair transactions between consumers and providers of computing cycles while
simultaneously encouraging improvements in the infrastructure of the
computational grid itself.
"
0501004,"Advances towards a General-Purpose Societal-Scale Human-Collective
  Problem-Solving Engine","  Human collective intelligence has proved itself as an important factor in a
society's ability to accomplish large-scale behavioral feats. As societies have
grown in population-size, individuals have seen a decrease in their ability to
activeily participate in the problem-solving processes of the group.
Representative decision-making structures have been used as a modern solution
to society's inadequate information-processing infrastructure. With computer
and network technologies being further embedded within the fabric of society,
the implementation of a general-purpose societal-scale human-collective
problem-solving engine is envisioned as a means of furthering the
collective-intelligence potential of society. This paper provides both a novel
framework for creating collective intelligence systems and a method for
implementing a representative and expertise system based on social-network
theory.
"
0501006,"Formal Languages and Algorithms for Similarity based Retrieval from
  Sequence Databases","  The paper considers various formalisms based on Automata, Temporal Logic and
Regular Expressions for specifying queries over sequences. Unlike traditional
binary semantics, the paper presents a similarity based semantics for thse
formalisms. More specifically, a distance measure in the range [0,1] is
associated with a sequence, query pair denoting how closely the sequence
satisfies the query. These measures are defined using a spectrum of normed
vector distance measures. Various distance measures based on the syntax and the
traditional semantics of the query are presented. Efficient algorithms for
computing these distance measure are presented. These algorithms can be
employed for retrieval of sequence from a database that closely satisfy a
given.
"
0501014,On the Design of Perceptual MPEG-Video Encryption Algorithms,"  In this paper, some existing perceptual encryption algorithms of MPEG videos
are reviewed and some problems, especially security defects of two recently
proposed MPEG-video perceptual encryption schemes, are pointed out. Then, a
simpler and more effective design is suggested, which selectively encrypts
fixed-length codewords (FLC) in MPEG-video bitstreams under the control of
three perceptibility factors. The proposed design is actually an encryption
configuration that can work with any stream cipher or block cipher. Compared
with the previously-proposed schemes, the new design provides more useful
features, such as strict size-preservation, on-the-fly encryption and multiple
perceptibility, which make it possible to support more applications with
different requirements. In addition, four different measures are suggested to
provide better security against known/chosen-plaintext attacks.
"
0501028,"An Empirical Study of MDL Model Selection with Infinite Parametric
  Complexity","  Parametric complexity is a central concept in MDL model selection. In
practice it often turns out to be infinite, even for quite simple models such
as the Poisson and Geometric families. In such cases, MDL model selection as
based on NML and Bayesian inference based on Jeffreys' prior can not be used.
Several ways to resolve this problem have been proposed. We conduct experiments
to compare and evaluate their behaviour on small sample sizes.
  We find interestingly poor behaviour for the plug-in predictive code; a
restricted NML model performs quite well but it is questionable if the results
validate its theoretical motivation. The Bayesian model with the improper
Jeffreys' prior is the most dependable.
"
0501040,"Split-2 Bisimilarity has a Finite Axiomatization over CCS with<br>
  Hennessy&#39;s Merge","  This note shows that split-2 bisimulation equivalence (also known as timed
equivalence) affords a finite equational axiomatization over the process
algebra obtained by adding an auxiliary operation proposed by Hennessy in 1981
to the recursion, relabelling and restriction free fragment of Milner's
Calculus of Communicating Systems. Thus the addition of a single binary
operation, viz. Hennessy's merge, is sufficient for the finite equational
axiomatization of parallel composition modulo this non-interleaving
equivalence. This result is in sharp contrast to a theorem previously obtained
by the same authors to the effect that the same language is not finitely based
modulo bisimulation equivalence.
"
0501048,"Low Complexity Joint Iterative Equalization and Multiuser Detection in
  Dispersive DS-CDMA Channels","  Communications in dispersive direct-sequence code-division multiple-access
(DS-CDMA) channels suffer from intersymbol and multiple-access interference,
which can significantly impair performance. Joint maximum \textit{a posteriori}
probability (MAP) equalization and multiuser detection with error control
decoding can be used to mitigate this interference and to achieve the optimal
bit error rate. Unfortunately, such optimal detection typically requires
prohibitive computational complexity. This problem is addressed in this paper
through the development of a reduced state trellis search detection algorithm,
based on decision feedback from channel decoders. The performance of this
algorithm is analyzed in the large-system limit. This analysis and simulations
show that this low-complexity algorithm can obtain near-optimal performance
under moderate signal-to-noise ratio and attains larger system load capacity
than parallel interference cancellation.
"
0501055,Consistency Problems for Jump-Diffusion Models,"  In this paper consistency problems for multi-factor jump-diffusion models,
where the jump parts follow multivariate point processes are examined. First
the gap between jump-diffusion models and generalized Heath-Jarrow-Morton (HJM)
models is bridged. By applying the drift condition for a generalized
arbitrage-free HJM model, the consistency condition for jump-diffusion models
is derived. Then we consider a case in which the forward rate curve has a
separable structure, and obtain a specific version of the general consistency
condition. In particular, a necessary and sufficient condition for a
jump-diffusion model to be affine is provided. Finally the Nelson-Siegel type
of forward curve structures is discussed. It is demonstrated that under
regularity condition, there exists no jump-diffusion model consistent with the
Nelson-Siegel curves.
"
0501063,Bandit Problems with Side Observations,"  An extension of the traditional two-armed bandit problem is considered, in
which the decision maker has access to some side information before deciding
which arm to pull. At each time t, before making a selection, the decision
maker is able to observe a random variable X_t that provides some information
on the rewards to be obtained. The focus is on finding uniformly good rules
(that minimize the growth rate of the inferior sampling time) and on
quantifying how much the additional information helps. Various settings are
considered and for each setting, lower bounds on the achievable inferior
sampling time are developed and asymptotically optimal adaptive schemes
achieving these lower bounds are constructed.
"
0501074,Efficient Computation of the Characteristic Polynomial,"  This article deals with the computation of the characteristic polynomial of
dense matrices over small finite fields and over the integers. We first present
two algorithms for the finite fields: one is based on Krylov iterates and
Gaussian elimination. We compare it to an improvement of the second algorithm
of Keller-Gehrig. Then we show that a generalization of Keller-Gehrig's third
algorithm could improve both complexity and computational time. We use these
results as a basis for the computation of the characteristic polynomial of
integer matrices. We first use early termination and Chinese remaindering for
dense matrices. Then a probabilistic approach, based on integer minimal
polynomial and Hensel factorization, is particularly well suited to sparse
and/or structured matrices.
"
0501075,"Simple extractors via constructions of cryptographic pseudo-random
  generators","  Trevisan has shown that constructions of pseudo-random generators from hard
functions (the Nisan-Wigderson approach) also produce extractors. We show that
constructions of pseudo-random generators from one-way permutations (the
Blum-Micali-Yao approach) can be used for building extractors as well. Using
this new technique we build extractors that do not use designs and
polynomial-based error-correcting codes and that are very simple and efficient.
For example, one extractor produces each output bit separately in $O(\log^2 n)$
time. These extractors work for weak sources with min entropy $\lambda n$, for
arbitrary constant $\lambda > 0$, have seed length $O(\log^2 n)$, and their
output length is $\approx n^{\lambda/3}$.
"
0501085,Space Frequency Codes from Spherical Codes,"  A new design method for high rate, fully diverse ('spherical') space
frequency codes for MIMO-OFDM systems is proposed, which works for arbitrary
numbers of antennas and subcarriers. The construction exploits a differential
geometric connection between spherical codes and space time codes. The former
are well studied e.g. in the context of optimal sequence design in CDMA
systems, while the latter serve as basic building blocks for space frequency
codes. In addition a decoding algorithm with moderate complexity is presented.
This is achieved by a lattice based construction of spherical codes, which
permits lattice decoding algorithms and thus offers a substantial reduction of
complexity.
"
0502009,"Performance Considerations for Gigabyte per Second Transcontinental
  Disk-to-Disk File Transfers","  Moving data from CERN to Pasadena at a gigabyte per second using the next
generation Internet requires good networking and good disk IO. Ten Gbps
Ethernet and OC192 links are in place, so now it is simply a matter of
programming. This report describes our preliminary work and measurements in
configuring the disk subsystem for this effort. Using 24 SATA disks at each
endpoint we are able to locally read and write an NTFS volume is striped across
24 disks at 1.2 GBps. A 32-disk stripe delivers 1.7 GBps. Experiments on higher
performance and higher-capacity systems deliver up to 3.5 GBps.
"
0502012,Sequential File Programming Patterns and Performance with .NET,"  Programming patterns for sequential file access in the .NET Framework are
described and the performance is measured. The default behavior provides
excellent performance on a single disk - 50 MBps both reading and writing.
Using large request sizes and doing file pre-allocation when possible have
quantifiable benefits. When one considers disk arrays, .NET unbuffered IO
delivers 800 MBps on a 16-disk array, but buffered IO delivers about 12% of
that performance. Consequently, high-performance file and database utilities
are still forced to use unbuffered IO for maximum sequential performance. The
report is accompanied by downloadable source code that demonstrates the
concepts and code that was used to obtain these measurements.
"
0502019,"A Price-Anticipating Resource Allocation Mechanism for Distributed
  Shared Clusters","  In this paper we formulate the fixed budget resource allocation game to
understand the performance of a distributed market-based resource allocation
system. Multiple users decide how to distribute their budget (bids) among
multiple machines according to their individual preferences to maximize their
individual utility. We look at both the efficiency and the fairness of the
allocation at the equilibrium, where fairness is evaluated through the measures
of utility uniformity and envy-freeness. We show analytically and through
simulations that despite being highly decentralized, such a system converges
quickly to an equilibrium and unlike the social optimum that achieves high
efficiency but poor fairness, the proposed allocation scheme achieves a nice
balance of high degrees of efficiency and fairness at the equilibrium.
"
0502020,Population Sizing for Genetic Programming Based Upon Decision Making,"  This paper derives a population sizing relationship for genetic programming
(GP). Following the population-sizing derivation for genetic algorithms in
Goldberg, Deb, and Clark (1992), it considers building block decision making as
a key facet. The analysis yields a GP-unique relationship because it has to
account for bloat and for the fact that GP solutions often use subsolution
multiple times. The population-sizing relationship depends upon tree size,
solution complexity, problem difficulty and building block expression
probability. The relationship is used to analyze and empirically investigate
population sizing for three model GP problems named ORDER, ON-OFF and LOUD.
These problems exhibit bloat to differing extents and differ in whether their
solutions require the use of a building block multiple times.
"
0502022,Sub-Structural Niching in Non-Stationary Environments,"  Niching enables a genetic algorithm (GA) to maintain diversity in a
population. It is particularly useful when the problem has multiple optima
where the aim is to find all or as many as possible of these optima. When the
fitness landscape of a problem changes overtime, the problem is called
non--stationary, dynamic or time--variant problem. In these problems, niching
can maintain useful solutions to respond quickly, reliably and accurately to a
change in the environment. In this paper, we present a niching method that
works on the problem substructures rather than the whole solution, therefore it
has less space complexity than previously known niching mechanisms. We show
that the method is responding accurately when environmental changes occur.
"
0502035,"Near Maximum-Likelihood Performance of Some New Cyclic Codes Constructed
  in the Finite-Field Transform Domain","  It is shown that some well-known and some new cyclic codes with orthogonal
parity-check equations can be constructed in the finite-field transform domain.
It is also shown that, for some binary linear cyclic codes, the performance of
the iterative decoder can be improved by substituting some of the dual code
codewords in the parity-check matrix with other dual code codewords formed from
linear combinations. This technique can bring the performance of a code closer
to its maximum-likelihood performance, which can be derived from the erroneous
decoded codeword whose euclidean distance with the respect to the received
block is smaller than that of the correct codeword. For (63,37), (93,47) and
(105,53) cyclic codes, the maximum-likelihood performance is realised with this
technique.
"
0502038,The Number of Spanning Trees in Kn-complements of Quasi-threshold Graphs,"  In this paper we examine the classes of graphs whose $K_n$-complements are
trees and quasi-threshold graphs and derive formulas for their number of
spanning trees; for a subgraph $H$ of $K_n$, the $K_n$-complement of $H$ is the
graph $K_n-H$ which is obtained from $K_n$ by removing the edges of $H$. Our
proofs are based on the complement spanning-tree matrix theorem, which
expresses the number of spanning trees of a graph as a function of the
determinant of a matrix that can be easily constructed from the adjacency
relation of the graph. Our results generalize previous results and extend the
family of graphs of the form $K_n-H$ admitting formulas for the number of their
spanning trees.
"
0502052,Log Analysis Case Study Using LoGS,"  A very useful technique a network administrator can use to identify
problematic network behavior is careful analysis of logs of incoming and
outgoing network flows. The challenge one faces when attempting to undertake
this course of action, though, is that large networks tend to generate an
extremely large quantity of network traffic in a very short period of time,
resulting in very large traffic logs which must be analyzed post-generation
with an eye for contextual information which may reveal symptoms of problematic
traffic. A better technique is to perform real-time log analysis using a
real-time context-generating tool such as LoGS.
"
0502054,Improved Tag Set Design and Multiplexing Algorithms for Universal Arrays,"  In this paper we address two optimization problems arising in the design of
genomic assays based on universal tag arrays. First, we address the universal
array tag set design problem. For this problem, we extend previous formulations
to incorporate antitag-to-antitag hybridization constraints in addition to
constraints on antitag-to-tag hybridization specificity, establish a
constructive upper bound on the maximum number of tags satisfying the extended
constraints, and propose a simple greedy tag selection algorithm. Second, we
give methods for improving the multiplexing rate in large-scale genomic assays
by combining primer selection with tag assignment. Experimental results on
simulated data show that this integrated optimization leads to reductions of up
to 50% in the number of required arrays.
"
0502070,"Bidimensionality, Map Graphs, and Grid Minors","  In this paper we extend the theory of bidimensionality to two families of
graphs that do not exclude fixed minors: map graphs and power graphs. In both
cases we prove a polynomial relation between the treewidth of a graph in the
family and the size of the largest grid minor. These bounds improve the running
times of a broad class of fixed-parameter algorithms. Our novel technique of
using approximate max-min relations between treewidth and size of grid minors
is powerful, and we show how it can also be used, e.g., to prove a linear
relation between the treewidth of a bounded-genus graph and the treewidth of
its dual.
"
0502075,"How far will you walk to find your shortcut: Space Efficient Synopsis
  Construction Algorithms","  In this paper we consider the wavelet synopsis construction problem without
the restriction that we only choose a subset of coefficients of the original
data. We provide the first near optimal algorithm. We arrive at the above
algorithm by considering space efficient algorithms for the restricted version
of the problem. In this context we improve previous algorithms by almost a
linear factor and reduce the required space to almost linear. Our techniques
also extend to histogram construction, and improve the space-running time
tradeoffs for V-Opt and range query histograms. We believe the idea applies to
a broad range of dynamic programs and demonstrate it by showing improvements in
a knapsack-like setting seen in construction of Extended Wavelets.
"
0502084,On the Typicality of the Linear Code Among the LDPC Coset Code Ensemble,"  Density evolution (DE) is one of the most powerful analytical tools for
low-density parity-check (LDPC) codes on memoryless
binary-input/symmetric-output channels. The case of non-symmetric channels is
tackled either by the LDPC coset code ensemble (a channel symmetrizing
argument) or by the generalized DE for linear codes on non-symmetric channels.
Existing simulations show that the bit error rate performances of these two
different approaches are nearly identical. This paper explains this phenomenon
by proving that as the minimum check node degree $d_c$ becomes sufficiently
large, the performance discrepancy of the linear and the coset LDPC codes is
theoretically indistinguishable. This typicality of linear codes among the LDPC
coset code ensemble provides insight into the concentration theorem of LDPC
coset codes.
"
0502085,Fast generation of random connected graphs with prescribed degrees,"  We address here the problem of generating random graphs uniformly from the
set of simple connected graphs having a prescribed degree sequence. Our goal is
to provide an algorithm designed for practical use both because of its ability
to generate very large graphs (efficiency) and because it is easy to implement
(simplicity). We focus on a family of heuristics for which we prove optimality
conditions, and show how this optimality can be reached in practice. We then
propose a different approach, specifically designed for typical real-world
degree distributions, which outperforms the first one. Assuming a conjecture
which we state and argue rigorously, we finally obtain an log-linear algorithm,
which, in spite of being very simple, improves the best known complexity.
"
0502092,Divergence-free Wavelets for Navier-Stokes,"  In this paper, we investigate the use of compactly supported divergence-free
wavelets for the representation of the Navier-Stokes solution. After reminding
the theoretical construction of divergence-free wavelet vectors, we present in
detail the bases and corresponding fast algorithms for 2D and 3D incompressible
flows. In order to compute the nonlinear term, we propose a new method which
provides in practice with the Hodge decomposition of any flow: this
decomposition enables us to separate the incompressible part of the flow from
its orthogonal complement, which corresponds to the gradient component of the
flow. Finally we show numerical tests to validate our approach.
"
0503001,"Top-Down Unsupervised Image Segmentation (it sounds like oxymoron, but
  actually it is not)","  Pattern recognition is generally assumed as an interaction of two inversely
directed image-processing streams: the bottom-up information details gathering
and localization (segmentation) stream, and the top-down information features
aggregation, association and interpretation (recognition) stream. Inspired by
recent evidence from biological vision research and by the insights of
Kolmogorov Complexity theory, we propose a new, just top-down evolving,
procedure of initial image segmentation. We claim that traditional top-down
cognitive reasoning, which is supposed to guide the segmentation process to its
final result, is not at all a part of the image information content evaluation.
And that initial image segmentation is certainly an unsupervised process. We
present some illustrative examples, which support our claims.
"
0503005,"High efficiency and low absorption Fresnel compound zone plates for hard
  X-ray focusing","  Circular and linear zone plates have been fabricated on the surface of
silicon crystals for the energy of 8 keV by electron beam lithography and deep
ion plasma etching methods. Various variants of compound zone plates with
first, second, third diffraction orders have been made. The zone relief height
is about 10 mkm, the outermost zone width of the zone plate is 0.4 mkm. The
experimental testing of the zone plates has been conducted on SPring-8 and ESRF
synchrotron radiation sources. A focused spot size and diffraction efficiency
measured by knife-edge scanning are accordingly 0.5 mkm and 39% for the first
order circular zone plate.
"
0503007,"Toward alternative metrics of journal impact: A comparison of download
  and citation data","  We generated networks of journal relationships from citation and download
data, and determined journal impact rankings from these networks using a set of
social network centrality metrics. The resulting journal impact rankings were
compared to the ISI IF. Results indicate that, although social network metrics
and ISI IF rankings deviate moderately for citation-based journal networks,
they differ considerably for journal networks derived from download data. We
believe the results represent a unique aspect of general journal impact that is
not captured by the ISI IF. These results furthermore raise questions regarding
the validity of the ISI IF as the sole assessment of journal impact, and
suggest the possibility of devising impact metrics based on usage information
in general.
"
0503009,Minimal chordal sense of direction and circulant graphs,"  A sense of direction is an edge labeling on graphs that follows a globally
consistent scheme and is known to considerably reduce the complexity of several
distributed problems. In this paper, we study a particular instance of sense of
direction, called a chordal sense of direction (CSD). In special, we identify
the class of k-regular graphs that admit a CSD with exactly k labels (a minimal
CSD). We prove that connected graphs in this class are Hamiltonian and that the
class is equivalent to that of circulant graphs, presenting an efficient
(polynomial-time) way of recognizing it when the graphs' degree k is fixed.
"
0503020,Earlier Web Usage Statistics as Predictors of Later Citation Impact,"  The use of citation counts to assess the impact of research articles is well
established. However, the citation impact of an article can only be measured
several years after it has been published. As research articles are
increasingly accessed through the Web, the number of times an article is
downloaded can be instantly recorded and counted. One would expect the number
of times an article is read to be related both to the number of times it is
cited and to how old the article is. This paper analyses how short-term Web
usage impact predicts medium-term citation impact. The physics e-print archive
(arXiv.org) is used to test this.
"
0503031,"On the Scalability of Cooperative Time Synchronization in
  Pulse-Connected Networks","  The problem of time synchronization in dense wireless networks is considered.
Well established synchronization techniques suffer from an inherent scalability
problem in that synchronization errors grow with an increasing number of hops
across the network. In this work, a model for communication in wireless
networks is first developed, and then the model is used to define a new time
synchronization mechanism. A salient feature of the proposed method is that, in
the regime of asymptotically dense networks, it can average out all random
errors and maintain global synchronization in the sense that all nodes in the
multi-hop network can see identical timing signals. This is irrespective of the
distance separating any two nodes.
"
0503036,Timed Analysis of Security Protocols,"  We propose a method for engineering security protocols that are aware of
timing aspects. We study a simplified version of the well-known Needham
Schroeder protocol and the complete Yahalom protocol, where timing information
allows the study of different attack scenarios. We model check the protocols
using UPPAAL. Further, a taxonomy is obtained by studying and categorising
protocols from the well known Clark Jacob library and the Security Protocol
Open Repository (SPORE) library. Finally, we present some new challenges and
threats that arise when considering time in the analysis, by providing a novel
protocol that uses time challenges and exposing a timing attack over an
implementation of an existing security protocol.
"
0503041,Soft Handoff and Uplink Capacity in a Two-Tier CDMA System,"  This paper examines the effect of soft handoff on the uplink user capacity of
a CDMA system consisting of a single macrocell in which a single hotspot
microcell is embedded. The users of these two base stations operate over the
same frequency band. In the soft handoff scenario studied here, both macrocell
and microcell base stations serve each system user and the two received copies
of a desired user's signal are summed using maximal ratio combining. Exact and
approximate analytical methods are developed to compute uplink user capacity.
Simulation results demonstrate a 20% increase in user capacity compared to hard
handoff. In addition, simple, approximate methods are presented for estimating
soft handoff capacity and are shown to be quite accurate.
"
0503060,Multi-Dimensional Hash Chains and Application to Micropayment Schemes,"  One-way hash chains have been used in many micropayment schemes due to their
simplicity and efficiency. In this paper we introduce the notion of
multi-dimensional hash chains, which is a new generalization of traditional
one-way hash chains. We show that this construction has storage-computational
complexity of O(logN) per chain element, which is comparable with the best
result reported in recent literature. Based on multi-dimensional hash chains,
we then propose two cash-like micropayment schemes, which have a number of
advantages in terms of efficiency and security. We also point out some possible
improvements to PayWord and similar schemes by using multi-dimensional hash
chains
"
0503067,Contextual equivalence for higher-order pi-calculus revisited,"  The higher-order pi-calculus is an extension of the pi-calculus to allow
communication of abstractions of processes rather than names alone. It has been
studied intensively by Sangiorgi in his thesis where a characterisation of a
contextual equivalence for higher-order pi-calculus is provided using labelled
transition systems and normal bisimulations. Unfortunately the proof technique
used there requires a restriction of the language to only allow finite types.
We revisit this calculus and offer an alternative presentation of the labelled
transition system and a novel proof technique which allows us to provide a
fully abstract characterisation of contextual equivalence using labelled
transitions and bisimulations for higher-order pi-calculus with recursive types
also.
"
0503069,mod_oai: An Apache Module for Metadata Harvesting,"  We describe mod_oai, an Apache 2.0 module that implements the Open Archives
Initiative Protocol for Metadata Harvesting (OAI-PMH). OAIPMH is the de facto
standard for metadata exchange in digital libraries and allows repositories to
expose their contents in a structured, application-neutral format with
semantics optimized for accurate incremental harvesting. Current
implementations of OAI-PMH are either separate applications that access an
existing repository, or are built-in to repository software packages. mod_oai
is different in that it optimizes harvesting web content by building OAI-PMH
capability into the Apache server. We discuss the implications of adding
harvesting capability to an Apache server and describe our initial experimental
results accessing a departmental web site using both web crawling and OAIPMH
harvesting techniques.
"
0503073,Tensor manipulation in GPL Maxima,"  GPL Maxima is an open-source computer algebra system based on DOE-MACSYMA.
GPL Maxima included two tensor manipulation packages from DOE-MACSYMA, but
these were in various states of disrepair. One of the two packages, CTENSOR,
implemented component-based tensor manipulation; the other, ITENSOR, treated
tensor symbols as opaque, manipulating them based on their index properties.
The present paper describes the state in which these packages were found, the
steps that were needed to make the packages fully functional again, and the new
functionality that was implemented to make them more versatile. A third
package, ATENSOR, was also implemented; fully compatible with the identically
named package in the commercial version of MACSYMA, ATENSOR implements abstract
tensor algebras.
"
0503074,A File System Abstraction for Sense and Respond Systems,"  The heterogeneity and resource constraints of sense-and-respond systems pose
significant challenges to system and application development. In this paper, we
present a flexible, intuitive file system abstraction for organizing and
managing sense-and-respond systems based on the Plan 9 design principles. A key
feature of this abstraction is the ability to support multiple views of the
system via filesystem namespaces. Constructed logical views present an
application-specific representation of the network, thus enabling high-level
programming of the network. Concurrently, structural views of the network
enable resource-efficient planning and execution of tasks. We present and
motivate the design using several examples, outline research challenges and our
research plan to address them, and describe the current state of
implementation.
"
0503081,An Optimization Model for Outlier Detection in Categorical Data,"  The task of outlier detection is to find small groups of data objects that
are exceptional when compared with rest large amount of data. Detection of such
outliers is important for many applications such as fraud detection and
customer migration. Most existing methods are designed for numeric data. They
will encounter problems with real-life applications that contain categorical
data. In this paper, we formally define the problem of outlier detection in
categorical data as an optimization problem from a global viewpoint. Moreover,
we present a local-search heuristic based algorithm for efficiently finding
feasible solutions. Experimental results on real datasets and large synthetic
datasets demonstrate the superiority of our model and algorithm.
"
0503091,Resource Bounded Unprovability of Computational Lower Bounds,"  This paper introduces new notions of asymptotic proofs,
PT(polynomial-time)-extensions, PTM(polynomial-time Turing
machine)-omega-consistency, etc. on formal theories of arithmetic including PA
(Peano Arithmetic). This paper shows that P not= NP (more generally, any
super-polynomial-time lower bound in PSPACE) is unprovable in a
PTM-omega-consistent theory T, where T is a consistent PT-extension of PA. This
result gives a unified view to the existing two major negative results on
proving P not= NP, Natural Proofs and relativizable proofs, through the two
manners of characterization of PTM-omega-consistency. We also show that the
PTM-omega-consistency of T cannot be proven in any PTM-omega-consistent theory
S, where S is a consistent PT-extension of T.
"
0504001,Probabilistic and Team PFIN-type Learning: General Properties,"  We consider the probability hierarchy for Popperian FINite learning and study
the general properties of this hierarchy. We prove that the probability
hierarchy is decidable, i.e. there exists an algorithm that receives p_1 and
p_2 and answers whether PFIN-type learning with the probability of success p_1
is equivalent to PFIN-type learning with the probability of success p_2.
  To prove our result, we analyze the topological structure of the probability
hierarchy. We prove that it is well-ordered in descending ordering and
order-equivalent to ordinal epsilon_0. This shows that the structure of the
hierarchy is very complicated.
  Using similar methods, we also prove that, for PFIN-type learning, team
learning and probabilistic learning are of the same power.
"
0504021,Near Perfect Decoding of LDPC Codes,"  Cooperative optimization is a new way for finding global optima of
complicated functions of many variables. It has some important properties not
possessed by any conventional optimization methods. It has been successfully
applied in solving many large scale optimization problems in image processing,
computer vision, and computational chemistry. This paper shows the application
of this optimization principle in decoding LDPC codes, which is another hard
combinatorial optimization problem. In our experiments, it significantly
out-performed the sum-product algorithm, the best known method for decoding
LDPC codes. Compared to the sum-product algorithm, our algorithm reduced the
error rate further by three fold, improved the speed by six times, and lowered
error floors dramatically in the decoding.
"
0504027,Linear Datalog and Bounded Path Duality of Relational Structures,"  In this paper we systematically investigate the connections between logics
with a finite number of variables, structures of bounded pathwidth, and linear
Datalog Programs. We prove that, in the context of Constraint Satisfaction
Problems, all these concepts correspond to different mathematical embodiments
of a unique robust notion that we call bounded path duality. We also study the
computational complexity implications of the notion of bounded path duality. We
show that every constraint satisfaction problem $\csp(\best)$ with bounded path
duality is solvable in NL and that this notion explains in a uniform way all
families of CSPs known to be in NL. Finally, we use the results developed in
the paper to identify new problems in NL.
"
0504040,DTN Routing in a Mobility Pattern Space,"  Routing in Delay Tolerant Networks (DTNs) benefits considerably if one can
take advantage of knowledge concerning node mobility. The main contribution of
this paper is the definition of a generic routing scheme for DTNs using a
high-dimensional Euclidean space constructed upon nodes' mobility patterns. For
example, nodes are represented as points having as coordinates their
probability of being found in each possible location. We present simulation
results indicating that such a scheme can be beneficial in a scenario inspired
by studies done on real mobility traces. This work should open the way to
further use of the virtual space formalism in DTN routing.
"
0504053,A Neural-Network Technique for Recognition of Filaments in Solar Images,"  We describe a new neural-network technique developed for an automated
recognition of solar filaments visible in the hydrogen H-alpha line full disk
spectroheliograms. This technique allows neural networks learn from a few image
fragments labelled manually to recognize the single filaments depicted on a
local background. The trained network is able to recognize filaments depicted
on the backgrounds with variations in brightness caused by atmospherics
distortions. Despite the difference in backgrounds in our experiments the
neural network has properly recognized filaments in the testing image
fragments. Using a parabolic activation function we extend this technique to
recognize multiple solar filaments which may appear in one fragment.
"
0504069,A Neural-Network Technique to Learn Concepts from Electroencephalograms,"  A new technique is presented developed to learn multi-class concepts from
clinical electroencephalograms. A desired concept is represented as a neuronal
computational model consisting of the input, hidden, and output neurons. In
this model the hidden neurons learn independently to classify the
electroencephalogram segments presented by spectral and statistical features.
This technique has been applied to the electroencephalogram data recorded from
65 sleeping healthy newborns in order to learn a brain maturation concept of
newborns aged between 35 and 51 weeks. The 39399 and 19670 segments from these
data have been used for learning and testing the concept, respectively. As a
result, the concept has correctly classified 80.1% of the testing segments or
87.7% of the 65 records.
"
0504070,"The Combined Technique for Detection of Artifacts in Clinical
  Electroencephalograms of Sleeping Newborns","  In this paper we describe a new method combining the polynomial neural
network and decision tree techniques in order to derive comprehensible
classification rules from clinical electroencephalograms (EEGs) recorded from
sleeping newborns. These EEGs are heavily corrupted by cardiac, eye movement,
muscle and noise artifacts and as a consequence some EEG features are
irrelevant to classification problems. Combining the polynomial network and
decision tree techniques, we discover comprehensible classification rules
whilst also attempting to keep their classification error down. This technique
is shown to outperform a number of commonly used machine learning technique
applied to automatically recognize artifacts in the sleep EEGs.
"
0504071,Proceedings of the Pacific Knowledge Acquisition Workshop 2004,"  Artificial intelligence (AI) research has evolved over the last few decades
and knowledge acquisition research is at the core of AI research. PKAW-04 is
one of three international knowledge acquisition workshops held in the
Pacific-Rim, Canada and Europe over the last two decades. PKAW-04 has a strong
emphasis on incremental knowledge acquisition, machine learning, neural nets
and active mining.
  The proceedings contain 19 papers that were selected by the program committee
among 24 submitted papers. All papers were peer reviewed by at least two
reviewers. The papers in these proceedings cover the methods and tools as well
as the applications related to develop expert systems or knowledge based
systems.
"
0504077,The Modified Scheme is still vulnerable to the parallel Session Attack,"  In 2002, Chien&#8211;Jan&#8211;Tseng introduced an efficient remote user
authentication scheme using smart cards. Further, in 2004, W. C. Ku and S. M.
Chen proposed an efficient remote user authentication scheme using smart cards
to solve the security problems of Chien et al.&#8217;s scheme. Recently, Hsu
and Yoon et al. pointed out the security weakness of the Ku and Chen&#8217;s
scheme Furthermore, Yoon et al. modified the password change phase of Ku and
Chen&#8217;s scheme and they also proposed a new efficient remote user
authentication scheme using smart cards. This paper analyzes that the modified
scheme of Yoon et al. still vulnerable to parallel session attack.
"
0504078,Adaptive Online Prediction by Following the Perturbed Leader,"  When applying aggregating strategies to Prediction with Expert Advice, the
learning rate must be adaptively tuned. The natural choice of
sqrt(complexity/current loss) renders the analysis of Weighted Majority
derivatives quite complicated. In particular, for arbitrary weights there have
been no results proven so far. The analysis of the alternative ""Follow the
Perturbed Leader"" (FPL) algorithm from Kalai & Vempala (2003) (based on
Hannan's algorithm) is easier. We derive loss bounds for adaptive learning rate
and both finite expert classes with uniform weights and countable expert
classes with arbitrary weights. For the former setup, our loss bounds match the
best known results so far, while for the latter our results are new.
"
0504086,Componentwise Least Squares Support Vector Machines,"  This chapter describes componentwise Least Squares Support Vector Machines
(LS-SVMs) for the estimation of additive models consisting of a sum of
nonlinear components. The primal-dual derivations characterizing LS-SVMs for
the estimation of the additive model result in a single set of linear equations
with size growing in the number of data-points. The derivation is elaborated
for the classification as well as the regression case. Furthermore, different
techniques are proposed to discover structure in the data by looking for sparse
components in the model based on dedicated regularization schemes on the one
hand and fusion of the componentwise LS-SVMs training with a validation
criterion on the other hand. (keywords: LS-SVMs, additive models,
regularization, structure detection)
"
0504093,A Multi-proxy Signature Scheme for Partial delegation with Warrant,"  In some cases, the original signer may delegate its signing power to a
specified proxy group while ensuring individual accountability of each
participantsigner. The proxy signature scheme that achieves such purpose is
called the multi-proxy signature scheme and the signature generated by the
specified proxy group is called multi-proxy signature for the original signer.
Recently such scheme has been discussed by Lin et al. Lins scheme is based on
partial delegation by Mambo et al. In present chapter we introduce a new
multi-proxy signature scheme, which requires less computational overhead in
comparison to Lin et al, and also fulfill the requirement of partial delegation
with warrant simultaneously.
"
0504094,"A New Remote User Authentication Scheme Using Smart Cards with Check
  Digits","  Since 1981, when Lamport introduced the remote user authentication scheme
using table, a plenty of schemes had been proposed with table and without table
using. In 1993, Chang and Wu [5] introduced Remote password authentication
scheme with smart cards. A number of remote authentication schemes with smart
cards have been proposed since then. These schemes allow a valid user to login
a remote server and access the services provided by the remote server. But
still there is no scheme to authenticate the remote proxy user. In this paper
we propose firstly, a protocol to authenticate a proxy user remotely using
smartcards.
"
0504096,"P-Selectivity, Immunity, and the Power of One Bit","  We prove that P-sel, the class of all P-selective sets, is EXP-immune, but is
not EXP/1-immune. That is, we prove that some infinite P-selective set has no
infinite EXP-time subset, but we also prove that every infinite P-selective set
has some infinite subset in EXP/1. Informally put, the immunity of P-sel is so
fragile that it is pierced by a single bit of information.
  The above claims follow from broader results that we obtain about the
immunity of the P-selective sets. In particular, we prove that for every
recursive function f, P-sel is DTIME(f)-immune. Yet we also prove that P-sel is
not \Pi_2^p/1-immune.
"
0504105,Wikis in Tuple Spaces,"  We consider storing the pages of a wiki in a tuple space and the effects this
might have on the wiki experience. In particular, wiki pages are stored in
tuples with a few identifying values such as title, author, revision date,
content, etc. and pages are retrieved by sending the tuple space templates,
such as one that gives the title but nothing else, leaving the tuple space to
resolve to a single tuple. We use a tuple space wiki to avoid deadlocks,
infinite loops, and wasted efforts when page edit contention arises and examine
how a tuple space wiki changes the wiki experience.
"
0505001,"Modelling investment in artificial stock markets: Analytical and
  Numerical Results","  In this article we study the behavior of a group of economic agents in the
context of cooperative game theory, interacting according to rules based on the
Potts Model with suitable modifications. Each agent can be thought of as
belonging to a chain, where agents can only interact with their nearest
neighbors (periodic boundary conditions are imposed). Each agent can invest an
amount &#963;_{i}=0,...,q-1. Using the transfer matrix method we study
analytically, among other things, the behavior of the investment as a function
of a control parameter (denoted &#946;) for the cases q=2 and 3. For q>3
numerical evaluation of eigenvalues and high precision numerical derivatives
are used in order to assess this information.
"
0505003,A New Kind of Hopfield Networks for Finding Global Optimum,"  The Hopfield network has been applied to solve optimization problems over
decades. However, it still has many limitations in accomplishing this task.
Most of them are inherited from the optimization algorithms it implements. The
computation of a Hopfield network, defined by a set of difference equations,
can easily be trapped into one local optimum or another, sensitive to initial
conditions, perturbations, and neuron update orders. It doesn't know how long
it will take to converge, as well as if the final solution is a global optimum,
or not. In this paper, we present a Hopfield network with a new set of
difference equations to fix those problems. The difference equations directly
implement a new powerful optimization algorithm.
"
0505021,Distant generalization by feedforward neural networks,"  This paper discusses the notion of generalization of training samples over
long distances in the input space of a feedforward neural network. Such a
generalization might occur in various ways, that differ in how great the
contribution of different training features should be.
  The structure of a neuron in a feedforward neural network is analyzed and it
is concluded, that the actual performance of the discussed generalization in
such neural networks may be problematic -- while such neural networks might be
capable for such a distant generalization, a random and spurious generalization
may occur as well.
  To illustrate the differences in generalizing of the same function by
different learning machines, results given by the support vector machines are
also presented.
"
0505066,Decision Sort and its Parallel Implementation,"  In this paper, a sorting technique is presented that takes as input a data
set whose primary key domain is known to the sorting algorithm, and works with
an time efficiency of O(n+k), where k is the primary key domain. It is shown
that the algorithm has applicability over a wide range of data sets. Later, a
parallel formulation of the same is proposed and its effectiveness is argued.
Though this algorithm is applicable over a wide range of general data sets, it
finds special application (much superior to others) in places where sorting
information that arrives in parts and in cases where input data is huge in
size.
"
0505071,Summarization Techniques for Pattern Collections in Data Mining,"  Discovering patterns from data is an important task in data mining. There
exist techniques to find large collections of many kinds of patterns from data
very efficiently. A collection of patterns can be regarded as a summary of the
data. A major difficulty with patterns is that pattern collections summarizing
the data well are often very large.
  In this dissertation we describe methods for summarizing pattern collections
in order to make them also more understandable. More specifically, we focus on
the following themes: 1) Quality value simplifications. 2) Pattern orderings.
3) Pattern chains and antichains. 4) Change profiles. 5) Inverse pattern
discovery.
"
0505074,Instance-Independent View Serializability for Semistructured Databases,"  Semistructured databases require tailor-made concurrency control mechanisms
since traditional solutions for the relational model have been shown to be
inadequate. Such mechanisms need to take full advantage of the hierarchical
structure of semistructured data, for instance allowing concurrent updates of
subtrees of, or even individual elements in, XML documents. We present an
approach for concurrency control which is document-independent in the sense
that two schedules of semistructured transactions are considered equivalent if
they are equivalent on all possible documents. We prove that it is decidable in
polynomial time whether two given schedules in this framework are equivalent.
This also solves the view serializability for semistructured schedules
polynomially in the size of the schedule and exponentially in the number of
transactions.
"
0506008,Bounds on the Automata Size for Presburger Arithmetic,"  Automata provide a decision procedure for Presburger arithmetic. However,
until now only crude lower and upper bounds were known on the sizes of the
automata produced by this approach. In this paper, we prove an upper bound on
the the number of states of the minimal deterministic automaton for a
Presburger arithmetic formula. This bound depends on the length of the formula
and the quantifiers occurring in the formula. The upper bound is established by
comparing the automata for Presburger arithmetic formulas with the formulas
produced by a quantifier elimination method. We also show that our bound is
tight, even for nondeterministic automata. Moreover, we provide optimal
automata constructions for linear equations and inequations.
"
0506031,A Constrained Object Model for Configuration Based Workflow Composition,"  Automatic or assisted workflow composition is a field of intense research for
applications to the world wide web or to business process modeling. Workflow
composition is traditionally addressed in various ways, generally via theorem
proving techniques. Recent research observed that building a composite workflow
bears strong relationships with finite model search, and that some workflow
languages can be defined as constrained object metamodels . This lead to
consider the viability of applying configuration techniques to this problem,
which was proven feasible. Constrained based configuration expects a
constrained object model as input. The purpose of this document is to formally
specify the constrained object model involved in ongoing experiments and
research using the Z specification language.
"
0506036,Non prefix-free codes for constrained sequences,"  In this paper we consider the use of variable length non prefix-free codes
for coding constrained sequences of symbols. We suppose to have a Markov source
where some state transitions are impossible, i.e. the stochastic matrix
associated with the Markov chain has some null entries. We show that classic
Kraft inequality is not a necessary condition, in general, for unique
decodability under the above hypothesis and we propose a relaxed necessary
inequality condition. This allows, in some cases, the use of non prefix-free
codes that can give very good performance, both in terms of compression and
computational efficiency. Some considerations are made on the relation between
the proposed approach and other existing coding paradigms.
"
0506048,Enriching a Text by Semantic Disambiguation for Information Extraction,"  External linguistic resources have been used for a very long time in
information extraction. These methods enrich a document with data that are
semantically equivalent, in order to improve recall. For instance, some of
these methods use synonym dictionaries. These dictionaries enrich a sentence
with words that have a similar meaning. However, these methods present some
serious drawbacks, since words are usually synonyms only in restricted
contexts. The method we propose here consists of using word sense
disambiguation rules (WSD) to restrict the selection of synonyms to only these
that match a specific syntactico-semantic context. We show how WSD rules are
built and how information extraction techniques can benefit from the
application of these rules.
"
0506052,Comments on `Bit Interleaved Coded Modulation',"  Caire, Taricco and Biglieri presented a detailed analysis of bit interleaved
coded modulation, a simple and popular technique used to improve system
performance, especially in the context of fading channels. They derived an
upper bound to the probability of error, called the expurgated bound. In this
correspondence, the proof of the expurgated bound is shown to be flawed. A new
upper bound is also derived. It is not known whether the original expurgated
bound is valid for the important special case of square QAM with Gray labeling,
but the new bound is very close to, and slightly tighter than, the original
bound for a numerical example.
"
0506061,Security Policies as Membranes in Systems for Global Computing,"  We propose a simple global computing framework, whose main concern is code
migration. Systems are structured in sites, and each site is divided into two
parts: a computing body, and a membrane, which regulates the interactions
between the computing body and the external environment. More precisely,
membranes are filters which control access to the associated site, and they
also rely on the well-established notion of trust between sites. We develop a
basic theory to express and enforce security policies via membranes. Initially,
these only control the actions incoming agents intend to perform locally. We
then adapt the basic theory to encompass more sophisticated policies, where the
number of actions an agent wants to perform, and also their order, are
considered.
"
0506069,A generating function method for the average-case analysis of DPLL,"  A method to calculate the average size of Davis-Putnam-Loveland-Logemann
(DPLL) search trees for random computational problems is introduced, and
applied to the satisfiability of random CNF formulas (SAT) and the coloring of
random graph (COL) problems. We establish recursion relations for the
generating functions of the average numbers of (variable or color) assignments
at a given height in the search tree, which allow us to derive the asymptotics
of the expected DPLL tree size, 2^{N w + o(N)}, where N is the instance size. w
is calculated as a function of the input distribution parameters (ratio of
clauses per variable for SAT, average vertex degree for COL), and the branching
heuristics.
"
0506078,Dynamical Neural Network: Information and Topology,"  A neural network works as an associative memory device if it has large
storage capacity and the quality of the retrieval is good enough. The learning
and attractor abilities of the network both can be measured by the mutual
information (MI), between patterns and retrieval states. This paper deals with
a search for an optimal topology, of a Hebb network, in the sense of the
maximal MI. We use small-world topology. The connectivity $\gamma$ ranges from
an extremely diluted to the fully connected network; the randomness $\omega$
ranges from purely local to completely random neighbors. It is found that,
while stability implies an optimal $MI(\gamma,\omega)$ at
$\gamma_{opt}(\omega)\to 0$, for the dynamics, the optimal topology holds at
certain $\gamma_{opt}>0$ whenever $0\leq\omega<0.3$.
"
0506086,"Large System Decentralized Detection Performance Under Communication
  Constraints","  The problem of decentralized detection in a sensor network subjected to a
total average power constraint and all nodes sharing a common bandwidth is
investigated. The bandwidth constraint is taken into account by assuming
non-orthogonal communication between sensors and the data fusion center via
direct-sequence code-division multiple-access (DS-CDMA). In the case of large
sensor systems and random spreading, the asymptotic decentralized detection
performance is derived assuming independent and identically distributed (iid)
sensor observations via random matrix theory. The results show that, even under
both power and bandwidth constraints, it is better to combine many not-so-good
local decisions rather than relying on one (or a few) very-good local
decisions.
"
0506090,An Exact 2.9416^n Algorithm for the Three Domatic Number Problem,"  The three domatic number problem asks whether a given undirected graph can be
partitioned into at least three dominating sets, i.e., sets whose closed
neighborhood equals the vertex set of the graph. Since this problem is
NP-complete, no polynomial-time algorithm is known for it. The naive
deterministic algorithm for this problem runs in time 3^n, up to polynomial
factors. In this paper, we design an exact deterministic algorithm for this
problem running in time 2.9416^n. Thus, our algorithm can handle problem
instances of larger size than the naive algorithm in the same amount of time.
We also present another deterministic and a randomized algorithm for this
problem that both have an even better performance for graphs with small maximum
degree.
"
0506092,"Emergent Statistical Wealth Distributions in Simple Monetary Exchange
  Models: A Critical Review","  This paper reviews recent attempts at modelling inequality of wealth as an
emergent phenomenon of interacting-agent processes. We point out that recent
models of wealth condensation which draw their inspiration from molecular
dynamics have, in fact, reinvented a process introduced quite some time ago by
Angle (1986) in the sociological literature. We emphasize some problematic
aspects of simple wealth exchange models and contrast them with a monetary
model based on economic principles of market mediated exchange. The paper also
reports new results on the influence of market power on the wealth distribution
in statistical equilibrium. As it turns out, inequality increases but market
power alone is not sufficient for changing the exponential tails of simple
exchange models into Pareto tails.
"
0506094,"Universal Codes as a Basis for Nonparametric Testing of Serial
  Independence for Time Series","  We consider a stationary and ergodic source $p$ generated symbols $x_1 ...
x_t$ from some finite set $A$ and a null hypothesis $H_0$ that $p$ is Markovian
source with memory (or connectivity) not larger than $m, (m >= 0).$ The
alternative hypothesis $H_1$ is that the sequence is generated by a stationary
and ergodic source, which differs from the source under $H_0$. In particular,
if $m= 0$ we have the null hypothesis $H_0$ that the sequence is generated by
Bernoully source (or the hypothesis that $x_1 ...x_t$ are independent.) Some
new tests which are based on universal codes and universal predictors, are
suggested.
"
0506101,Efficient Multiclass Implementations of L1-Regularized Maximum Entropy,"  This paper discusses the application of L1-regularized maximum entropy
modeling or SL1-Max [9] to multiclass categorization problems. A new
modification to the SL1-Max fast sequential learning algorithm is proposed to
handle conditional distributions. Furthermore, unlike most previous studies,
the present research goes beyond a single type of conditional distribution. It
describes and compares a variety of modeling assumptions about the class
distribution (independent or exclusive) and various types of joint or
conditional distributions. It results in a new methodology for combining binary
regularized classifiers to achieve multiclass categorization. In this context,
Maximum Entropy can be considered as a generic and efficient regularized
classification tool that matches or outperforms the state-of-the art
represented by AdaBoost and SVMs.
"
0507001,Asymptotically Optimal Tree-based Group Key Management Schemes,"  In key management schemes that realize secure multicast communications
encrypted by group keys on a public network, tree structures are often used to
update the group keys efficiently. Selcuk and Sidhu have proposed an efficient
scheme which updates dynamically the tree structures based on the withdrawal
probabilities of members. In this paper, it is shown that Selcuk-Sidhu scheme
is asymptotically optimal for the cost of withdrawal. Furthermore, a new key
management scheme, which takes account of key update costs of joining in
addition to withdrawal, is proposed. It is proved that the proposed scheme is
also asymptotically optimal, and it is shown by simulation that it can attain
good performance for nonasymptotic cases.
"
0507008,Complexity Science for Simpletons,"  In this article, we shall describe some of the most interesting topics in the
subject of Complexity Science for a general audience. Anyone with a solid
foundation in high school mathematics (with some calculus) and an elementary
understanding of computer programming will be able to follow this article.
First, we shall explain the significance of the P versus NP problem and solve
it. Next, we shall describe two other famous mathematics problems, the Collatz
3n+1 Conjecture and the Riemann Hypothesis, and show how both Chaitin's
incompleteness theorem and Wolfram's notion of ""computational irreducibility""
are important for understanding why no one has, as of yet, solved these two
problems.
"
0507019,"Making Space for Stories: Ambiguity in the Design of Personal
  Communication Systems","  Pervasive personal communication technologies offer the potential for
important social benefits for individual users, but also the potential for
significant social difficulties and costs. In research on face-to-face social
interaction, ambiguity is often identified as an important resource for
resolving social difficulties. In this paper, we discuss two design cases of
personal communication systems, one based on fieldwork of a commercial system
and another based on an unrealized design concept. The cases illustrate how
user behavior concerning a particular social difficulty, unexplained
unresponsiveness, can be influenced by technological issues that result in
interactional ambiguity. The cases also highlight the need to balance the
utility of ambiguity against the utility of usability and communicative
clarity.
"
0507035,Enhancing Global SLS-Resolution with Loop Cutting and Tabling Mechanisms,"  Global SLS-resolution is a well-known procedural semantics for top-down
computation of queries under the well-founded model. It inherits from
SLDNF-resolution the {\em linearity} property of derivations, which makes it
easy and efficient to implement using a simple stack-based memory structure.
However, like SLDNF-resolution it suffers from the problem of infinite loops
and redundant computations. To resolve this problem, in this paper we develop a
new procedural semantics, called {\em SLTNF-resolution}, by enhancing Global
SLS-resolution with loop cutting and tabling mechanisms. SLTNF-resolution is
sound and complete w.r.t. the well-founded semantics for logic programs with
the bounded-term-size property, and is superior to existing linear tabling
procedural semantics such as SLT-resolution.
"
0507036,Improved Inference for Checking Annotations,"  We consider type inference in the Hindley/Milner system extended with type
annotations and constraints with a particular focus on Haskell-style type
classes. We observe that standard inference algorithms are incomplete in the
presence of nested type annotations. To improve the situation we introduce a
novel inference scheme for checking type annotations. Our inference scheme is
also incomplete in general but improves over existing implementations as found
e.g. in the Glasgow Haskell Compiler (GHC). For certain cases (e.g. Haskell 98)
our inference scheme is complete. Our approach has been fully implemented as
part of the Chameleon system (experimental version of Haskell).
"
0507037,Type Inference for Guarded Recursive Data Types,"  We consider type inference for guarded recursive data types (GRDTs) -- a
recent generalization of algebraic data types. We reduce type inference for
GRDTs to unification under a mixed prefix. Thus, we obtain efficient type
inference. Inference is incomplete because the set of type constraints allowed
to appear in the type system is only a subset of those type constraints
generated by type inference. Hence, inference only succeeds if the program is
sufficiently type annotated. We present refined procedures to infer types
incrementally and to assist the user in identifying which pieces of type
information are missing. Additionally, we introduce procedures to test if a
type is not principal and to find a principal type if one exists.
"
0507041,Monotone Conditional Complexity Bounds on Future Prediction Errors,"  We bound the future loss when predicting any (computably) stochastic sequence
online. Solomonoff finitely bounded the total deviation of his universal
predictor M from the true distribution m by the algorithmic complexity of m.
Here we assume we are at a time t>1 and already observed x=x_1...x_t. We bound
the future prediction performance on x_{t+1}x_{t+2}... by a new variant of
algorithmic complexity of m given x, plus the complexity of the randomness
deficiency of x. The new complexity is monotone in its condition in the sense
that this complexity can only decrease if the condition is prolonged. We also
briefly discuss potential generalizations to Bayesian model classes and to
classification problems.
"
0507047,Inferring AS Relationships: Dead End or Lively Beginning?,"  Recent techniques for inferring business relationships between ASs have
yielded maps that have extremely few invalid BGP paths in the terminology of
Gao. However, some relationships inferred by these newer algorithms are
incorrect, leading to the deduction of unrealistic AS hierarchies. We
investigate this problem and discover what causes it. Having obtained such
insight, we generalize the problem of AS relationship inference as a
multiobjective optimization problem with node-degree-based corrections to the
original objective function of minimizing the number of invalid paths. We solve
the generalized version of the problem using the semidefinite programming
relaxation of the MAX2SAT problem. Keeping the number of invalid paths small,
we obtain a more veracious solution than that yielded by recent heuristics.
"
0507049,"The Skip Quadtree: A Simple Dynamic Data Structure for Multidimensional
  Data","  We present a new multi-dimensional data structure, which we call the skip
quadtree (for point data in R^2) or the skip octree (for point data in R^d,
with constant d>2). Our data structure combines the best features of two
well-known data structures, in that it has the well-defined ""box""-shaped
regions of region quadtrees and the logarithmic-height search and update
hierarchical structure of skip lists. Indeed, the bottom level of our structure
is exactly a region quadtree (or octree for higher dimensional data). We
describe efficient algorithms for inserting and deleting points in a skip
quadtree, as well as fast methods for performing point location and approximate
range queries.
"
0507064,Termination of rewriting strategies: a generic approach,"  We propose a generic termination proof method for rewriting under strategies,
based on an explicit induction on the termination property. Rewriting trees on
ground terms are modeled by proof trees, generated by alternatively applying
narrowing and abstracting steps. The induction principle is applied through the
abstraction mechanism, where terms are replaced by variables representing any
of their normal forms. The induction ordering is not given a priori, but
defined with ordering constraints, incrementally set during the proof.
Abstraction constraints can be used to control the narrowing mechanism, well
known to easily diverge. The generic method is then instantiated for the
innermost, outermost and local strategies.
"
0507071,"Security for Distributed Web-Applications via Aspect-Oriented
  Programming","  Identity Management is becoming more and more important in business systems
as they are opened for third parties including trading partners, consumers and
suppliers. This paper presents an approach securing a system without any
knowledge of the system source code. The security module adds to the existing
system authentication and authorisation based on aspect oriented programming
and the liberty alliance framework, an upcoming industrie standard providing
single sign on. In an initial training phase the module is adapted to the
application which is to be secured. Moreover the use of hardware tokens and
proactive computing is demonstrated. The high modularisation is achived through
use of AspectJ, a programming language extension of Java.
"
0507072,Reliable Data Storage in Distributed Hash Tables,"  Distributed Hash Tables offer a resilient lookup service for unstable
distributed environments. Resilient data storage, however, requires additional
data replication and maintenance algorithms. These algorithms can have an
impact on both the performance and the scalability of the system. In this
paper, we describe the goals and design space of these replication algorithms.
  We examine an existing replication algorithm, and present a new analysis of
its reliability. We then present a new dynamic replication algorithm which can
operate in unstable environments. We give several possible replica placement
strategies for this algorithm, and show how they impact reliability and
performance.
  Finally we compare all replication algorithms through simulation, showing
quantitatively the difference between their bandwidth use, fault tolerance and
performance.
"
0508003,Model Checking Probabilistic Pushdown Automata,"  We consider the model checking problem for probabilistic pushdown automata
(pPDA) and properties expressible in various probabilistic logics. We start
with properties that can be formulated as instances of a generalized random
walk problem. We prove that both qualitative and quantitative model checking
for this class of properties and pPDA is decidable. Then we show that model
checking for the qualitative fragment of the logic PCTL and pPDA is also
decidable. Moreover, we develop an error-tolerant model checking algorithm for
PCTL and the subclass of stateless pPDA. Finally, we consider the class of
omega-regular properties and show that both qualitative and quantitative model
checking for pPDA is decidable.
"
0508005,Logic Column 13: Reasoning Formally about Quantum Systems: An Overview,"  This article is intended as an introduction to the subject of quantum logic,
and as a brief survey of the relevant literature. Also discussed here are
logics for specification and analysis of quantum information systems, in
particular, recent work by P. Mateus and A. Sernadas, and also by R. van der
Meyden and M. Patra. Overall, our objective is to provide a high-level
presentation of the logical aspects of quantum theory. Mateus' and Sernadas'
EQPL logic is illustrated with a small example, namely the state of an
entangled pair of qubits. The ""KT"" logic of van der Meyden and Patra is
demonstrated briefly in the context of the B92 protocol for quantum key
distribution.
"
0508013,"Relations between the Local Weight Distributions of a Linear Block Code,
  Its Extended Code, and Its Even Weight Subcode","  Relations between the local weight distributions of a binary linear code, its
extended code, and its even weight subcode are presented. In particular, for a
code of which the extended code is transitive invariant and contains only
codewords with weight multiples of four, the local weight distribution can be
obtained from that of the extended code. Using the relations, the local weight
distributions of the $(127,k)$ primitive BCH codes for $k\leq50$, the
$(127,64)$ punctured third-order Reed-Muller, and their even weight subcodes
are obtained from the local weight distribution of the $(128,k)$ extended
primitive BCH codes for $k\leq50$ and the $(128,64)$ third-order Reed-Muller
code. We also show an approach to improve an algorithm for computing the local
weight distribution proposed before.
"
0508014,The Benefit of Thresholding in LP Decoding of LDPC Codes,"  Consider data transmission over a binary-input additive white Gaussian noise
channel using a binary low-density parity-check code. We ask the following
question: Given a decoder that takes log-likelihood ratios as input, does it
help to modify the log-likelihood ratios before decoding? If we use an optimal
decoder then it is clear that modifying the log-likelihoods cannot possibly
help the decoder's performance, and so the answer is ""no."" However, for a
suboptimal decoder like the linear programming decoder, the answer might be
""yes"": In this paper we prove that for certain interesting classes of
low-density parity-check codes and large enough SNRs, it is advantageous to
truncate the log-likelihood ratios before passing them to the linear
programming decoder.
"
0508018,"Spectral Factorization, Whitening- and Estimation Filter -- Stability,
  Smoothness Properties and FIR Approximation Behavior","  A Wiener filter can be interpreted as a cascade of a whitening- and an
estimation filter. This paper gives a detailed investigates of the properties
of these two filters. Then the practical consequences for the overall Wiener
filter are ascertained. It is shown that if the given spectral densities are
smooth (Hoelder continuous) functions, the resulting Wiener filter will always
be stable and can be approximated arbitrarily well by a finite impulse response
(FIR) filter. Moreover, the smoothness of the spectral densities characterizes
how fast the FIR filter approximates the desired filter characteristic. If on
the other hand the spectral densities are continuous but not smooth enough, the
resulting Wiener filter may not be stable.
"
0508040,Bounds on the Capacity of the Blockwise Noncoherent APSK-AWGN Channels,"  Capacity of M-ary Amplitude and Phase-Shift Keying(M-APSK) over an Additive
White Gaussian Noise(AWGN) channel that also introduces an unknown carrier
phase rotation is considered. The phase remains constant over a block of L
symbols and it is independent from block to block. Aiming to design codes with
equally probable symbols, uniformly distributed channel inputs are assumed.
Based on results of Peleg and Shamai for M-ary Phase Shift Keying(M-PSK)
modulation, easily computable upper and lower bounds on the effective M-APSK
capacity are derived. For moderate M and L and a broad range of Signal-to-Noise
Ratios(SNR's), the bounds come close together. As in the case of M-PSK
modulation, for large L the coherent capacity is approached.
"
0508041,OpenVanilla - A Non-Intrusive Plug-In Framework of Text Services,"  Input method (IM) is a sine qua non for text entry of many Asian languages,
but its potential applications on other languages remain under-explored. This
paper proposes a philosophy of input method design by seeing it as a
nonintrusive plug-in text service framework. Such design allows new
functionalities of text processing to be attached onto a running application
without any tweaking of code. We also introduce OpenVanilla, a cross-platform
framework that is designed with the above-mentioned model in mind. Frameworks
like OpenVanilla have shown that an input method can be more than just a text
entry tool: it offers a convenient way for developing various text service and
language tools.
"
0508046,Relaxation Bounds on the Minimum Pseudo-Weight of Linear Block Codes,"  Just as the Hamming weight spectrum of a linear block code sheds light on the
performance of a maximum likelihood decoder, the pseudo-weight spectrum
provides insight into the performance of a linear programming decoder. Using
properties of polyhedral cones, we find the pseudo-weight spectrum of some
short codes. We also present two general lower bounds on the minimum
pseudo-weight. The first bound is based on the column weight of the
parity-check matrix. The second bound is computed by solving an optimization
problem. In some cases, this bound is more tractable to compute than previously
known bounds and thus can be applied to longer codes.
"
0508047,"Further Results on Coding for Reliable Communication over Packet
  Networks","  In ""On Coding for Reliable Communication over Packet Networks"" (Lun, Medard,
and Effros, Proc. 42nd Annu. Allerton Conf. Communication, Control, and
Computing, 2004), a capacity-achieving coding scheme for unicast or multicast
over lossy wireline or wireless packet networks is presented. We extend that
paper's results in two ways: First, we extend the network model to allow
packets received on a link to arrive according to any process with an average
rate, as opposed to the assumption of Poisson traffic with i.i.d. losses that
was previously made. Second, in the case of Poisson traffic with i.i.d. losses,
we derive error exponents that quantify the rate at which the probability of
error decays with coding delay.
"
0508063,"Disks, Partitions, Volumes and RAID Performance with the Linux Operating
  System","  Block devices in computer operating systems typically correspond to disks or
disk partitions, and are used to store files in a filesystem. Disks are not the
only real or virtual device which adhere to the block accessible stream of
bytes block device model. Files, remote devices, or even RAM may be used as a
virtual disks. This article examines several common combinations of block
device layers used as virtual disks in the Linux operating system: disk
partitions, loopback files, software RAID, Logical Volume Manager, and Network
Block Devices. It measures their relative performance using different
filesystems: Ext2, Ext3, ReiserFS, JFS, XFS,NFS.
"
0508064,"Layered Orthogonal Lattice Detector for Two Transmit Antenna
  Communications","  A novel detector for multiple-input multiple-output (MIMO) communications is
presented. The algorithm belongs to the class of the lattice detectors, i.e. it
finds a reduced complexity solution to the problem of finding the closest
vector to the received observations. The algorithm achieves optimal
maximum-likelihood (ML) performance in case of two transmit antennas, at the
same time keeping a complexity much lower than the exhaustive search-based ML
detection technique. Also, differently from the state-of-art lattice detector
(namely sphere decoder), the proposed algorithm is suitable for a highly
parallel hardware architecture and for a reliable bit soft-output information
generation, thus making it a promising option for real-time high-data rate
transmission.
"
0508069,Real Hypercomputation and Continuity,"  By the sometimes so-called 'Main Theorem' of Recursive Analysis, every
computable real function is necessarily continuous. We wonder whether and which
kinds of HYPERcomputation allow for the effective evaluation of also
discontinuous f:R->R. More precisely the present work considers the following
three super-Turing notions of real function computability:
  * relativized computation; specifically given oracle access to the Halting
Problem 0' or its jump 0'';
  * encoding real input x and/or output y=f(x) in weaker ways also related to
the Arithmetic Hierarchy;
  * non-deterministic computation.
  It turns out that any f:R->R computable in the first or second sense is still
necessarily continuous whereas the third type of hypercomputation does provide
the required power to evaluate for instance the discontinuous sign function.
"
0508082,The Structure of Collaborative Tagging Systems,"  Collaborative tagging describes the process by which many users add metadata
in the form of keywords to shared content. Recently, collaborative tagging has
grown in popularity on the web, on sites that allow users to tag bookmarks,
photographs and other content. In this paper we analyze the structure of
collaborative tagging systems as well as their dynamical aspects. Specifically,
we discovered regularities in user activity, tag frequencies, kinds of tags
used, bursts of popularity in bookmarking and a remarkable stability in the
relative proportions of tags within a given url. We also present a dynamical
model of collaborative tagging that predicts these stable patterns and relates
them to imitation and shared knowledge.
"
0508089,Modelling the EAH Data Compression Algorithm using Graph Theory,"  Adaptive codes associate variable-length codewords to symbols being encoded
depending on the previous symbols in the input data string. This class of codes
has been introduced in [Dragos Trinca, cs.DS/0505007] as a new class of
non-standard variable-length codes. New algorithms for data compression, based
on adaptive codes of order one, have been presented in [Dragos Trinca,
ITCC-2004], where we have behaviorally shown that for a large class of input
data strings, these algorithms substantially outperform the Lempel-Ziv
universal data compression algorithm. EAH has been introduced in [Dragos
Trinca, cs.DS/0505061], as an improved generalization of these algorithms. In
this paper, we present a translation of the EAH algorithm into the graph
theory.
"
0508094,"Conference Key Agreement and Quantum Sharing of Classical Secrets with
  Noisy GHZ States","  We propose a wide class of distillation schemes for multi-partite entangled
states that are CSS-states. Our proposal provides not only superior efficiency,
but also new insights on the connection between CSS-states and bipartite graph
states. We then consider the applications of our distillation schemes for two
cryptographic tasks--namely, (a) conference key agreement and (b) quantum
sharing of classical secrets. In particular, we construct
``prepare-and-measure'' protocols. Also we study the yield of those protocols
and the threshold value of the fidelity above which the protocols can function
securely. Surprisingly, our protocols will function securely even when the
initial state does not violate the standard Bell-inequalities for GHZ states.
Experimental realization involving only bi-partite entanglement is also
suggested.
"
0508097,Tightness of LP via Max-product Belief Propagation,"  We investigate the question of tightness of linear programming (LP)
relaxation for finding a maximum weight independent set (MWIS) in sparse random
weighted graphs. We show that an edge-based LP relaxation is asymptotically
tight for Erdos-Renyi graph $G(n,c/n)$ for $c \leq 2e$ and random regular graph
$G(n,r)$ for $r\leq 4$ when node weights are i.i.d. with exponential
distribution of mean 1. We establish these results, through a precise relation
between the tightness of LP relaxation and convergence of the max-product
belief propagation algorithm. We believe that this novel method of
understanding structural properties of combinatorial problems through
properties of iterative procedure such as the max-product should be of interest
in its own right.
"
0508106,"An Improved Non-Termination Criterion for Binary Constraint Logic
  Programs","  On one hand, termination analysis of logic programs is now a fairly
established research topic within the logic programming community. On the other
hand, non-termination analysis seems to remain a much less attractive subject.
If we divide this line of research into two kinds of approaches: dynamic versus
static analysis, this paper belongs to the latter. It proposes a criterion for
detecting non-terminating atomic queries with respect to binary CLP clauses,
which strictly generalizes our previous works on this subject. We give a
generic operational definition and a logical form of this criterion. Then we
show that the logical form is correct and complete with respect to the
operational definition.
"
0508108,Proving or Disproving likely Invariants with Constraint Reasoning,"  A program invariant is a property that holds for every execution of the
program. Recent work suggest to infer likely-only invariants, via dynamic
analysis. A likely invariant is a property that holds for some executions but
is not guaranteed to hold for all executions. In this paper, we present work in
progress addressing the challenging problem of automatically verifying that
likely invariants are actual invariants. We propose a constraint-based
reasoning approach that is able, unlike other approaches, to both prove or
disprove likely invariants. In the latter case, our approach provides
counter-examples. We illustrate the approach on a motivating example where
automatically generated likely invariants are verified.
"
0508115,New Sequence Sets with Zero-Correlation Zone,"  A method for constructing sets of sequences with zero-correlation zone (ZCZ
sequences) and sequence sets with low cross correlation is proposed. The method
is to use families of short sequences and complete orthogonal sequence sets to
derive families of long sequences with desired correlation properties. It is a
unification of works of Matsufuji and Torii \emph{et al.}, and there are more
choices of parameters of sets for our method. In particular, ZCZ sequence sets
generated by the method can achieve a related ZCZ bound. Furthermore, the
proposed method can be utilized to derive new ZCZ sets with both longer ZCZ and
larger set size from known ZCZ sets. These sequence sets are applicable in
broadband satellite IP networks.
"
0508129,Temporal Phylogenetic Networks and Logic Programming,"  The concept of a temporal phylogenetic network is a mathematical model of
evolution of a family of natural languages. It takes into account the fact that
languages can trade their characteristics with each other when linguistic
communities are in contact, and also that a contact is only possible when the
languages are spoken at the same time. We show how computational methods of
answer set programming and constraint logic programming can be used to generate
plausible conjectures about contacts between prehistoric linguistic
communities, and illustrate our approach by applying it to the evolutionary
history of Indo-European languages.
  To appear in Theory and Practice of Logic Programming (TPLP).
"
0509005,"Combining Structured Corporate Data and Document Content to Improve
  Expertise Finding","  In this paper, we present an algorithm for automatically building expertise
evidence for finding experts within an organization by combining structured
corporate information with different content. We also describe our test data
collection and our evaluation method. Evaluation of the algorithm shows that
using organizational structure leads to a significant improvement in the
precision of finding an expert. Furthermore we evaluate the impact of using
different data sources on the quality of the results and conclude that Expert
Finding is not a ""one engine fits all"" solution. It requires an analysis of the
information space into which a solution will be placed and the appropriate
selection and weighting scheme of the data sources.
"
0509006,"Optimal space-time codes for the MIMO amplify-and-forward cooperative
  channel","  In this work, we extend the non-orthogonal amplify-and-forward (NAF)
cooperative diversity scheme to the MIMO channel. A family of space-time block
codes for a half-duplex MIMO NAF fading cooperative channel with N relays is
constructed. The code construction is based on the non-vanishing determinant
criterion (NVD) and is shown to achieve the optimal diversity-multiplexing
tradeoff (DMT) of the channel. We provide a general explicit algebraic
construction, followed by some examples. In particular, in the single relay
case, it is proved that the Golden code and the 4x4 Perfect code are optimal
for the single-antenna and two-antenna case, respectively. Simulation results
reveal that a significant gain (up to 10dB) can be obtained with the proposed
codes, especially in the single-antenna case.
"
0509007,"Non-Data-Aided Parameter Estimation in an Additive White Gaussian Noise
  Channel","  Non-data-aided (NDA) parameter estimation is considered for
binary-phase-shift-keying transmission in an additive white Gaussian noise
channel. Cramer-Rao lower bounds (CRLBs) for signal amplitude, noise variance,
channel reliability constant and bit-error rate are derived and it is shown how
these parameters relate to the signal-to-noise ratio (SNR). An alternative
derivation of the iterative maximum likelihood (ML) SNR estimator is presented
together with a novel, low complexity NDA SNR estimator. The performance of the
proposed estimator is compared to previously suggested estimators and the CRLB.
The results show that the proposed estimator performs close to the iterative ML
estimator at significantly lower computational complexity.
"
0509015,"Optimal Prefix Codes with Fewer Distinct Codeword Lengths are Faster to
  Construct","  A new method for constructing minimum-redundancy binary prefix codes is
described. Our method does not explicitly build a Huffman tree; instead it uses
a property of optimal prefix codes to compute the codeword lengths
corresponding to the input weights. Let $n$ be the number of weights and $k$ be
the number of distinct codeword lengths as produced by the algorithm for the
optimum codes. The running time of our algorithm is $O(k \cdot n)$. Following
our previous work in \cite{be}, no algorithm can possibly construct optimal
prefix codes in $o(k \cdot n)$ time. When the given weights are presorted our
algorithm performs $O(9^k \cdot \log^{2k}{n})$ comparisons.
"
0509016,NP-hardness of the cluster minimization problem revisited,"  The computational complexity of the ""cluster minimization problem"" is
revisited [L. T. Wille and J. Vennik, J. Phys. A 18, L419 (1985)]. It is argued
that the original NP-hardness proof does not apply to pairwise potentials of
physical interest, such as those that depend on the geometric distance between
the particles. A geometric analog of the original problem is formulated, and a
new proof for such potentials is provided by polynomial time transformation
from the independent set problem for unit disk graphs. Limitations of this
formulation are pointed out, and new subproblems that bear more direct
consequences to the numerical study of clusters are suggested.
"
0509020,"Transitive Text Mining for Information Extraction and Hypothesis
  Generation","  Transitive text mining - also named Swanson Linking (SL) after its primary
and principal researcher - tries to establish meaningful links between
literature sets which are virtually disjoint in the sense that each does not
mention the main concept of the other. If successful, SL may give rise to the
development of new hypotheses. In this communication we describe our approach
to transitive text mining which employs co-occurrence analysis of the medical
subject headings (MeSH), the descriptors assigned to papers indexed in PubMed.
In addition, we will outline the current state of our web-based information
system which will enable our users to perform literature-driven hypothesis
building on their own.
"
0509028,Projecting the Forward Rate Flow onto a Finite Dimensional Manifold,"  Given a Heath-Jarrow-Morton (HJM) interest rate model $\mathcal{M}$ and a
parametrized family of finite dimensional forward rate curves $\mathcal{G}$,
this paper provides a technique for projecting the infinite dimensional forward
rate curve $r_{t}$ given by $\mathcal{M}$ onto the finite dimensional manifold
$\mathcal{G}$.The Stratonovich dynamics of the projected finite dimensional
forward curve are derived and it is shown that, under the regularity
conditions, the given Stratonovich differential equation has a unique strong
solution. Moreover, this projection leads to an efficient algorithm for
implicit parametric estimation of the infinite dimensional HJM model. The
feasibility of this method is demonstrated by applying the generalized method
of moments.
"
0509034,N-free extensions of posets.Note on a theorem of P.A.Grillet,"  Let $S\_{N}(P)$ be the poset obtained by adding a dummy vertex on each
diagonal edge of the $N$'s of a finite poset $P$. We show that
$S\_{N}(S\_{N}(P))$ is $N$-free. It follows that this poset is the smallest
$N$-free barycentric subdivision of the diagram of $P$, poset whose existence
was proved by P.A. Grillet. This is also the poset obtained by the algorithm
starting with $P\_0:=P$ and consisting at step $m$ of adding a dummy vertex on
a diagonal edge of some $N$ in $P\_m$, proving that the result of this
algorithm does not depend upon the particular choice of the diagonal edge
choosen at each step. These results are linked to drawing of posets.
"
0509036,Security Problems with Improper Implementations of Improved FEA-M,"  This paper reports security problems with improper implementations of an
improved version of FEA-M (fast encryption algorithm for multimedia). It is
found that an implementation-dependent differential chosen-plaintext attack or
its chosen-ciphertext counterpart can reveal the secret key of the
cryptosystem, if the involved (pseudo-)random process can be tampered (for
example, through a public time service). The implementation-dependent
differential attack is very efficient in complexity and needs only $O(n^2)$
chosen plaintext or ciphertext bits. In addition, this paper also points out a
minor security problem with the selection of the session key. In real
implementations of the cryptosystem, these security problems should be
carefully avoided, or the cryptosystem has to be further enhanced to work under
such weak implementations.
"
0509047,"Secure multiplex coding to attain the channel capacity in wiretap
  channels","  It is known that a message can be transmitted safely against any wiretapper
via a noisy channel without a secret key if the coding rate is less than the
so-called secrecy capacity $C_S$, which is usually smaller than the channel
capacity $C$. In order to remove the loss $C - C_S$, we propose a multiplex
coding scheme with plural independent messages. In this paper, it is shown that
the proposed multiplex coding scheme can attain the channel capacity as the
total rate of the plural messages and the perfect secrecy for each message. The
coding theorem is proved by extending Hayashi's proof, in which the coding of
the channel resolvability is applied to wiretap channels.
"
0509052,"Club Formation by Rational Sharing : Content, Viability and Community
  Structure","  A sharing community prospers when participation and contribution are both
high. We suggest the two, while being related decisions every peer makes,
should be given separate rational bases. Considered as such, a basic issue is
the viability of club formation, which necessitates the modelling of two major
sources of heterogeneity, namely, peers and shared content. This viability
perspective clearly explains why rational peers contribute (or free-ride when
they don't) and how their collective action determines viability as well as the
size of the club formed. It also exposes another fundamental source of
limitation to club formation apart from free-riding, in the community structure
in terms of the relation between peers' interest (demand) and sharing (supply).
"
0509084,Representing Digital Assets for Long-Term Preservation using MPEG-21 DID,"  Various efforts aimed at representing digital assets have emerged from
several communities over the last years, including the Metadata Encoding and
Transmission Standard (METS), the IMS Content Packaging (IMS-CP) XML Binding
and the XML Formatted Data Units (XFDU). The MPEG-21 Digital Item Declaration
(MPEG-21 DID) is another approach that can be used for the representation of
digital assets in XML. This paper will explore the potential of the MPEG-21 DID
in a Digital Preservation context, by looking at the core building blocks of
the OAIS Information Model and the way in which they map to the MPEG-21 DID
abstract model and the MPEG-21 DIDL XML syntax.
"
0509088,"Business intelligence systems and user's parameters: an application to a
  documents' database","  This article presents earlier results of our research works in the area of
modeling Business Intelligence Systems. The basic idea of this research area is
presented first. We then show the necessity of including certain users'
parameters in Information systems that are used in Business Intelligence
systems in order to integrate a better response from such systems. We
identified two main types of attributes that can be missing from a base and we
showed why they needed to be included. A user model that is based on a
cognitive user evolution is presented. This model when used together with a
good definition of the information needs of the user (decision maker) will
accelerate his decision making process.
"
0510010,On the Expressiveness of the Ambient Logic,"  The Ambient Logic (AL) has been proposed for expressing properties of process
mobility in the calculus of Mobile Ambients (MA), and as a basis for query
languages on semistructured data. In this paper, we study the expressiveness of
AL. We define formulas for capabilities and for communication in MA. We also
derive some formulas that capture finitess of a term, name occurrences and
persistence. We study extensions of the calculus involving more complex forms
of communications, and we define characteristic formulas for the equivalence
induced by the logic on a subcalculus of MA. This subcalculus is defined by
imposing an image-finiteness condition on the reducts of a MA process.
"
0510030,"A Near Maximum Likelihood Decoding Algorithm for MIMO Systems Based on
  Semi-Definite Programming","  In Multi-Input Multi-Output (MIMO) systems, Maximum-Likelihood (ML) decoding
is equivalent to finding the closest lattice point in an N-dimensional complex
space. In general, this problem is known to be NP hard. In this paper, we
propose a quasi-maximum likelihood algorithm based on Semi-Definite Programming
(SDP). We introduce several SDP relaxation models for MIMO systems, with
increasing complexity. We use interior-point methods for solving the models and
obtain a near-ML performance with polynomial computational complexity. Lattice
basis reduction is applied to further reduce the computational complexity of
solving these models. The proposed relaxation models are also used for soft
output decoding in MIMO systems.
"
0510033,Coding for the Optical Channel: the Ghost-Pulse Constraint,"  We consider a number of constrained coding techniques that can be used to
mitigate a nonlinear effect in the optical fiber channel that causes the
formation of spurious pulses, called ``ghost pulses.'' Specifically, if $b_1
b_2 ... b_{n}$ is a sequence of bits sent across an optical channel, such that
$b_k=b_l=b_m=1$ for some $k,l,m$ (not necessarily all distinct) but $b_{k+l-m}
= 0$, then the ghost-pulse effect causes $b_{k+l-m}$ to change to 1, thereby
creating an error. We design and analyze several coding schemes using binary
and ternary sequences constrained so as to avoid patterns that give rise to
ghost pulses. We also discuss the design of encoders and decoders for these
coding schemes.
"
0510045,Why We Can Not Surpass Capacity: The Matching Condition,"  We show that iterative coding systems can not surpass capacity using only
quantities which naturally appear in density evolution. Although the result in
itself is trivial, the method which we apply shows that in order to achieve
capacity the various components in an iterative coding system have to be
perfectly matched. This generalizes the perfect matching condition which was
previously known for the case of transmission over the binary erasure channel
to the general class of binary-input memoryless output-symmetric channels.
Potential applications of this perfect matching condition are the construction
of capacity-achieving degree distributions and the determination of the number
required iterations as a function of the multiplicative gap to capacity.
"
0510057,Towards a diagrammatic modeling of the LinBox C++ linear algebra library,"  We propose a new diagrammatic modeling language, DML. The paradigm used is
that of the category theory and in particular of the pushout tool. We show that
most of the object-oriented structures can be described with this tool and have
many examples in C++, ranging from virtual inheritance and polymorphism to
template genericity. With this powerful tool, we propose a quite simple
description of the C++ LinBox library. This library has been designed for
efficiency and genericity and therefore makes heavy usage of complex template
and polymorphic mecanism. Be reverse engineering, we are able to describe in a
simple manner the complex structure of archetypes in LinBox.
"
0510064,Acyclic orientations with path constraints,"  Many well-known combinatorial optimization problems can be stated over the
set of acyclic orientations of an undirected graph. For example, acyclic
orientations with certain diameter constraints are closely related to the
optimal solutions of the vertex coloring and frequency assignment problems. In
this paper we introduce a linear programming formulation of acyclic
orientations with path constraints, and discuss its use in the solution of the
vertex coloring problem and some versions of the frequency assignment problem.
A study of the polytope associated with the formulation is presented, including
proofs of which constraints of the formulation are facet-defining and the
introduction of new classes of valid inequalities.
"
0510065,A new authentication protocol for revocable anonymity in ad-hoc networks,"  This paper describes a new protocol for authentication in ad-hoc networks.
The protocol has been designed to meet specialized requirements of ad-hoc
networks, such as lack of direct communication between nodes or requirements
for revocable anonymity. At the same time, a ad-hoc authentication protocol
must be resistant to spoofing, eavesdropping and playback, and
man-in-the-middle attacks. The article analyzes existing authentication methods
based on the Public Key Infrastructure, and finds that they have several
drawbacks in ad-hoc networks. Therefore, a new authentication protocol, basing
on established cryptographic primitives (Merkle's puzzles and zero-knowledge
proofs) is proposed. The protocol is studied for a model ad-hoc chat
application that provides private conversations.
"
0510073,Semantic Embedding of Petri Nets into Event-B,"  We present an embedding of Petri nets into B abstract systems. The embedding
is achieved by translating both the static structure (modelling aspect) and the
evolution semantics of Petri nets. The static structure of a Petri-net is
captured within a B abstract system through a graph structure. This abstract
system is then included in another abstract system which captures the evolution
semantics of Petri-nets. The evolution semantics results in some B events
depending on the chosen policies: basic nets or high level Petri nets. The
current embedding enables one to use conjointly Petri nets and Event-B in the
same system development, but at different steps and for various analysis.
"
0510080,When Ignorance is Bliss,"  It is commonly-accepted wisdom that more information is better, and that
information should never be ignored. Here we argue, using both a Bayesian and a
non-Bayesian analysis, that in some situations you are better off ignoring
information if your uncertainty is represented by a set of probability
measures. These include situations in which the information is relevant for the
prediction task at hand. In the non-Bayesian analysis, we show how ignoring
information avoids dilation, the phenomenon that additional pieces of
information sometimes lead to an increase in uncertainty. In the Bayesian
analysis, we show that for small sample sizes and certain prediction tasks, the
Bayesian posterior based on a noninformative prior yields worse predictions
than simply ignoring the given information.
"
0511002,Bibliographic Classification using the ADS Databases,"  We discuss two techniques used to characterize bibliographic records based on
their similarity to and relationship with the contents of the NASA Astrophysics
Data System (ADS) databases. The first method has been used to classify input
text as being relevant to one or more subject areas based on an analysis of the
frequency distribution of its individual words. The second method has been used
to classify existing records as being relevant to one or more databases based
on the distribution of the papers citing them. Both techniques have proven to
be valuable tools in assigning new and existing bibliographic records to
different disciplines within the ADS databases.
"
0511026,A Decision Theoretic Framework for Real-Time Communication,"  We consider a communication system in which the outputs of a Markov source
are encoded and decoded in \emph{real-time} by a finite memory receiver, and
the distortion measure does not tolerate delays. The objective is to choose
designs, i.e. real-time encoding, decoding and memory update strategies that
minimize a total expected distortion measure. This is a dynamic team problem
with non-classical information structure [Witsenhausen:1971]. We use the
structural results of [Teneketzis:2004] to develop a sequential decomposition
for the finite and infinite horizon problems. Thus, we obtain a systematic
methodology for the determination of jointly optimal encoding decoding and
memory update strategies for real-time point-to-point communication systems.
"
0511027,Discrete Network Dynamics. Part 1: Operator Theory,"  An operator algebra implementation of Markov chain Monte Carlo algorithms for
simulating Markov random fields is proposed. It allows the dynamics of networks
whose nodes have discrete state spaces to be specified by the action of an
update operator that is composed of creation and annihilation operators. This
formulation of discrete network dynamics has properties that are similar to
those of a quantum field theory of bosons, which allows reuse of many
conceptual and theoretical structures from QFT. The equilibrium behaviour of
one of these generalised MRFs and of the adaptive cluster expansion network
(ACEnet) are shown to be equivalent, which provides a way of unifying these two
theories.
"
0511032,"Spatiotemporal sensistivity and visual attention for efficient rendering
  of dynamic environments","  We present a method to accelerate global illumination computation in dynamic
environments by taking advantage of limitations of the human visual system. A
model of visual attention is used to locate regions of interest in a scene and
to modulate spatiotemporal sensitivity. The method is applied in the form of a
spatiotemporal error tolerance map. Perceptual acceleration combined with good
sampling protocols provide a global illumination solution feasible for use in
animation. Results indicate an order of magnitude improvement in computational
speed. The method is adaptable and can also be used in image-based rendering,
geometry level of detail selection, realistic image synthesis, video telephony
and video compression.
"
0511034,Generalized Hermitian Codes over GF(2^r),"  In this paper we studied generalization of Hermitian function field proposed
by A.Garcia and H.Stichtenoth. We calculated a Weierstrass semigroup of the
point at infinity for the case q=2, r>=3. It turned out that unlike Hermitian
case, we have already three generators for the semigroup. We then applied this
result to codes, constructed on generalized Hermitian function fields. Further,
we applied results of C.Kirfel and R.Pellikaan to estimating a Feng-Rao
designed distance for GH-codes, which improved on Goppa designed distance.
Next, we studied the question of codes dual to GH-codes. We identified that the
duals are also GH-codes and gave an explicit formula. We concluded with some
computational results. In particular, a new record-giving [32,16,>=12]-code
over GF(8) was presented.
"
0511036,"A Capacity Achieving and Low Complexity Multilevel Coding Scheme for ISI
  Channels","  We propose a computationally efficient multilevel coding scheme to achieve
the capacity of an ISI channel using layers of binary inputs. The transmitter
employs multilevel coding with linear mapping. The receiver uses multistage
decoding where each stage performs a separate linear minimum mean square error
(LMMSE) equalization and decoding. The optimality of the scheme is due to the
fact that the LMMSE equalizer is information lossless in an ISI channel when
signal to noise ratio is sufficiently low. The computational complexity is low
and scales linearly with the length of the channel impulse response and the
number of layers. The decoder at each layer sees an equivalent AWGN channel,
which makes coding straightforward.
"
0511037,Trellis Pruning for Peak-to-Average Power Ratio Reduction,"  This paper introduces a new trellis pruning method which uses nonlinear
convolutional coding for peak-to-average power ratio (PAPR) reduction of
filtered QPSK and 16-QAM modulations. The Nyquist filter is viewed as a
convolutional encoder that controls the analog waveforms of the filter output
directly. Pruning some edges of the encoder trellis can effectively reduce the
PAPR. The only tradeoff is a slightly lower channel capacity and increased
complexity. The paper presents simulation results of the pruning action and the
resulting PAPR, and also discusses the decoding algorithm and the capacity of
the filtered and pruned QPSK and 16-QAM modulations on the AWGN channel.
Simulation results show that the pruning method reduces the PAPR significantly
without much damage to capacity.
"
0511042,Dimensions of Neural-symbolic Integration - A Structured Survey,"  Research on integrated neural-symbolic systems has made significant progress
in the recent past. In particular the understanding of ways to deal with
symbolic knowledge within connectionist systems (also called artificial neural
networks) has reached a critical mass which enables the community to strive for
applicable implementations and use cases. Recent work has covered a great
variety of logics used in artificial intelligence and provides a multitude of
techniques for dealing with them within the context of artificial neural
networks. We present a comprehensive survey of the field of neural-symbolic
integration, including a new classification of system according to their
architectures and abilities.
"
0511045,An Invariant Cost Model for the Lambda Calculus,"  We define a new cost model for the call-by-value lambda-calculus satisfying
the invariance thesis. That is, under the proposed cost model, Turing machines
and the call-by-value lambda-calculus can simulate each other within a
polynomial time overhead. The model only relies on combinatorial properties of
usual beta-reduction, without any reference to a specific machine or evaluator.
In particular, the cost of a single beta reduction is proportional to the
difference between the size of the redex and the size of the reduct. In this
way, the total cost of normalizing a lambda term will take into account the
size of all intermediate results (as well as the number of steps to normal
form).
"
0511062,"Analytic performance comparison of routing protocols in master-slave PLC
  networks","  In the wide area master-slave PLC (powerline communication) system, the
source node cannot reach the destination node without packet relay. Due to the
time-variable attenuation in the powerline, the communication distance cannot
be defined. Two kind of dynamic repeater algorithms are developed, dynamic
source routing and flooding based routing. In this paper, we use analytic
approach to compare the performance of those two routing protocols. We give
formulas to calculate the average duration of a polling cycle for each
protocols. Then we present simulation results to bolster the results of our
analysis. We use three metrics, which are bandwidth consumed for routing
signaling, normalized routing load and average duration of a polling cycle to
evaluate those routing protocols.
"
0511073,Stochastic Process Semantics for Dynamical Grammar Syntax: An Overview,"  We define a class of probabilistic models in terms of an operator algebra of
stochastic processes, and a representation for this class in terms of
stochastic parameterized grammars. A syntactic specification of a grammar is
mapped to semantics given in terms of a ring of operators, so that grammatical
composition corresponds to operator addition or multiplication. The operators
are generators for the time-evolution of stochastic processes. Within this
modeling framework one can express data clustering models, logic programs,
ordinary and stochastic differential equations, graph grammars, and stochastic
chemical reaction kinetics. This mathematical formulation connects these
apparently distant fields to one another and to mathematical methods from
quantum field theory and operator algebra.
"
0511074,Every Sequence is Decompressible from a Random One,"  Kucera and Gacs independently showed that every infinite sequence is Turing
reducible to a Martin-Lof random sequence. This result is extended by showing
that every infinite sequence S is Turing reducible to a Martin-Lof random
sequence R such that the asymptotic number of bits of R needed to compute n
bits of S, divided by n, is precisely the constructive dimension of S. It is
shown that this is the optimal ratio of query bits to computed bits achievable
with Turing reductions. As an application of this result, a new
characterization of constructive dimension is given in terms of Turing
reduction compression ratios.
"
0511082,Approximating Clustering of Fingerprint Vectors with Missing Values,"  The problem of clustering fingerprint vectors is an interesting problem in
Computational Biology that has been proposed in (Figureroa et al. 2004). In
this paper we show some improvements in closing the gaps between the known
lower bounds and upper bounds on the approximability of some variants of the
biological problem. Namely we are able to prove that the problem is APX-hard
even when each fingerprint contains only two unknown position. Moreover we have
studied some variants of the orginal problem, and we give two 2-approximation
algorithm for the IECMV and OECMV problems when the number of unknown entries
for each vector is at most a constant.
"
0511088,Bounds on Query Convergence,"  The problem of finding an optimum using noisy evaluations of a smooth cost
function arises in many contexts, including economics, business, medicine,
experiment design, and foraging theory. We derive an asymptotic bound E[ (x_t -
x*)^2 ] >= O(1/sqrt(t)) on the rate of convergence of a sequence (x_0, x_1,
>...) generated by an unbiased feedback process observing noisy evaluations of
an unknown quadratic function maximised at x*. The bound is tight, as the proof
leads to a simple algorithm which meets it. We further establish a bound on the
total regret, E[ sum_{i=1..t} (x_i - x*)^2 ] >= O(sqrt(t)) These bounds may
impose practical limitations on an agent's performance, as O(eps^-4) queries
are made before the queries converge to x* with eps accuracy.
"
0511097,Modularizing the Elimination of r=0 in Kleene Algebra,"  Given a universal Horn formula of Kleene algebra with hypotheses of the form
r = 0, it is already known that we can efficiently construct an equation which
is valid if and only if the Horn formula is valid. This is an example of
<i>elimination of hypotheses</i>, which is useful because the equational theory
of Kleene algebra is decidable while the universal Horn theory is not. We show
that hypotheses of the form r = 0 can still be eliminated in the presence of
other hypotheses. This lets us extend any technique for eliminating hypotheses
to include hypotheses of the form r = 0.
"
0512006,"Capacity-Achieving Ensembles of Accumulate-Repeat-Accumulate Codes for
  the Erasure Channel with Bounded Complexity","  The paper introduces ensembles of accumulate-repeat-accumulate (ARA) codes
which asymptotically achieve capacity on the binary erasure channel (BEC) with
{\em bounded complexity}, per information bit, of encoding and decoding. It
also introduces symmetry properties which play a central role in the
construction of capacity-achieving ensembles for the BEC with bounded
complexity. The results here improve on the tradeoff between performance and
complexity provided by previous constructions of capacity-achieving ensembles
of codes defined on graphs. The superiority of ARA codes with moderate to large
block length is exemplified by computer simulations which compare their
performance with those of previously reported capacity-achieving ensembles of
LDPC and IRA codes. The ARA codes also have the advantage of being systematic.
"
0512023,"Perfect Space-Time Codes with Minimum and Non-Minimum Delay for Any
  Number of Antennas","  Perfect space-time codes were first introduced by Oggier et. al. to be the
space-time codes that have full rate, full diversity-gain, non-vanishing
determinant for increasing spectral efficiency, uniform average transmitted
energy per antenna and good shaping of the constellation. These defining
conditions jointly correspond to optimality with respect to the Zheng-Tse D-MG
tradeoff, independent of channel statistics, as well as to near optimality in
maximizing mutual information. All the above traits endow the code with error
performance that is currently unmatched. Yet perfect space-time codes have been
constructed only for 2,3,4 and 6 transmit antennas. We construct minimum and
non-minimum delay perfect codes for all channel dimensions.
"
0512028,"Approximately universal optimality over several dynamic and non-dynamic
  cooperative diversity schemes for wireless networks","  In this work we explicitly provide the first ever optimal, with respect to
the Zheng-Tse diversity multiplexing gain (D-MG) tradeoff, cooperative
diversity schemes for wireless relay networks. The schemes are based on
variants of perfect space-time codes and are optimal for any number of users
and all statistically symmetric (and in some cases, asymmetric) fading
distributions.
  We deduce that, with respect to the D-MG tradeoff, channel knowledge at the
intermediate relays and infinite delay are unnecessary. We also show that the
non-dynamic selection decode and forward strategy, the non-dynamic amplify and
forward, the non-dynamic receive and forward, the dynamic amplify and forward
and the dynamic receive and forward cooperative diversity strategies allow for
exactly the same D-MG optimal performance.
"
0512031,Alternating Timed Automata,"  A notion of alternating timed automata is proposed. It is shown that such
automata with only one clock have decidable emptiness problem over finite
words. This gives a new class of timed languages which is closed under boolean
operations and which has an effective presentation. We prove that the
complexity of the emptiness problem for alternating timed automata with one
clock is non-primitive recursive. The proof gives also the same lower bound for
the universality problem for nondeterministic timed automata with one clock. We
investigate extension of the model with epsilon-transitions and prove that
emptiness is undecidable. Over infinite words, we show undecidability of the
universality problem.
"
0512032,A Software Framework for Vehicle-Infrastructure Cooperative Applications,"  A growing category of vehicle-infrastructure cooperative (VIC) applications
requires telematics software components distributed between an
infrastructure-based management center and a number of vehicles. This article
presents an approach based on a software framework, focusing on a Telematic
Management System (TMS), a component suite aimed to run inside an
infrastructure-based operations center, in some cases interacting with legacy
systems like Advanced Traffic Management Systems or Vehicle Relationship
Management. The TMS framework provides support for modular, flexible,
prototyping and implementation of VIC applications. This work has received the
support of the European Commission in the context of the projects REACT and
CyberCars.
"
0512036,A System of Interaction and Structure II: The Need for Deep Inference,"  This paper studies properties of the logic BV, which is an extension of
multiplicative linear logic (MLL) with a self-dual non-commutative operator. BV
is presented in the calculus of structures, a proof theoretic formalism that
supports deep inference, in which inference rules can be applied anywhere
inside logical expressions. The use of deep inference results in a simple
logical system for MLL extended with the self-dual non-commutative operator,
which has been to date not known to be expressible in sequent calculus. In this
paper, deep inference is shown to be crucial for the logic BV, that is, any
restriction on the ``depth'' of the inference rules of BV would result in a
strictly less expressive logical system.
"
0512050,Preference Learning in Terminology Extraction: A ROC-based approach,"  A key data preparation step in Text Mining, Term Extraction selects the
terms, or collocation of words, attached to specific concepts. In this paper,
the task of extracting relevant collocations is achieved through a supervised
learning algorithm, exploiting a few collocations manually labelled as
relevant/irrelevant. The candidate terms are described along 13 standard
statistical criteria measures. From these examples, an evolutionary learning
algorithm termed Roger, based on the optimization of the Area under the ROC
curve criterion, extracts an order on the candidate terms. The robustness of
the approach is demonstrated on two real-world domain applications, considering
different domains (biology and human resources) and different languages
(English and French).
"
0512062,Evolino for recurrent support vector machines,"  Traditional Support Vector Machines (SVMs) need pre-wired finite time windows
to predict and classify time series. They do not have an internal state
necessary to deal with sequences involving arbitrary long-term dependencies.
Here we introduce a new class of recurrent, truly sequential SVM-like devices
with internal adaptive states, trained by a novel method called EVOlution of
systems with KErnel-based outputs (Evoke), an instance of the recent Evolino
class of methods. Evoke evolves recurrent neural networks to detect and
represent temporal dependencies while using quadratic programming/support
vector regression to produce precise outputs. Evoke is the first SVM-based
mechanism learning to classify a context-sensitive language. It also
outperforms recent state-of-the-art gradient-based recurrent neural networks
(RNNs) on various time series prediction tasks.
"
0512067,Solving Partial Order Constraints for LPO Termination,"  This paper introduces a new kind of propositional encoding for reasoning
about partial orders. The symbols in an unspecified partial order are viewed as
variables which take integer values and are interpreted as indices in the
order. For a partial order statement on n symbols each index is represented in
log2 n propositional variables and partial order constraints between symbols
are modeled on the bit representations. We illustrate the application of our
approach to determine LPO termination for term rewrite systems. Experimental
results are unequivocal, indicating orders of magnitude speedups in comparison
with current implementations for LPO termination. The proposed encoding is
general and relevant to other applications which involve propositional
reasoning about partial orders.
"
0512075,"Performance versus Complexity Per Iteration for Low-Density Parity-Check
  Codes: An Information-Theoretic Approach","  The paper is focused on the tradeoff between performance and decoding
complexity per iteration for LDPC codes in terms of their gap (in rate) to
capacity. The study of this tradeoff is done via information-theoretic bounds
which also enable to get an indication on the sub-optimality of message-passing
iterative decoding algorithms (as compared to optimal ML decoding). The bounds
are generalized for parallel channels, and are applied to ensembles of
punctured LDPC codes where both intentional and random puncturing are
addressed. This work suggests an improvement in the tightness of some
information-theoretic bounds which were previously derived by Burshtein et al.
and by Sason and Urbanke.
"
0512088,Analysis of loss networks with routing,"  This paper analyzes stochastic networks consisting of finite capacity nodes
with different classes of requests which move according to some routing policy.
The Markov processes describing these networks do not, in general, have
reversibility properties, so the explicit expression of their invariant
distribution is not known. Kelly's limiting regime is considered: the arrival
rates of calls as well as the capacities of the nodes are proportional to a
factor going to infinity. It is proved that, in limit, the associated rescaled
Markov process converges to a deterministic dynamical system with a unique
equilibrium point characterized by a nonstandard fixed point equation.
"
0512094,Low-Energy Sensor Network Time Synchronization as an Emergent Property,"  The primary contribution of this work is to examine the energy efficiency of
pulse coupled oscillation for time synchronization in a realistic wireless
network environment and to explore the impact of mobility on convergence rate.
Energy coupled oscillation is susceptible to interference; this approach uses
reception and decoding of short packet bursts to eliminate this problem. The
energy efficiency of a commonly used timestamp broadcast algorithm is compared
and contrasted with pulse-coupled oscillation. The emergent pulse coupled
oscillation technique shows greater energy efficiency as well as robustness
with mobility. A proportion of the sensors may be integrated with GPS receivers
in order to obtain a master clock time.
"
0512099,Mathematical Models in Schema Theory,"  In this paper, a mathematical schema theory is developed. This theory has
three roots: brain theory schemas, grid automata, and block-shemas. In Section
2 of this paper, elements of the theory of grid automata necessary for the
mathematical schema theory are presented. In Section 3, elements of brain
theory necessary for the mathematical schema theory are presented. In Section
4, other types of schemas are considered. In Section 5, the mathematical schema
theory is developed. The achieved level of schema representation allows one to
model by mathematical tools virtually any type of schemas considered before,
including schemas in neurophisiology, psychology, computer science, Internet
technology, databases, logic, and mathematics.
"
0512104,Reversible CAM Processor Modeled After Quantum Computer Behavior,"  Proposed below is a reversible digital computer modeled after the natural
behavior of a quantum system. Using approaches usually reserved for idealized
quantum computers, the Reversible CAM, or State Vector Parallel (RSVP)
processor can easily find keywords in an unstructured database (that is, it can
solve a needle in a haystack problem). The RSVP processor efficiently solves a
SAT (Satisfiability of Boolean Formulae) problem; also it can aid in the
solution of a GP (Global Properties of Truth Table) problem. The power delay
product of the RSVP processor is exponentially lower than that of a standard
CAM programmed to perform similar operations.
"
0601010,Multi-Map Orbit Hopping Chaotic Stream Cipher,"  In this paper we propose a multi-map orbit hopping chaotic stream cipher that
utilizes the idea of spread spectrum mechanism for secure digital
communications and fundamental chaos characteristics of mixing, unpredictable,
and extremely sensitive to initial conditions. The design, key and subkeys, and
detail implementation of the system are addressed. A variable number of well
studied chaotic maps form a map bank. And the key determines how the system
hops between multiple orbits, and it also determines the number of maps, the
number of orbits for each map, and the number of sample points for each orbits.
A detailed example is provided.
"
0601018,A comparison between two logical formalisms for rewriting,"  Meseguer's rewriting logic and the rewriting logic CRWL are two well-known
approaches to rewriting as logical deduction that, despite some clear
similarities, were designed with different objectives. Here we study the
relationships between them, both at a syntactic and at a semantic level. Even
though it is not possible to establish an entailment system map between them,
both can be naturally simulated in each other. Semantically, there is no
embedding between the corresponding institutions. Along the way, the notions of
entailment and satisfaction in Meseguer's rewriting logic are generalized. We
also use the syntactic results to prove reflective properties of CRWL.
"
0601029,Sending a Bi-Variate Gaussian Source over a Gaussian MAC,"  We consider a problem where a memoryless bi-variate Gaussian source is to be
transmitted over an additive white Gaussian multiple-access channel with two
transmitting terminals and one receiving terminal. The first transmitter only
sees the first source component and the second transmitter only sees the second
source component. We are interested in the pair of mean squared-error
distortions at which the receiving terminal can reproduce each of the source
components.
  It is demonstrated that in the symmetric case, below a certain
signal-to-noise ratio (SNR) threshold, which is determined by the source
correlation, uncoded communication is optimal. For SNRs above this threshold we
present outer and inner bounds on the achievable distortions.
"
0601034,Using First-Order Logic to Reason about Policies,"  A policy describes the conditions under which an action is permitted or
forbidden. We show that a fragment of (multi-sorted) first-order logic can be
used to represent and reason about policies. Because we use first-order logic,
policies have a clear syntax and semantics. We show that further restricting
the fragment results in a language that is still quite expressive yet is also
tractable. More precisely, questions about entailment, such as `May Alice
access the file?', can be answered in time that is a low-order polynomial
(indeed, almost linear in some cases), as can questions about the consistency
of policy sets.
"
0601044,"Genetic Programming, Validation Sets, and Parsimony Pressure","  Fitness functions based on test cases are very common in Genetic Programming
(GP). This process can be assimilated to a learning task, with the inference of
models from a limited number of samples. This paper is an investigation on two
methods to improve generalization in GP-based learning: 1) the selection of the
best-of-run individuals using a three data sets methodology, and 2) the
application of parsimony pressure in order to reduce the complexity of the
solutions. Results using GP in a binary classification setup show that while
the accuracy on the test sets is preserved, with less variances compared to
baseline results, the mean tree size obtained with the tested methods is
significantly reduced.
"
0601045,"PageRank without hyperlinks: Structural re-ranking using links induced
  by language models","  Inspired by the PageRank and HITS (hubs and authorities) algorithms for Web
search, we propose a structural re-ranking approach to ad hoc information
retrieval: we reorder the documents in an initially retrieved set by exploiting
asymmetric relationships between them. Specifically, we consider generation
links, which indicate that the language model induced from one document assigns
high probability to the text of another; in doing so, we take care to prevent
bias against long documents. We study a number of re-ranking criteria based on
measures of centrality in the graphs formed by generation links, and show that
integrating centrality into standard language-model-based retrieval is quite
effective at improving precision at top ranks.
"
0601051,A Constructive Semantic Characterization of Aggregates in ASP,"  This technical note describes a monotone and continuous fixpoint operator to
compute the answer sets of programs with aggregates. The fixpoint operator
relies on the notion of aggregate solution. Under certain conditions, this
operator behaves identically to the three-valued immediate consequence operator
$\Phi^{aggr}_P$ for aggregate programs, independently proposed Pelov et al.
This operator allows us to closely tie the computational complexity of the
answer set checking and answer sets existence problems to the cost of checking
a solution of the aggregates in the program. Finally, we relate the semantics
described by the operator to other proposals for logic programming with
aggregates.
  To appear in Theory and Practice of Logic Programming (TPLP).
"
0601063,"Optimal Point-to-Point Trajectory Tracking of Redundant Manipulators
  using Generalized Pattern Search","  Optimal point-to-point trajectory planning for planar redundant manipulator
is considered in this study. The main objective is to minimize the sum of the
position error of the end-effector at each intermediate point along the
trajectory so that the end-effector can track the prescribed trajectory
accurately. An algorithm combining Genetic Algorithm and Pattern Search as a
Generalized Pattern Search GPS is introduced to design the optimal trajectory.
To verify the proposed algorithm, simulations for a 3-D-O-F planar manipulator
with different end-effector trajectories have been carried out. A comparison
between the Genetic Algorithm and the Generalized Pattern Search shows that The
GPS gives excellent tracking performance.
"
0601074,Joint universal lossy coding and identification of i.i.d. vector sources,"  The problem of joint universal source coding and modeling, addressed by
Rissanen in the context of lossless codes, is generalized to fixed-rate lossy
coding of continuous-alphabet memoryless sources. We show that, for bounded
distortion measures, any compactly parametrized family of i.i.d. real vector
sources with absolutely continuous marginals (satisfying appropriate smoothness
and Vapnik--Chervonenkis learnability conditions) admits a joint scheme for
universal lossy block coding and parameter estimation, and give nonasymptotic
estimates of convergence rates for distortion redundancies and variational
distances between the active source and the estimated source. We also present
explicit examples of parametric sources admitting such joint universal
compression and modeling schemes.
"
0601090,Improved Nearly-MDS Expander Codes,"  A construction of expander codes is presented with the following three
properties:
  (i) the codes lie close to the Singleton bound, (ii) they can be encoded in
time complexity that is linear in their code length, and (iii) they have a
linear-time bounded-distance decoder.
  By using a version of the decoder that corrects also erasures, the codes can
replace MDS outer codes in concatenated constructions, thus resulting in
linear-time encodable and decodable codes that approach the Zyablov bound or
the capacity of memoryless channels. The presented construction improves on an
earlier result by Guruswami and Indyk in that any rate and relative minimum
distance that lies below the Singleton bound is attainable for a significantly
smaller alphabet size.
"
0601096,On timed automata with input-determined guards,"  We consider a general notion of timed automata with input-determined guards
and show that they admit a robust logical framework along the lines of [D
'Souza03], in terms of a monadic second order logic characterisation and an
expressively complete timed temporal logic. We then generalize these automata
using the notion of recursive operators introduced by Henzinger, Raskin, and
Schobbens, and show that they admit a similar logical framework. These results
hold in the ``pointwise'' semantics. We finally use this framework to show that
the real-time logic MITL of Alur et al is expressively complete with respect to
an MSO corresponding to an appropriate input-determined operator.
"
0601125,"Metadata aggregation and ""automated digital libraries"": A retrospective
  on the NSDL experience","  Over three years ago, the Core Integration team of the National Science
Digital Library (NSDL) implemented a digital library based on metadata
aggregation using Dublin Core and OAI-PMH. The initial expectation was that
such low-barrier technologies would be relatively easy to automate and
administer. While this architectural choice permitted rapid deployment of a
production NSDL, our three years of experience have contradicted our original
expectations of easy automation and low people cost. We have learned that
alleged ""low-barrier"" standards are often harder to deploy than expected. In
this paper we report on this experience and comment on the general cost, the
functionality, and the ultimate effectiveness of this architecture.
"
0601130,From Dumb Wireless Sensors to Smart Networks using Network Coding,"  The vision of wireless sensor networks is one of a smart collection of tiny,
dumb devices. These motes may be individually cheap, unintelligent, imprecise,
and unreliable. Yet they are able to derive strength from numbers, rendering
the whole to be strong, reliable and robust. Our approach is to adopt a
distributed and randomized mindset and rely on in network processing and
network coding. Our general abstraction is that nodes should act only locally
and independently, and the desired global behavior should arise as a collective
property of the network. We summarize our work and present how these ideas can
be applied for communication and storage in sensor networks.
"
0602002,"Simulating Network Influence Algorithms Using Particle-Swarms: PageRank
  and PageRank-Priors","  A particle-swarm is a set of indivisible processing elements that traverse a
network in order to perform a distributed function. This paper will describe a
particular implementation of a particle-swarm that can simulate the behavior of
the popular PageRank algorithm in both its {\it global-rank} and {\it
relative-rank} incarnations. PageRank is compared against the particle-swarm
method on artificially generated scale-free networks of 1,000 nodes constructed
using a common gamma value, $\gamma = 2.5$. The running time of the
particle-swarm algorithm is $O(|P|+|P|t)$ where $|P|$ is the size of the
particle population and $t$ is the number of particle propagation iterations.
The particle-swarm method is shown to be useful due to its ease of extension
and running time.
"
0602015,"On the Asymptotic Performance of Multiple Antenna Channels with Fast
  Channel Feedback","  In this paper, we analyze the asymptotic performance of multiple antenna
channels where the transmitter has either perfect or finite bit channel state
information. Using the diversity-multiplexing tradeoff to characterize the
system performance, we demonstrate that channel feedback can fundamentally
change the system behavior. Even one-bit of information can increase the
diversity order of the system compared to the system with no transmitter
information. In addition, as the amount of channel information at the
transmitter increases, the diversity order for each multiplexing gain increases
and goes to infinity for perfect transmitter information. The major reason for
diversity order gain is a ""location-dependent"" temporal power control, which
adapts the power control strategy based on the average channel conditions of
the channel.
"
0602018,"Improving the CSIEC Project and Adapting It to the English Teaching and
  Learning in China","  In this paper after short review of the CSIEC project initialized by us in
2003 we present the continuing development and improvement of the CSIEC project
in details, including the design of five new Microsoft agent characters
representing different virtual chatting partners and the limitation of
simulated dialogs in specific practical scenarios like graduate job application
interview, then briefly analyze the actual conditions and features of its
application field: web-based English education in China. Finally we introduce
our efforts to adapt this system to the requirements of English teaching and
learning in China and point out the work next to do.
"
0602022,Avoiding the Bloat with Stochastic Grammar-based Genetic Programming,"  The application of Genetic Programming to the discovery of empirical laws is
often impaired by the huge size of the search space, and consequently by the
computer resources needed. In many cases, the extreme demand for memory and CPU
is due to the massive growth of non-coding segments, the introns. The paper
presents a new program evolution framework which combines distribution-based
evolution in the PBIL spirit, with grammar-based genetic programming; the
information is stored as a probability distribution on the gra mmar rules,
rather than in a population. Experiments on a real-world like problem show that
this approach gives a practical solution to the problem of intron growth.
"
0602056,"Building Scenarios for Environmental Management and Planning: An
  IT-Based Approach","  Oftentimes, the need to build multidiscipline knowledge bases, oriented to
policy scenarios, entails the involvement of stakeholders in manifold domains,
with a juxtaposition of different languages whose semantics can hardly allow
inter-domain transfers. A useful support for planning is the building up of
durable IT based interactive platforms, where it is possible to modify initial
positions toward a semantic convergence. The present paper shows an area-based
application of these tools, for the integrated distance-management of different
forms of knowledge expressed by selected stakeholders about environmental
planning issues, in order to build alternative development scenarios.
  Keywords: Environmental planning, Scenario building, Multi-source knowledge,
IT-based
"
0602057,Plane Decompositions as Tools for Approximation,"  Tree decompositions were developed by Robertson and Seymour. Since then
algorithms have been developed to solve intractable problems efficiently for
graphs of bounded treewidth. In this paper we extend tree decompositions to
allow cycles to exist in the decomposition graph; we call these new
decompositions plane decompositions because we require that the decomposition
graph be planar. First, we give some background material about tree
decompositions and an overview of algorithms both for decompositions and for
approximations of planar graphs. Then, we give our plane decomposition
definition and an algorithm that uses this decomposition to approximate the
size of the maximum independent set of the underlying graph in polynomial time.
"
0602077,Bisimulations of enrichments,"  In this paper we show that classical notions from automata theory such as
simulation and bisimulation can be lifted to the context of enriched
categories. The usual properties of bisimulation are nearly all preserved in
this new context. The class of enriched functors that correspond to functionnal
bisimulations surjective on objects is investigated and appears ""nearly"" open
in the sense of Joyal and Moerdijk. Seeing the change of base techniques as a
convenient means to define process refinement/abstractions, we give sufficient
conditions for the change of base categories to preserve bisimularity. We apply
these concepts to Betti's generalized automata, categorical transition systems,
and other exotic categories.
"
0602080,Pants Decomposition of the Punctured Plane,"  A pants decomposition of an orientable surface S is a collection of simple
cycles that partition S into pants, i.e., surfaces of genus zero with three
boundary cycles. Given a set P of n points in the plane, we consider the
problem of computing a pants decomposition of the surface S which is the plane
minus P, of minimum total length. We give a polynomial-time approximation
scheme using Mitchell's guillotine rectilinear subdivisions. We give a
quartic-time algorithm to compute the shortest pants decomposition of S when
the cycles are restricted to be axis-aligned boxes, and a quadratic-time
algorithm when all the points lie on a line; both exact algorithms use dynamic
programming with Yao's speedup.
"
0602082,"Digital Libraries: From Process Modelling to Grid-based Service Oriented
  Architecture","  Graphical Business Process Modelling Languages (BPML) like Role Activity
Diagrams (RAD) provide ease and flexibility for modelling business behaviour.
However, these languages show limited applicability in terms of enactment over
distributed systems paradigms like Service Oriented Architecture (SOA) based
grid computing. This paper investigates RAD modelling of a Scientific
Publishing Process (SPP) for Digital Libraries (DL) and tries to determine the
suitability of Pi-Calculus based formal approaches to enact SOA based grid
computing. In order to achieve this purpose, the Pi-Calculus based formal
transformation from a RAD model of SPP for DL draws attention towards a number
of challenging issues including issues that require particular design
considerations for appropriate enactment in a SOA based grid system.
"
0602093,Rational stochastic languages,"  The goal of the present paper is to provide a systematic and comprehensive
study of rational stochastic languages over a semiring K \in {Q, Q +, R, R+}. A
rational stochastic language is a probability distribution over a free monoid
\Sigma^* which is rational over K, that is which can be generated by a
multiplicity automata with parameters in K. We study the relations between the
classes of rational stochastic languages S rat K (\Sigma). We define the notion
of residual of a stochastic language and we use it to investigate properties of
several subclasses of rational stochastic languages. Lastly, we study the
representation of rational stochastic languages by means of multiplicity
automata.
"
0602094,Effect of CSMA/CD on Self-Similarity of Network Traffic,"  It is now well known that Internet traffic exhibits self-similarity, which
cannot be described by traditional Markovian models such as the Poisson
process. The causes of self-similarity of network traffic must be identified
because understanding the nature of network traffic is critical in order to
properly design and implement computer networks and network services like the
World Wide Web. While some researchers have argued self similarity is generated
by the typical applications or caused by Transport layer Protocols, it is also
possible that the CSMA/CD protocol may cause or at least contribute to this
phenomenon. In this paper, we use NS simulator to study the effect of CSMA/CD
Exponential Backoff retransmission algorithm on Traffic Self similarity.
"
0602095,Epsilon-Unfolding Orthogonal Polyhedra,"  An unfolding of a polyhedron is produced by cutting the surface and
flattening to a single, connected, planar piece without overlap (except
possibly at boundary points). It is a long unsolved problem to determine
whether every polyhedron may be unfolded. Here we prove, via an algorithm, that
every orthogonal polyhedron (one whose faces meet at right angles) of genus
zero may be unfolded. Our cuts are not necessarily along edges of the
polyhedron, but they are always parallel to polyhedron edges. For a polyhedron
of n vertices, portions of the unfolding will be rectangular strips which, in
the worst case, may need to be as thin as epsilon = 1/2^{Omega(n)}.
"
0603002,On comparing sums of square roots of small integers,"  Let $k$ and $n$ be positive integers, $n>k$. Define $r(n,k)$ to be the
minimum positive value of $$ |\sqrt{a_1} + ... + \sqrt{a_k} - \sqrt{b_1} - >...
-\sqrt{b_k} | $$ where $ a_1, a_2, ..., a_k, b_1, b_2, ..., b_k $ are positive
integers no larger than $n$. It is an important problem in computational
geometry to determine a good upper bound of $-\log r(n,k)$. In this paper we
prove an upper bound of $ 2^{O(n/\log n)} \log n$, which is better than the
best known result $O(2^{2k} \log n)$ whenever $ n \leq ck\log k$ for some
constant $c$. In particular, our result implies a {\em subexponential}
algorithm to compare two sums of square roots of integers of size $o(k\log k)$.
"
0603013,On the MacWilliams Identity for Convolutional Codes,"  The adjacency matrix associated with a convolutional code collects in a
detailed manner information about the weight distribution of the code. A
MacWilliams Identity Conjecture, stating that the adjacency matrix of a code
fully determines the adjacency matrix of the dual code, will be formulated, and
an explicit formula for the transformation will be stated. The formula involves
the MacWilliams matrix known from complete weight enumerators of block codes.
The conjecture will be proven for the class of convolutional codes where either
the code itself or its dual does not have Forney indices bigger than one. For
the general case the conjecture is backed up by many examples, and a weaker
version will be established.
"
0603015,The Basic Kak Neural Network with Complex Inputs,"  The Kak family of neural networks is able to learn patterns quickly, and this
speed of learning can be a decisive advantage over other competing models in
many applications. Amongst the implementations of these networks are those
using reconfigurable networks, FPGAs and optical networks. In some
applications, it is useful to use complex data, and it is with that in mind
that this introduction to the basic Kak network with complex inputs is being
presented. The training algorithm is prescriptive and the network weights are
assigned simply upon examining the inputs. The input is mapped using quaternary
encoding for purpose of efficienty. This network family is part of a larger
hierarchy of learning schemes that include quantum models.
"
0603023,"Metric State Space Reinforcement Learning for a Vision-Capable Mobile
  Robot","  We address the problem of autonomously learning controllers for
vision-capable mobile robots. We extend McCallum's (1995) Nearest-Sequence
Memory algorithm to allow for general metrics over state-action trajectories.
We demonstrate the feasibility of our approach by successfully running our
algorithm on a real mobile robot. The algorithm is novel and unique in that it
(a) explores the environment and learns directly on a mobile robot without
using a hand-made computer model as an intermediate step, (b) does not require
manual discretization of the sensor input space, (c) works in piecewise
continuous perceptual spaces, and (d) copes with partial observability.
Together this allows learning from much less experience compared to previous
methods.
"
0603027,"On the Second-Order Statistics of the Instantaneous Mutual Information
  in Rayleigh Fading Channels","  In this paper, the second-order statistics of the instantaneous mutual
information are studied, in time-varying Rayleigh fading channels, assuming
general non-isotropic scattering environments. Specifically, first the
autocorrelation function, correlation coefficient, level crossing rate, and the
average outage duration of the instantaneous mutual information are
investigated in single-input single-output (SISO) systems. Closed-form exact
expressions are derived, as well as accurate approximations in low- and
high-SNR regimes. Then, the results are extended to multiple-input
single-output and single-input multiple-output systems, as well as
multiple-input multiple-output systems with orthogonal space-time block code
transmission. Monte Carlo simulations are provided to verify the accuracy of
the analytical results. The results shed more light on the dynamic behavior of
the instantaneous mutual information in mobile fading channels.
"
0603034,Metatheory of actions: beyond consistency,"  Consistency check has been the only criterion for theory evaluation in
logic-based approaches to reasoning about actions. This work goes beyond that
and contributes to the metatheory of actions by investigating what other
properties a good domain description in reasoning about actions should have. We
state some metatheoretical postulates concerning this sore spot. When all
postulates are satisfied together we have a modular action theory. Besides
being easier to understand and more elaboration tolerant in McCarthy's sense,
modular theories have interesting properties. We point out the problems that
arise when the postulates about modularity are violated and propose algorithmic
checks that can help the designer of an action theory to overcome them.
"
0603041,Locally Adaptive Block Thresholding Method with Continuity Constraint,"  We present an algorithm that enables one to perform locally adaptive block
thresholding, while maintaining image continuity. Images are divided into
sub-images based some standard image attributes and thresholding technique is
employed over the sub-images. The present algorithm makes use of the thresholds
of neighboring sub-images to calculate a range of values. The image continuity
is taken care by choosing the threshold of the sub-image under consideration to
lie within the above range. After examining the average range values for
various sub-image sizes of a variety of images, it was found that the range of
acceptable threshold values is substantially high, justifying our assumption of
exploiting the freedom of range for bringing out local details.
"
0603053,"Automatic generation of simplified weakest preconditions for integrity
  constraint verification","  Given a constraint $c$ assumed to hold on a database $B$ and an update $u$ to
be performed on $B$, we address the following question: will $c$ still hold
after $u$ is performed? When $B$ is a relational database, we define a
confluent terminating rewriting system which, starting from $c$ and $u$,
automatically derives a simplified weakest precondition $wp(c,u)$ such that,
whenever $B$ satisfies $wp(c,u)$, then the updated database $u(B)$ will satisfy
$c$, and moreover $wp(c,u)$ is simplified in the sense that its computation
depends only upon the instances of $c$ that may be modified by the update. We
then extend the definition of a simplified $wp(c,u)$ to the case of deductive
databases; we prove it using fixpoint induction.
"
0603059,Derivatives of Entropy Rate in Special Families of Hidden Markov Chains,"  Consider a hidden Markov chain obtained as the observation process of an
ordinary Markov chain corrupted by noise. Zuk, et. al. [13], [14] showed how,
in principle, one can explicitly compute the derivatives of the entropy rate of
at extreme values of the noise. Namely, they showed that the derivatives of
standard upper approximations to the entropy rate actually stabilize at an
explicit finite time. We generalize this result to a natural class of hidden
Markov chains called ``Black Holes.'' We also discuss in depth special cases of
binary Markov chains observed in binary symmetric noise, and give an abstract
formula for the first derivative in terms of a measure on the simplex due to
Blackwell.
"
0603064,Guessing under source uncertainty,"  This paper considers the problem of guessing the realization of a finite
alphabet source when some side information is provided. The only knowledge the
guesser has about the source and the correlated side information is that the
joint source is one among a family. A notion of redundancy is first defined and
a new divergence quantity that measures this redundancy is identified. This
divergence quantity shares the Pythagorean property with the Kullback-Leibler
divergence. Good guessing strategies that minimize the supremum redundancy
(over the family) are then identified. The min-sup value measures the richness
of the uncertainty set. The min-sup redundancies for two examples - the
families of discrete memoryless sources and finite-state arbitrarily varying
sources - are then determined.
"
0603066,A Feedback Reduction Technique for MIMO Broadcast Channels,"  A multiple antenna broadcast channel with perfect channel state information
at the receivers is considered. If each receiver quantizes its channel
knowledge to a finite number of bits which are fed back to the transmitter, the
large capacity benefits of the downlink channel can be realized. However, the
required number of feedback bits per mobile must be scaled with both the number
of transmit antennas and the system SNR, and thus can be quite large in even
moderately sized systems. It is shown that a small number of antennas can be
used at each receiver to improve the quality of the channel estimate provided
to the transmitter. As a result, the required feedback rate per mobile can be
significantly decreased.
"
0603071,An Explicit Solution to Post's Problem over the Reals,"  In the BCSS model of real number computations we prove a concrete and
explicit semi-decidable language to be undecidable yet not reducible from (and
thus strictly easier than) the real Halting Language. This solution to Post's
Problem over the reals significantly differs from its classical, discrete
variant where advanced diagonalization techniques are only known to yield the
existence of such intermediate Turing degrees. Strengthening the above result,
we construct (that is, obtain again explicitly) as well an uncountable number
of incomparable semi-decidable Turing degrees below the real Halting problem in
the BCSS model. Finally we show the same to hold for the linear BCSS model,
that is over (R,+,-,<) rather than (R,+,-,*,/,<).
"
0603087,"IP over P2P: Enabling Self-configuring Virtual IP Networks for Grid
  Computing","  Peer-to-peer (P2P) networks have mostly focused on task oriented networking,
where networks are constructed for single applications, i.e. file-sharing, DNS
caching, etc. In this work, we introduce IPOP, a system for creating virtual IP
networks on top of a P2P overlay. IPOP enables seamless access to Grid
resources spanning multiple domains by aggregating them into a virtual IP
network that is completely isolated from the physical network. The virtual IP
network provided by IPOP supports deployment of existing IP-based protocols
over a robust, self-configuring P2P overlay. We present implementation details
as well as experimental measurement results taken from LAN, WAN, and Planet-Lab
tests.
"
0603100,Efficient Compression of Prolog Programs,"  We propose a special-purpose class of compression algorithms for efficient
compression of Prolog programs. It is a dictionary-based compression method,
specially designed for the compression of Prolog code, and therefore we name it
PCA (Prolog Compression Algorithm). According to the experimental results this
method provides better compression than state-of-the-art general-purpose
compression algorithms. Since the algorithm works with Prolog syntactic
entities (e.g. atoms, terms, etc.) the implementation of a Prolog prototype is
straightforward and very easy to use in any Prolog application that needs
compression. Although the algorithm is designed for Prolog programs, the idea
can be easily applied for the compression of programs written in other (logic)
languages.
"
0603101,Prolog Server Pages,"  Prolog Server Pages (PSP) is a scripting language, based on Prolog, than can
be embedded in HTML documents. To run PSP applications one needs a web server,
a web browser and a PSP interpreter. The code is executed, by the interpreter,
on the server-side (web server) and the output (together with the html code in
witch the PSP code is embedded) is sent to the client-side (browser). The
current implementation supports Apache Web Server. We implemented an Apache web
server module that handles PSP files, and sends the result (an html document)
to the client. PSP supports both GET and POST http requests. It also provides
methods for working with http cookies.
"
0603103,Bargaining over the interference channel,"  In this paper we analyze the interference channel as a conflict situation.
This viewpoint implies that certain points in the rate region are unreasonable
to one of the players. Therefore these points cannot be considered achievable
based on game theoretic considerations. We then propose to use Nash bargaining
solution as a tool that provides preferred points on the boundary of the game
theoretic rate region. We provide analysis for the 2x2 intereference channel
using the FDM achievable rate region. We also outline how to generalize our
results to other achievable rate regions for the interference channel as well
as the multiple access channel.
  Keywords: Spectrum optimization, distributed coordination, game theory,
interference channel, multiple access channel.
"
0603104,"Verification of Ptime reducibility for system F terms via Dual Light
  Affine Logic","  In a previous work we introduced Dual Light Affine Logic (DLAL)
([BaillotTerui04]) as a variant of Light Linear Logic suitable for guaranteeing
complexity properties on lambda-calculus terms: all typable terms can be
evaluated in polynomial time and all Ptime functions can be represented. In the
present work we address the problem of typing lambda-terms in second-order
DLAL. For that we give a procedure which, starting with a term typed in system
F, finds all possible ways to decorate it into a DLAL typed term. We show that
our procedure can be run in time polynomial in the size of the original Church
typed system F term.
"
0603110,"Asymptotic Learnability of Reinforcement Problems with Arbitrary
  Dependence","  We address the problem of reinforcement learning in which observations may
exhibit an arbitrary form of stochastic dependence on past observations and
actions. The task for an agent is to attain the best possible asymptotic reward
where the true generating environment is unknown but belongs to a known
countable family of environments. We find some sufficient conditions on the
class of environments under which an agent exists which attains the best
asymptotic reward for any environment in the class. We analyze how tight these
conditions are and how they relate to different probabilistic assumptions known
in reinforcement learning and related fields, such as Markov Decision Processes
and mixing conditions.
"
0603120,Approximation Algorithms for K-Modes Clustering,"  In this paper, we study clustering with respect to the k-modes objective
function, a natural formulation of clustering for categorical data. One of the
main contributions of this paper is to establish the connection between k-modes
and k-median, i.e., the optimum of k-median is at most twice the optimum of
k-modes for the same categorical data clustering problem. Based on this
observation, we derive a deterministic algorithm that achieves an approximation
factor of 2. Furthermore, we prove that the distance measure in k-modes defines
a metric. Hence, we are able to extend existing approximation algorithms for
metric k-median to k-modes. Empirical results verify the superiority of our
method.
"
0603124,Diversity-Multiplexing Tradeoff of Double Scattering MIMO Channels,"  It is well known that the presence of double scattering degrades the
performance of a MIMO channel, in terms of both the multiplexing gain and the
diversity gain. In this paper, a closed-form expression of the
diversity-multiplexing tradeoff (DMT) of double scattering MIMO channels is
obtained. It is shown that, for a channel with nT transmit antennas, nR receive
antennas and nS scatterers, the DMT only depends on the ordered version of the
triple (nT,nS,nR), for arbitrary nT, nS and nR. The condition under which the
double scattering channel has the same DMT as the single scattering channel is
also established.
"
0603129,"A Business Goal Driven Approach for Understanding and Specifying
  Information Security Requirements","  In this paper we present an approach for specifying and prioritizing
information security requirements in organizations. It is important to
prioritize security requirements since hundred per cent security is not
achievable and the limited resources available should be directed to satisfy
the most important ones. We propose to link explicitly security requirements
with the organization's business vision, i.e. to provide business rationale for
security requirements. The rationale is then used as a basis for comparing the
importance of different security requirements. A conceptual framework is
presented, where the relationships between business vision, critical impact
factors and valuable assets (together with their security requirements) are
shown.
"
0603131,"Error Rate Analysis for Coded Multicarrier Systems over Quasi-Static
  Fading Channels","  This paper presents two methods for approximating the performance of coded
multicarrier systems operating over frequency-selective, quasi-static fading
channels with non-ideal interleaving. The first method is based on
approximating the performance of the system over each realization of the
channel, and is suitable for obtaining the outage performance of this type of
system. The second method is based on knowledge of the correlation matrix of
the frequency-domain channel gains and can be used to directly obtain the
average performance. Both of the methods are applicable for
convolutionally-coded interleaved systems employing Quadrature Amplitude
Modulation (QAM). As examples, both methods are used to study the performance
of the Multiband Orthogonal Frequency Division Multiplexing (OFDM) proposal for
high data-rate Ultra-Wideband (UWB) communication.
"
0603132,Graphics Turing Test,"  We define a Graphics Turing Test to measure graphics performance in a similar
manner to the definition of the traditional Turing Test. To pass the test one
needs to reach a computational scale, the Graphics Turing Scale, for which
Computer Generated Imagery becomes comparatively indistinguishable from real
images while also being interactive. We derive an estimate for this
computational scale which, although large, is within reach of todays
supercomputers. We consider advantages and disadvantages of various computer
systems designed to pass the Graphics Turing Test. Finally we discuss
commercial applications from the creation of such a system, in particular
Interactive Cinema.
"
0604010,Nearly optimal exploration-exploitation decision thresholds,"  While in general trading off exploration and exploitation in reinforcement
learning is hard, under some formulations relatively simple solutions exist. In
this paper, we first derive upper bounds for the utility of selecting different
actions in the multi-armed bandit setting. Unlike the common statistical upper
confidence bounds, these explicitly link the planning horizon, uncertainty and
the need for exploration explicit. The resulting algorithm can be seen as a
generalisation of the classical Thompson sampling algorithm. We experimentally
test these algorithms, as well as $\epsilon$-greedy and the value of perfect
information heuristics. Finally, we also introduce the idea of bagging for
reinforcement learning. By employing a version of online bootstrapping, we can
efficiently sample from an approximate posterior distribution.
"
0604034,"Squarepants in a Tree: Sum of Subtree Clustering and Hyperbolic Pants
  Decomposition","  We provide efficient constant factor approximation algorithms for the
problems of finding a hierarchical clustering of a point set in any metric
space, minimizing the sum of minimimum spanning tree lengths within each
cluster, and in the hyperbolic or Euclidean planes, minimizing the sum of
cluster perimeters. Our algorithms for the hyperbolic and Euclidean planes can
also be used to provide a pants decomposition, that is, a set of disjoint
simple closed curves partitioning the plane minus the input points into subsets
with exactly three boundary components, with approximately minimum total
length. In the Euclidean case, these curves are squares; in the hyperbolic
case, they combine our Euclidean square pants decomposition with our tree
clustering method for general metric spaces.
"
0604035,Certain new M-matrices and their properties and applications,"  The Mn-matrix was defined by Mohan [20] in which he has shown a method of
constructing (1,-1)-matrices and studied some of their properties. The
(1,-1)-matrices were constructed and studied by Cohn [5],Wang [33], Ehrlich [8]
and Ehrlich and Zeller[9]. But in this paper, while giving some resemblances of
this matrix with Hadamard matrix, and by naming it as M-matrix, we show how to
construct partially balanced incomplete block (PBIB) designs and some regular
bipartite graphs by it. We have considered two types of these M- matrices. Also
we will make a mention of certain applications of these M-matrices in signal
and communication processing, and network systems and end with some open
problems.
"
0604044,"A new M-matrix of Type III, its properties and applications","  Some binary matrices like (1,-1) and (1,0) were studied by many authors like
Cohn, Wang, Ehlich and Ehlich and Zeller, and Mohan, Kageyama, Lee, and Gao. In
this recent paper by Mohan et al considered the M-matrices of Type I and II by
studying some of their properties and applications. In the present paper they
discussed the M-matrices of Type III, and studied their properties and
applications. They gave some constructions of SPBIB designs and some
corresponding M-graphs, which are being constructed by it. This is the
continuation of our earlier research work in this direction, and these papers
establish the importance of non-orthogonal matrices as well.
"
0604061,Effect of E-printing on Citation Rates in Astronomy and Physics,"  In this report we examine the change in citation behavior since the
introduction of the arXiv e-print repository (Ginsparg, 2001). It has been
observed that papers that initially appear as arXiv e-prints get cited more
than papers that do not (Lawrence, 2001; Brody et al., 2004; Schwarz &
Kennicutt, 2004; Kurtz et al., 2005a, Metcalfe, 2005). Using the citation
statistics from the NASA-Smithsonian Astrophysics Data System (ADS; Kurtz et
al., 1993, 2000), we confirm the findings from other studies, we examine the
average citation rate to e-printed papers in the Astrophysical Journal, and we
show that for a number of major astronomy and physics journals the most
important papers are submitted to the arXiv e-print repository first.
"
0604063,Golden Space-Time Trellis Coded Modulation,"  In this paper, we present a concatenated coding scheme for a high rate
$2\times 2$ multiple-input multiple-output (MIMO) system over slow fading
channels. The inner code is the Golden code \cite{Golden05} and the outer code
is a trellis code. Set partitioning of the Golden code is designed specifically
to increase the minimum determinant. The branches of the outer trellis code are
labeled with these partitions. Viterbi algorithm is applied for trellis
decoding. In order to compute the branch metrics a lattice sphere decoder is
used. The general framework for code optimization is given. The performance of
the proposed concatenated scheme is evaluated by simulation. It is shown that
the proposed scheme achieves significant performance gains over uncoded Golden
code.
"
0604074,"Information and multiaccess interference in a complexity-constrained
  vector channel","  Rodrigo de Miguel et al 2007 J. Phys. A: Math. Theor. 40 5241-5260: A noisy
vector channel operating under a strict complexity constraint at the receiver
is introduced. According to this constraint, detected bits, obtained by
performing hard decisions directly on the channel's matched filter output, must
be the same as the transmitted binary inputs. An asymptotic analysis is carried
out using mathematical tools imported from the study of neural networks, and it
is shown that, under a bounded noise assumption, such complexity-constrained
channel exhibits a non-trivial Shannon-theoretic capacity. It is found that
performance relies on rigorous interference-based multiuser cooperation at the
transmitter and that this cooperation is best served when all transmitters use
the same amplitude.
"
0604083,"Optimum Asymptotic Multiuser Efficiency of Pseudo-Orthogonal Randomly
  Spread CDMA","  A $K$-user pseudo-orthogonal (PO) randomly spread CDMA system, equivalent to
transmission over a subset of $K'\leq K$ single-user Gaussian channels, is
introduced. The high signal-to-noise ratio performance of the PO-CDMA is
analyzed by rigorously deriving its asymptotic multiuser efficiency (AME) in
the large system limit. Interestingly, the $K'$-optimized PO-CDMA transceiver
scheme yields an AME which is practically equal to 1 for system loads smaller
than 0.1 and lower bounded by 1/4 for increasing loads. As opposed to the
vanishing efficiency of linear multiuser detectors, the derived efficiency is
comparable to the ultimate CDMA efficiency achieved for the intractable optimal
multiuser detector.
"
0604103,Further Evaluationh of VLEs using HCI and Educational Metrics,"  Under consideration are the general set of Human computer Interaction (HCI)
and Educational principles from prominent authors in the field and the
construction of a system for evaluating Virtual Learning Environments (VLEs)
with respect to the application of these HCI and Educational Principles. A
frequency analysis of principles is used to obtain the most significant set.
Metrics are devised to provide objective measures of these principles and a
consistent testing regime is introduced. These principles are used to analyse
the University VLE Blackboard. An open source VLE is also constructed with
similar content to Blackboard courses so that a systematic comparison can be
made. HCI and Educational metrics are determined for each VLE.
"
0605012,Perspective alignment in spatial language,"  It is well known that perspective alignment plays a major role in the
planning and interpretation of spatial language. In order to understand the
role of perspective alignment and the cognitive processes involved, we have
made precise complete cognitive models of situated embodied agents that
self-organise a communication system for dialoging about the position and
movement of real world objects in their immediate surroundings. We show in a
series of robotic experiments which cognitive mechanisms are necessary and
sufficient to achieve successful spatial language and why and how perspective
alignment can take place, either implicitly or based on explicit marking.
"
0605017,"Reasoning and Planning with Sensing Actions, Incomplete Information, and
  Static Causal Laws using Answer Set Programming","  We extend the 0-approximation of sensing actions and incomplete information
in [Son and Baral 2000] to action theories with static causal laws and prove
its soundness with respect to the possible world semantics. We also show that
the conditional planning problem with respect to this approximation is
NP-complete. We then present an answer set programming based conditional
planner, called ASCP, that is capable of generating both conformant plans and
conditional plans in the presence of sensing actions, incomplete information
about the initial state, and static causal laws. We prove the correctness of
our implementation and argue that our planner is sound and complete with
respect to the proposed approximation. Finally, we present experimental results
comparing ASCP to other planners.
"
0605026,Strongly Almost Periodic Sequences under Finite Automata Mappings,"  The notion of almost periodicity nontrivially generalizes the notion of
periodicity. Strongly almost periodic sequences (=uniformly recurrent infinite
words) first appeared in the field of symbolic dynamics, but then turned out to
be interesting in connection with computer science. The paper studies the class
of eventually strongly almost periodic sequences (i. e., becoming strongly
almost periodic after deleting some prefix). We prove that the property of
eventual strong almost periodicity is preserved under the mappings done by
finite automata and finite transducers. The class of almost periodic sequences
includes the class of eventually strongly almost periodic sequences. We prove
this inclusion to be strict.
"
0605029,Spanners for Geometric Intersection Graphs,"  Efficient algorithms are presented for constructing spanners in geometric
intersection graphs. For a unit ball graph in R^k, a (1+\epsilon)-spanner is
obtained using efficient partitioning of the space into hypercubes and solving
bichromatic closest pair problems. The spanner construction has almost
equivalent complexity to the construction of Euclidean minimum spanning trees.
The results are extended to arbitrary ball graphs with a sub-quadratic running
time.
  For unit ball graphs, the spanners have a small separator decomposition which
can be used to obtain efficient algorithms for approximating proximity problems
like diameter and distance queries. The results on compressed quadtrees,
geometric graph separators, and diameter approximation might be of independent
interest.
"
0605031,On the Design of Agent-Based Systems using UML and Extensions,"  The Unified Software Development Process (USDP) and UML have been now
generally accepted as the standard methodology and modeling language for
developing Object-Oriented Systems. Although Agent-based Systems introduces new
issues, we consider that USDP and UML can be used in an extended manner for
modeling Agent-based Systems. The paper presents a methodology for designing
agent-based systems and the specific models expressed in an UML-based notation
corresponding to each phase of the software development process. UML was
extended using the provided mechanism: stereotypes. Therefore, this approach
can be managed with any CASE tool supporting UML. A Case Study, the development
of a specific agent-based Student Evaluation System (SAS), is presented.
"
0605032,A framework of reusable structures for mobile agent development,"  Mobile agents research is clearly aiming towards imposing agent based
development as the next generation of tools for writing software. This paper
comes with its own contribution to this global goal by introducing a novel
unifying framework meant to bring simplicity and interoperability to and among
agent platforms as we know them today. In addition to this, we also introduce a
set of agent behaviors which, although tailored for and from the area of
virtual learning environments, are none the less generic enough to be used for
rapid, simple, useful and reliable agent deployment. The paper also presents an
illustrative case study brought forward to prove the feasibility of our design.
"
0605037,"Minimally Invasive Randomization for Collecting Unbiased Preferences
  from Clickthrough Logs","  Clickthrough data is a particularly inexpensive and plentiful resource to
obtain implicit relevance feedback for improving and personalizing search
engines. However, it is well known that the probability of a user clicking on a
result is strongly biased toward documents presented higher in the result set
irrespective of relevance. We introduce a simple method to modify the
presentation of search results that provably gives relevance judgments that are
unaffected by presentation bias under reasonable assumptions. We validate this
property of the training data in interactive real world experiments. Finally,
we show that using these unbiased relevance judgments learning methods can be
guaranteed to converge to an ideal ranking given sufficient data.
"
0605039,Fast and Generalized Polynomial Time Memory Consistency Verification,"  The problem of verifying multi-threaded execution against the memory
consistency model of a processor is known to be an NP hard problem. However
polynomial time algorithms exist that detect almost all failures in such
execution. These are often used in practice for microprocessor verification. We
present a low complexity and fully parallelized algorithm to check program
execution against the processor consistency model. In addition our algorithm is
general enough to support a number of consistency models without any
degradation in performance. An implementation of this algorithm is currently
used in practice to verify processors in the post silicon stage for multiple
architectures.
"
0605044,Linear Shift-Register Synthesis for Multiple Sequences of Varying Length,"  The problem of finding the shortest linear shift-register capable of
generating t finite length sequences over some field F is considered. A similar
problem was already addressed by Feng and Tzeng. They presented an iterative
algorithm for solving this multi-sequence shift-register synthesis problem,
which can be considered as generalization of the well known Berlekamp-Massey
algorithm. The Feng-Tzeng algorithm works indeed, if all t sequences have the
same length. This paper focuses on multi-sequence shift-register synthesis for
generating sequences of varying length. It is exposed, that the Feng-Tzeng
algorithm does not always give the correct solution in this case. A modified
algorithm is proposed and formally proved, which overcomes this problem.
"
0605048,"On Learning Thresholds of Parities and Unions of Rectangles in Random
  Walk Models","  In a recent breakthrough, [Bshouty et al., 2005] obtained the first
passive-learning algorithm for DNFs under the uniform distribution. They showed
that DNFs are learnable in the Random Walk and Noise Sensitivity models. We
extend their results in several directions. We first show that thresholds of
parities, a natural class encompassing DNFs, cannot be learned efficiently in
the Noise Sensitivity model using only statistical queries. In contrast, we
show that a cyclic version of the Random Walk model allows to learn efficiently
polynomially weighted thresholds of parities. We also extend the algorithm of
Bshouty et al. to the case of Unions of Rectangles, a natural generalization of
DNFs to $\{0,...,b-1\}^n$.
"
0605054,From Proof Nets to the Free *-Autonomous Category,"  In the first part of this paper we present a theory of proof nets for full
multiplicative linear logic, including the two units. It naturally extends the
well-known theory of unit-free multiplicative proof nets. A linking is no
longer a set of axiom links but a tree in which the axiom links are subtrees.
These trees will be identified according to an equivalence relation based on a
simple form of graph rewriting. We show the standard results of
sequentialization and strong normalization of cut elimination. In the second
part of the paper we show that the identifications enforced on proofs are such
that the class of two-conclusion proof nets defines the free *-autonomous
category.
"
0605057,"SLA-Based Coordinated Superscheduling Scheme and Performance for
  Computational Grids","  The Service Level Agreement~(SLA) based grid superscheduling approach
promotes coordinated resource sharing. Superscheduling is facilitated between
administratively and topologically distributed grid sites by grid schedulers
such as Resource brokers. In this work, we present a market-based SLA
coordination mechanism. We based our SLA model on a well known \emph{contract
net protocol}.
  The key advantages of our approach are that it allows:~(i) resource owners to
have finer degree of control over the resource allocation that was previously
not possible through traditional mechanism; and (ii) superschedulers to bid for
SLA contracts in the contract net with focus on completing the job within the
user specified deadline. In this work, we use simulation to show the
effectiveness of our proposed approach.
"
0605061,"An Internet Framework to Bring Coherence between WAP and HTTP Ensuring
  Better Mobile Internet Security","  To bring coherence between Wireless Access Protocol (WAP) and Hyper Text
Transfer Protocol (HTTP), in this paper, we have proposed an enhanced Internet
framework, which incorporates a new markup language and a browser compatible
with both of the access control protocols. This Markup Language and the browser
enables co-existence of both Hyper Text Markup Language (HTML) and Wireless
Markup Language (WML) contents in a single source file, whereas the browser
incorporates the ability to hold contents compliant with both HTTP and WAP. The
proposed framework also bridges the security gap that is present in the
existing mobile Internet framework.
  Keywords: WAP, WML, HTTP, HTML, browser, parser, wireless devices.
"
0605062,QoSIP: A QoS Aware IP Routing Ptotocol for Multimedia Data,"  Conventional IP routing protocols are not suitable for multimedia
applications which have very stringent Quality-of-Service (QoS) demands and
they require a connection oriented service. For multimedia applications it is
expected that the router should be able to forward the packet according to the
demand of the packet and it is necessary to find a path that satisfies the
specific demands of a particular application. In order to address these issues,
in this paper, we have presented a QoS aware IP routing protocol where a router
stores information about the QoS parameters and routes the packet accordingly.
  Keywords: IP Routing Protocol, Quality of Service (QoS) parameter, QoSIP,
Selective Flooding.
"
0605065,On the possible Computational Power of the Human Mind,"  The aim of this paper is to address the question: Can an artificial neural
network (ANN) model be used as a possible characterization of the power of the
human mind? We will discuss what might be the relationship between such a model
and its natural counterpart. A possible characterization of the different power
capabilities of the mind is suggested in terms of the information contained (in
its computational complexity) or achievable by it. Such characterization takes
advantage of recent results based on natural neural networks (NNN) and the
computational power of arbitrary artificial neural networks (ANN). The possible
acceptance of neural networks as the model of the human mind's operation makes
the aforementioned quite relevant.
"
0605069,"Parallel vs. Sequential Belief Propagation Decoding of LDPC Codes over
  GF(q) and Markov Sources","  A sequential updating scheme (SUS) for belief propagation (BP) decoding of
LDPC codes over Galois fields, $GF(q)$, and correlated Markov sources is
proposed, and compared with the standard parallel updating scheme (PUS). A
thorough experimental study of various transmission settings indicates that the
convergence rate, in iterations, of the BP algorithm (and subsequently its
complexity) for the SUS is about one half of that for the PUS, independent of
the finite field size $q$. Moreover, this 1/2 factor appears regardless of the
correlations of the source and the channel's noise model, while the error
correction performance remains unchanged. These results may imply on the
'universality' of the one half convergence speed-up of SUS decoding.
"
0605071,On the Capacity of Interference Channels with Degraded Message sets,"  This paper is motivated by a sensor network on a correlated field where
nearby sensors share information, and can thus assist rather than interfere
with one another. A special class of two-user Gaussian interference channels
(IFCs) is considered where one of the two transmitters knows both the messages
to be conveyed to the two receivers (called the IFC with degraded message
sets). Both achievability and converse arguments are provided for this scenario
for a class of discrete memoryless channels with weak interference. For the
case of the Gaussian weak interference channel with degraded message sets,
optimality of Gaussian inputs is also shown, resulting in the capacity region
of this channel.
"
0605072,"On the Capacity of Gaussian Weak Interference Channels with Degraded
  Message sets","  This paper is motivated by a sensor network on a correlated field where
nearby sensors share information, and can thus assist rather than interfere
with one another. We consider a special class of two-user Gaussian interference
channels (IFCs) where one of the two transmitters knows both the messages to be
conveyed to the two receivers. Both achievability and converse arguments are
provided for a channel with Gaussian inputs and Gaussian noise when the
interference is weaker than the direct link (a so called weak IFC). In general,
this region serves as an outer bound on the capacity of weak IFCs with no
shared knowledge between transmitters.
"
0605075,"On the Capacity and Mutual Information of Memoryless Noncoherent
  Rayleigh-Fading Channels","  The memoryless noncoherent single-input single-output (SISO) Rayleigh-fading
channel is considered. Closed-form expressions for the mutual information
between the output and the input of this channel when the input magnitude
distribution is discrete and restricted to having two mass points are derived,
and it is subsequently shown how these expressions can be used to obtain
closed-form expressions for the capacity of this channel for signal to noise
ratio (SNR) values of up to approximately 0 dB, and a tight capacity lower
bound for SNR values between 0 dB and 10 dB. The expressions for the channel
capacity and its lower bound are given as functions of a parameter which can be
obtained via numerical root-finding algorithms.
"
0605092,The Multiple Access Channel with Feedback and Correlated Sources,"  In this paper, we investigate communication strategies for the multiple
access channel with feedback and correlated sources (MACFCS). The MACFCS models
a wireless sensor network scenario in which sensors distributed throughout an
arbitrary random field collect correlated measurements and transmit them to a
common sink. We derive achievable rate regions for the three-node MACFCS.
First, we study the strategy when source coding and channel coding are
combined, which we term full decoding at sources. Second, we look at several
strategies when source coding and channel coding are separated, which we term
full decoding at destination. From numerical computations on Gaussian channels,
we see that different strategies perform better under certain source
correlations and channel setups.
"
0605095,"Single-Symbol-Decodable Differential Space-Time Modulation Based on
  QO-STBC","  We present a novel differential space-time modulation (DSTM) scheme that is
single-symbol decodable and can provide full transmit diversity. It is the
first known singlesymbol- decodable DSTM scheme not based on Orthogonal STBC
(O-STBC), and it is constructed based on the recently proposed
Minimum-Decoding-Complexity Quasi-Orthogonal Space-Time Block Code
(MDC-QOSTBC). We derive the code design criteria and present systematic
methodology to find the solution sets. The proposed DSTM scheme can provide
higher code rate than DSTM schemes based on O-STBC. Its decoding complexity is
also considerably lower than DSTM schemes based on Sp(2) and
double-symbol-decodable QOSTBC, with negligible or slight trade-off in decoding
error probability performance.
"
0605123,Classification of Ordinal Data,"  Classification of ordinal data is one of the most important tasks of relation
learning. In this thesis a novel framework for ordered classes is proposed. The
technique reduces the problem of classifying ordered classes to the standard
two-class problem. The introduced method is then mapped into support vector
machines and neural networks. Compared with a well-known approach using
pairwise objects as training samples, the new algorithm has a reduced
complexity and training time. A second novel model, the unimodal model, is also
introduced and a parametric version is mapped into neural networks. Several
case studies are presented to assert the validity of the proposed models.
"
0605129,An Outer Bound for the Multi-Terminal Rate-Distortion Region,"  The multi-terminal rate-distortion problem has been studied extensively.
Notably, among these, Tung and Housewright have provided the best known inner
and outer bounds for the rate region under certain distortion constraints. In
this paper, we first propose an outer bound for the rate region, and show that
it is tighter than the outer bound of Tung and Housewright. Our outer bound
involves some $n$-letter Markov chain constraints, which cause computational
difficulties. We utilize a necessary condition for the Markov chain constraints
to obtain another outer bound, which is represented in terms of some
single-letter mutual information expressions evaluated over probability
distributions that satisfy some single-letter conditions.
"
0605132,Stable partitions in coalitional games,"  We propose a notion of a stable partition in a coalitional game that is
parametrized by the concept of a defection function. This function assigns to
each partition of the grand coalition a set of different coalition arrangements
for a group of defecting players. The alternatives are compared using their
social welfare. We characterize the stability of a partition for a number of
most natural defection functions and investigate whether and how so defined
stable partitions can be reached from any initial partition by means of simple
transformations. The approach is illustrated by analyzing an example in which a
set of stores seeks an optimal transportation arrangement.
"
0605134,DSR with Non-Optimal Route Suppression for MANETs,"  This paper revisits the issue of route discovery in dynamic source routing
(DSR) for mobile ad hoc networks (MANETs), and puts forward a proposal of a
lightweight non-optimal route suppression technique based on the observation of
a rarely noted but commonly occurring phenomenon in route discovery. The
technique exploits the observed phenomenon to extract query state information
that permits intermediate nodes to identify and suppress the initiation of
route replies with non-optimal routes, even if the route query is received for
the first time. A detailed evaluation of DSR with non-optimal route suppression
is found to yield significant improvements in both protocol efficiency and
performance.
"
0605145,Memory Aware High-Level Synthesis for Embedded Systems,"  We introduce a new approach to take into account the memory architecture and
the memory mapping in the High- Level Synthesis of Real-Time embedded systems.
We formalize the memory mapping as a set of constraints used in the scheduling
step. We use a memory mapping file to include those memory constraints in our
HLS tool GAUT. Our scheduling algorithm exhibits a relatively low complexity
that permits to tackle complex designs in a reasonable time. Finally, we show
how to explore, with the help of GAUT, a wide range of solutions, and to reach
a good tradeoff between time, power-consumption, and area.
"
0605146,"Synth\`{e}se Comportementale Sous Contraintes de Communication et de
  Placement M\'{e}moire pour les composants du TDSI","  The design of complex Digital Signal Processing systems implies to minimize
architectural cost and to maximize timing performances while taking into
account communication and memory accesses constraints for the integration of
dedicated hardware accelerator. Unfortunately, the traditional Matlab/ Simulink
design flows gather not very flexible hardware blocs. In this paper, we present
a methodology and a tool that permit the High-Level Synthesis of DSP
applications, under both I/O timing and memory constraints. Based on formal
models and a generic architecture, our tool GAUT helps the designer in finding
a reasonable trade-off between the circuit's performance and its architectural
complexity. The efficiency of our approach is demonstrated on the case study of
a FFT algorithm.
"
0605147,"Utilisation de la linguistique en reconnaissance de la parole : un
  \'{e}tat de l'art","  To transcribe speech, automatic speech recognition systems use statistical
methods, particularly hidden Markov model and N-gram models. Although these
techniques perform well and lead to efficient systems, they approach their
maximum possibilities. It seems thus necessary, in order to outperform current
results, to use additional information, especially bound to language. However,
introducing such knowledge must be realized taking into account specificities
of spoken language (hesitations for example) and being robust to possible
misrecognized words. This document presents a state of the art of these
researches, evaluating the impact of the insertion of linguistic information on
the quality of the transcription.
"
0606005,The KAA project: a trust policy point of view,"  In the context of ambient networks where each small device must trust its
neighborhood rather than a fixed network, we propose in this paper a
\textit{trust management framework} inspired by known social patterns and based
on the following statements: each mobile constructs itself a local level of
trust what means that it does not accept recommendation by other peers, and the
only relevant parameter, beyond some special cases discussed later, to evaluate
the level of trust is the number of common trusted mobiles. These trusted
mobiles are considered as entries in a local database called history for each
device and we use identity-based cryptography to ensure strong security:
history must be a non-tansferable object.
"
0606033,"Natural Halting Probabilities, Partial Randomness, and Zeta Functions","  We introduce the zeta number, natural halting probability and natural
complexity of a Turing machine and we relate them to Chaitin's Omega number,
halting probability, and program-size complexity. A classification of Turing
machines according to their zeta numbers is proposed: divergent, convergent and
tuatara. We prove the existence of universal convergent and tuatara machines.
Various results on (algorithmic) randomness and partial randomness are proved.
For example, we show that the zeta number of a universal tuatara machine is
c.e. and random. A new type of partial randomness, asymptotic randomness, is
introduced. Finally we show that in contrast to classical (algorithmic)
randomness--which cannot be naturally characterised in terms of plain
complexity--asymptotic randomness admits such a characterisation.
"
0606043,"Schedule generation schemes for the job-shop problem with
  sequence-dependent setup times: dominance properties and computational
  analysis","  We consider the job-shop problem with sequence-dependent setup times. We
focus on the formal definition of schedule generation schemes (SGSs) based on
the semi-active, active, and non-delay schedule categories. We study dominance
properties of the sets of schedules obtainable with each SGS. We show how the
proposed SGSs can be used within single-pass and multi-pass priority rule based
heuristics. We study several priority rules for the problem and provide a
comparative computational analysis of the different SGSs on sets of instances
taken from the literature. The proposed SGSs significantly improve previously
best-known results on a set of hard benchmark instances.
"
0606045,Trusted Computing in Mobile Action,"  Due to the convergence of various mobile access technologies like UMTS, WLAN,
and WiMax the need for a new supporting infrastructure arises. This
infrastructure should be able to support more efficient ways to authenticate
users and devices, potentially enabling novel services based on the security
provided by the infrastructure. In this paper we exhibit some usage scenarios
from the mobile domain integrating trusted computing, which show that trusted
computing offers new paradigms for implementing trust and by this enables new
technical applications and business scenarios. The scenarios show how the
traditional boundaries between technical and authentication domains become
permeable while a high security level is maintained.
"
0606049,Decentralized Erasure Codes for Distributed Networked Storage,"  We consider the problem of constructing an erasure code for storage over a
network when the data sources are distributed. Specifically, we assume that
there are n storage nodes with limited memory and k<n sources generating the
data. We want a data collector, who can appear anywhere in the network, to
query any k storage nodes and be able to retrieve the data. We introduce
Decentralized Erasure Codes, which are linear codes with a specific randomized
structure inspired by network coding on random bipartite graphs. We show that
decentralized erasure codes are optimally sparse, and lead to reduced
communication, storage and computation cost over random linear coding.
"
0606056,Fast and Simple Methods For Computing Control Points,"  The purpose of this paper is to present simple and fast methods for computing
control points for polynomial curves and polynomial surfaces given explicitly
in terms of polynomials (written as sums of monomials). We give recurrence
formulae w.r.t. arbitrary affine frames. As a corollary, it is amusing that we
can also give closed-form expressions in the case of the frame (r, s) for
curves, and the frame ((1, 0, 0), (0, 1, 0), (0, 0, 1) for surfaces. Our
methods have the same low polynomial (time and space) complexity as the other
best known algorithms, and are very easy to implement.
"
0606058,"Lower bounds and complete problems in nondeterministic linear time and
  sublinear space complexity classes","  Proving lower bounds remains the most difficult of tasks in computational
complexity theory. In this paper, we show that whereas most natural NP-complete
problems belong to NLIN (linear time on nondeterministic RAMs), some of them,
typically the planar versions of many NP-complete problems are recognized by
nondeterministic RAMs in linear time and sublinear space. The main results of
this paper are the following: as the second author did for NLIN, we give exact
logical characterizations of nondeterministic polynomial time-space complexity
classes; we derive from them a class of problems, which are complete in these
classes, and as a consequence of such a precise result and of some recent
separation theorems using diagonalization, prove time-space lower bounds for
these problems.
"
0606061,"On the Efficiency of Strategies for Subdividing Polynomial Triangular
  Surface Patches","  In this paper, we investigate the efficiency of various strategies for
subdividing polynomial triangular surface patches. We give a simple algorithm
performing a regular subdivision in four calls to the standard de Casteljau
algorithm (in its subdivision version). A naive version uses twelve calls. We
also show that any method for obtaining a regular subdivision using the
standard de Casteljau algorithm requires at least 4 calls. Thus, our method is
optimal. We give another subdivision algorithm using only three calls to the de
Casteljau algorithm. Instead of being regular, the subdivision pattern is
diamond-like. Finally, we present a ``spider-like'' subdivision scheme
producing six subtriangles in four calls to the de Casteljau algorithm.
"
0606070,Is there an Elegant Universal Theory of Prediction?,"  Solomonoff's inductive learning model is a powerful, universal and highly
elegant theory of sequence prediction. Its critical flaw is that it is
incomputable and thus cannot be used in practice. It is sometimes suggested
that it may still be useful to help guide the development of very general and
powerful theories of prediction which are computable. In this paper it is shown
that although powerful algorithms exist, they are necessarily highly complex.
This alone makes their theoretical analysis problematic, however it is further
shown that beyond a moderate level of complexity the analysis runs into the
deeper problem of Goedel incompleteness. This limits the power of mathematics
to analyse and study prediction algorithms, and indeed intelligent systems in
general.
"
0606103,Precision Arithmetic: A New Floating-Point Arithmetic,"  A new deterministic floating-point arithmetic called precision arithmetic is
developed to track precision for arithmetic calculations. It uses a novel
rounding scheme to avoid excessive rounding error propagation of conventional
floating-point arithmetic. Unlike interval arithmetic, its uncertainty tracking
is based on statistics and the central limit theorem, with a much tighter
bounding range. Its stable rounding error distribution is approximated by a
truncated normal distribution. Generic standards and systematic methods for
validating uncertainty-bearing arithmetics are discussed. The precision
arithmetic is found to be better than interval arithmetic in both
uncertainty-tracking and uncertainty-bounding for normal usages.
  The precision arithmetic is available publicly at
http://precisionarithm.sourceforge.net.
"
0606104,An information-spectrum approach to large deviation theorems,"  In this paper we show a some new look at large deviation theorems from the
viewpoint of the information-spectrum (IS) methods, which has been first
exploited in information theory, and also demonstrate a new basic formula for
the large deviation rate function in general, which is a pair of the lower and
upper IS rate functions. In particular, we are interested in establishing the
general large deviation rate functions that can be derivable as the
Fenchel-Legendre transform of the cumulant generating function. The final goal
is to show a necessary and sufficient condition for the rate function to be of
Cram\'er-G\""artner-Ellis type.
"
0606105,"Iso9000 Based Advanced Quality Approach for Continuous Improvement of
  Manufacturing Processes","  The continuous improvement in TQM is considered as the core value by which
organisation could maintain a competitive edge. Several techniques and tools
are known to support this core value but most of the time these techniques are
informal and without modelling the interdependence between the core value and
tools. Thus, technique formalisation is one of TQM challenges for increasing
efficiency of quality process implementation. In that way, the paper proposes
and experiments an advanced quality modelling approach based on meta-modelling
the ""process approach"" as advocated by the standard ISO9000:2000. This
meta-model allows formalising the interdependence between technique, tools and
core value
"
0606108,"A Product Oriented Modelling Concept: Holons for systems synchronisation
  and interoperability","  Nowadays, enterprises are confronted to growing needs for traceability,
product genealogy and product life cycle management. To meet those needs, the
enterprise and applications in the enterprise environment have to manage flows
of information that relate to flows of material and that are managed in shop
floor level. Nevertheless, throughout product lifecycle coordination needs to
be established between reality in the physical world (physical view) and the
virtual world handled by manufacturing information systems (informational
view). This paper presents the ""Holon"" modelling concept as a means for the
synchronisation of both physical view and informational views. Afterwards, we
show how the concept of holon can play a major role in ensuring
interoperability in the enterprise context.
"
0606109,Maximum gradient embeddings and monotone clustering,"  Let (X,d_X) be an n-point metric space. We show that there exists a
distribution D over non-contractive embeddings into trees f:X-->T such that for
every x in X, the expectation with respect to D of the maximum over y in X of
the ratio d_T(f(x),f(y)) / d_X(x,y) is at most C (log n)^2, where C is a
universal constant. Conversely we show that the above quadratic dependence on
log n cannot be improved in general. Such embeddings, which we call maximum
gradient embeddings, yield a framework for the design of approximation
algorithms for a wide range of clustering problems with monotone costs,
including fault-tolerant versions of k-median and facility location.
"
0606119,"Lexical Adaptation of Link Grammar to the Biomedical Sublanguage: a
  Comparative Evaluation of Three Approaches","  We study the adaptation of Link Grammar Parser to the biomedical sublanguage
with a focus on domain terms not found in a general parser lexicon. Using two
biomedical corpora, we implement and evaluate three approaches to addressing
unknown words: automatic lexicon expansion, the use of morphological clues, and
disambiguation using a part-of-speech tagger. We evaluate each approach
separately for its effect on parsing performance and consider combinations of
these approaches. In addition to a 45% increase in parsing efficiency, we find
that the best approach, incorporating information from a domain part-of-speech
tagger, offers a statistically signicant 10% relative decrease in error. The
adapted parser is available under an open-source license at
http://www.it.utu.fi/biolg.
"
0606123,Use MPLS in Lan's,"  To demonstrate the result of researches in laboratory with the focus in
exhibiting the real impact of the use of the technology MPLS in LAN. Through
these researches we will verify that the investment in this technology is
shown, of the point of view cost/benefit, very interesting, being necessary,
however, the adoption of another measured, in order to settle down a
satisfactory level in the items Quality and safety in the sending of packages
in VPN but assisting to the requirement latency of the net very well being
shown in the tests that it consumes on average one Tuesday leaves of the time
spend for the same function in routing IP.
"
0606125,Formalizing typical crosscutting concerns,"  We present a consistent system for referring crosscutting functionality,
relating crosscutting concerns to specific implementation idioms, and
formalizing their underlying relations through queries. The system is based on
generic crosscutting concerns that we organize and describe in a catalog.
  We have designed and implemented a tool support for querying source code for
instances of the proposed generic concerns and organizing them in composite
concern models. The composite concern model adds a new dimension to the
dominant decomposition of the system for describing and making explicit source
code relations specific to crosscutting concerns implementations.
  We use the proposed approach to describe crosscutting concerns in design
patterns and apply the tool to an opensource system (JHotDraw).
"
0606127,Approximately Efficient Cost-Sharing Mechanisms,"  We make three different types of contributions to cost-sharing: First, we
identify several new classes of combinatorial cost functions that admit
incentive-compatible mechanisms achieving both a constant-factor approximation
of budget-balance and a polylogarithmic approximation of the social cost
formulation of efficiency. Second, we prove a new, optimal lower bound on the
approximate efficiency of every budget-balanced Moulin mechanism for Steiner
tree or SSRoB cost functions. This lower bound exposes a latent approximation
hierarchy among different cost-sharing problems. Third, we show that weakening
the definition of incentive-compatibility to strategyproofness can permit
exponentially more efficient approximately budget-balanced mechanisms, in
particular for set cover cost-sharing problems.
"
0607004,On the Error Exponents of Some Improved Tangential-Sphere Bounds,"  The performance of maximum-likelihood (ML) decoded binary linear block codes
over the AWGN channel is addressed via the tangential-sphere bound (TSB) and
two of its recent improved versions. The paper is focused on the derivation of
the error exponents of these bounds. Although it was exemplified that some
recent improvements of the TSB tighten this bound for finite-length codes, it
is demonstrated in this paper that their error exponents coincide. For an
arbitrary ensemble of binary linear block codes, the common value of these
error exponents is explicitly expressed in terms of the asymptotic growth rate
of the average distance spectrum.
"
0607013,Database Querying under Changing Preferences,"  We present here a formal foundation for an iterative and incremental approach
to constructing and evaluating preference queries. Our main focus is on query
modification: a query transformation approach which works by revising the
preference relation in the query. We provide a detailed analysis of the cases
where the order-theoretic properties of the preference relation are preserved
by the revision. We consider a number of different revision operators: union,
prioritized and Pareto composition. We also formulate algebraic laws that
enable incremental evaluation of preference queries. Finally, we consider two
variations of the basic framework: finite restrictions of preference relations
and weak-order extensions of strict partial order preference relations.
"
0607021,Slepian-Wolf Code Design via Source-Channel Correspondence,"  We consider Slepian-Wolf code design based on LDPC (low-density parity-check)
coset codes for memoryless source-side information pairs. A density evolution
formula, equipped with a concentration theorem, is derived for Slepian- Wolf
coding based on LDPC coset codes. As a consequence, an intimate connection
between Slepian-Wolf coding and channel coding is established. Specifically we
show that, under density evolution, design of binary LDPC coset codes for
Slepian-Wolf coding of an arbitrary memoryless source-side information pair
reduces to design of binary LDPC codes for binary-input output-symmetric
channels without loss of optimality. With this connection, many classic results
in channel coding can be easily translated into the Slepian-Wolf setting.
"
0607024,"Results on Parity-Check Matrices with Optimal Stopping and/or Dead-End
  Set Enumerators","  The performance of iterative decoding techniques for linear block codes
correcting erasures depends very much on the sizes of the stopping sets
associated with the underlying Tanner graph, or, equivalently, the parity-check
matrix representing the code. In this paper, we introduce the notion of
dead-end sets to explicitly demonstrate this dependency. The choice of the
parity-check matrix entails a trade-off between performance and complexity. We
give bounds on the complexity of iterative decoders achieving optimal
performance in terms of the sizes of the underlying parity-check matrices.
Further, we fully characterize codes for which the optimal stopping set
enumerator equals the weight enumerator.
"
0607025,The evolution of navigable small-world networks,"  Small-world networks, which combine randomized and structured elements, are
seen as prevalent in nature. Several random graph models have been given for
small-world networks, with one of the most fruitful, introduced by Jon
Kleinberg, showing in which type of graphs it is possible to route, or
navigate, between vertices with very little knowledge of the graph itself.
Kleinberg's model is static, with random edges added to a fixed grid. In this
paper we introduce, analyze and test a randomized algorithm which successively
rewires a graph with every application. The resulting process gives a model for
the evolution of small-world networks with properties similar to those studied
by Kleinberg.
"
0607028,"A Quasi-Optimal Leader Election Algorithm in Radio Networks with
  Log-Logarithmic Awake Time Slots","  Radio networks (RN) are distributed systems (\textit{ad hoc networks})
consisting in $n \ge 2$ radio stations. Assuming the number $n$ unknown, two
distinct models of RN without collision detection (\textit{no-CD}) are
addressed: the model with \textit{weak no-CD} RN and the one with
\textit{strong no-CD} RN. We design and analyze two distributed leader election
protocols, each one running in each of the above two (no-CD RN) models,
respectively. Both randomized protocols are shown to elect a leader within
$\BO(\log{(n)})$ expected time, with no station being awake for more than
$\BO(\log{\log{(n)}})$ time slots (such algorithms are said to be
\textit{energy-efficient}). Therefore, a new class of efficient algorithms is
set up that matchthe $\Omega(\log{(n)})$ time lower-bound established by
Kushilevitz and Mansour.
"
0607048,"Evaluation de Techniques de Traitement des Refus\'{e}s pour l'Octroi de
  Cr\'{e}dit","  We present the problem of ""Reject Inference"" for credit acceptance. Because
of the current legal framework (Basel II), credit institutions need to
industrialize their processes for credit acceptance, including Reject
Inference. We present here a methodology to compare various techniques of
Reject Inference and show that it is necessary, in the absence of real
theoretical results, to be able to produce and compare models adapted to
available data (selection of ""best"" model conditionnaly on data). We describe
some simulations run on a small data set to illustrate the approach and some
strategies for choosing the control group, which is the only valid approach to
Reject Inference.
"
0607050,Interactive Hatching and Stippling by Example,"  We describe a system that lets a designer interactively draw patterns of
strokes in the picture plane, then guide the synthesis of similar patterns over
new picture regions. Synthesis is based on an initial user-assisted analysis
phase in which the system recognizes distinct types of strokes (hatching and
stippling) and organizes them according to perceptual grouping criteria. The
synthesized strokes are produced by combining properties (eg. length,
orientation, parallelism, proximity) of the stroke groups extracted from the
input examples. We illustrate our technique with a drawing application that
allows the control of attributes and scale-dependent reproduction of the
synthesized patterns.
"
0607054,Elementary Proof of a Theorem of Jean Ville,"  Considerable thought has been devoted to an adequate definition of the class
of infinite, random binary sequences (the sort of sequence that almost
certainly arises from flipping a fair coin indefinitely). The first
mathematical exploration of this problem was due to R. Von Mises, and based on
his concept of a ""selection function."" A decisive objection to Von Mises' idea
was formulated in a theorem offered by Jean Ville in 1939. It shows that some
sequences admitted by Von Mises as ""random"" in fact manifest a certain kind of
systematicity. Ville's proof is challenging, and an alternative approach has
appeared only in condensed form. We attempt to provide an expanded version of
the latter, alternative argument.
"
0607056,Reasoning with Intervals on Granules,"  The formalizations of periods of time inside a linear model of Time are
usually based on the notion of intervals, that may contain or may not their
endpoints. This is not enought when the periods are written in terms of coarse
granularities with respect to the event taken into account. For instance, how
to express the inter-war period in terms of a {\em years} interval? This paper
presents a new type of intervals, neither open, nor closed or open-closed and
the extension of operations on intervals of this new type, in order to reduce
the gap between the discourse related to temporal relationship and its
translation into a discretized model of Time.
"
0607059,Creation and Growth of Components in a Random Hypergraph Process,"  Denote by an $\ell$-component a connected $b$-uniform hypergraph with $k$
edges and $k(b-1) - \ell$ vertices. We prove that the expected number of
creations of $\ell$-component during a random hypergraph process tends to 1 as
$\ell$ and $b$ tend to $\infty$ with the total number of vertices $n$ such that
$\ell = o(\sqrt[3]{\frac{n}{b}})$. Under the same conditions, we also show that
the expected number of vertices that ever belong to an $\ell$-component is
approximately $12^{1/3} (b-1)^{1/3} \ell^{1/3} n^{2/3}$. As an immediate
consequence, it follows that with high probability the largest $\ell$-component
during the process is of size $O((b-1)^{1/3} \ell^{1/3} n^{2/3})$. Our results
give insight about the size of giant components inside the phase transition of
random hypergraphs.
"
0607069,"The B-Exponential Map: A Generalization of the Logistic Map, and Its
  Applications In Generating Pseudo-random Numbers","  A 1-dimensional generalization of the well known Logistic Map is proposed.
The proposed family of maps is referred to as the B-Exponential Map. The
dynamics of this map are analyzed and found to have interesting properties. In
particular, the B-Exponential Map exhibits robust chaos for all real values of
the parameter B >= e^(-4). We then propose a pseudo-random number generator
based on the B-Exponential Map by chaotically hopping between different
trajectories for different values of B. We call this BEACH (B-Exponential
All-Chaotic Map Hopping) pseudo-random number generator. BEACH successfully
passes stringent statistical randomness tests such as ENT, NIST and Diehard. An
implementation of BEACH is also outlined.
"
0607080,New Model of Internet Topology Using k-shell Decomposition,"  We introduce and use k-shell decomposition to investigate the topology of the
Internet at the AS level. Our analysis separates the Internet into three
sub-components: (a) a nucleus which is a small (~100 nodes) very well connected
globally distributed subgraph; (b) a fractal sub-component that is able to
connect the bulk of the Internet without congesting the nucleus, with self
similar properties and critical exponents; and (c) dendrite-like structures,
usually isolated nodes that are connected to the rest of the network through
the nucleus only. This unique decomposition is robust, and provides insight
into the underlying structure of the Internet and its functional consequences.
Our approach is general and useful also when studying other complex networks.
"
0607086,Representing Knowledge about Norms,"  Norms are essential to extend inference: inferences based on norms are far
richer than those based on logical implications. In the recent decades, much
effort has been devoted to reason on a domain, once its norms are represented.
How to extract and express those norms has received far less attention.
Extraction is difficult: as the readers are supposed to know them, the norms of
a domain are seldom made explicit. For one thing, extracting norms requires a
language to represent them, and this is the topic of this paper. We apply this
language to represent norms in the domain of driving, and show that it is
adequate to reason on the causes of accidents, as described by car-crash
reports.
"
0607089,"Superregular Matrices and the Construction of Convolutional Codes having
  a Maximum Distance Profile","  Superregular matrices are a class of lower triangular Toeplitz matrices that
arise in the context of constructing convolutional codes having a maximum
distance profile. These matrices are characterized by the property that no
submatrix has a zero determinant unless it is trivially zero due to the lower
triangular structure. In this paper, we discuss how superregular matrices may
be used to construct codes having a maximum distance profile. We also introduce
group actions that preserve the superregularity property and present an upper
bound on the minimum size a finite field must have in order that a superregular
matrix of a given size can exist over that field.
"
0607097,"Dynamic Packet Aggregation to Solve Performance Anomaly in 802.11
  Wireless Networks","  In the widely used 802.11 standard, the so called performance anomaly is a
well known issue. Several works have tried to solve this problem by introducing
mechanisms such as packet fragmentation, backoff adaptation, or packet
aggregation during a fixed time interval. In this paper, we propose a novel
approach solving the performance anomaly problem by packet aggregation using a
dynamic time interval, which depends on the busy time of the wireless medium.
Our solution differs from other proposition in the literature because of this
dynamic time interval, which allows increasing fairness, reactivity, and in
some cases efficiency. In this article, we emphasize the performance evaluation
of our proposal.
"
0607110,"A Theory of Probabilistic Boosting, Decision Trees and Matryoshki","  We present a theory of boosting probabilistic classifiers. We place ourselves
in the situation of a user who only provides a stopping parameter and a
probabilistic weak learner/classifier and compare three types of boosting
algorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of
trees, which we call matryoshka. ""Nested tree,"" ""embedded tree"" and ""recursive
tree"" are also appropriate names for this algorithm, which is one of our
contributions. Our other contribution is the theoretical analysis of the
algorithms, in which we give training error bounds. This analysis suggests that
the matryoshka leverages probabilistic weak classifiers more efficiently than
simple decision trees.
"
0607114,Revising Type-2 Computation and Degrees of Discontinuity,"  By the sometimes so-called MAIN THEOREM of Recursive Analysis, every
computable real function is necessarily continuous. Weihrauch and Zheng
(TCS'2000), Brattka (MLQ'2005), and Ziegler (ToCS'2006) have considered
different relaxed notions of computability to cover also discontinuous
functions. The present work compares and unifies these approaches. This is
based on the concept of the JUMP of a representation: both a TTE-counterpart to
the well known recursion-theoretic jump on Kleene's Arithmetical Hierarchy of
hypercomputation: and a formalization of revising computation in the sense of
Shoenfield.
  We also consider Markov and Banach/Mazur oracle-computation of discontinuous
fu nctions and characterize the computational power of Type-2 nondeterminism to
coincide with the first level of the Analytical Hierarchy.
"
0607119,"Web-Based Enterprise Information Systems Development: The Integrated
  Methodology","  The paper considers software development issues for large-scale enterprise
information systems (IS) with databases (DB) in global heterogeneous
distributed computational environment. Due to high IT development rates, the
present-day society has accumulated and rapidly increases an extremely huge
data burden. Manipulating with such huge data arrays becomes an essential
problem, particularly due to their global distribution, heterogeneous and
weak-structured character. The conceptual approach to integrated Internet-based
IS design, development and implementation is presented, including formal
models, software development methodology and original software development
tools for visual problem-oriented development and content management. IS
implementation results proved shortening terms and reducing costs of
implementation compared to commercial software available.
"
0607147,Fusion of qualitative beliefs using DSmT,"  This paper introduces the notion of qualitative belief assignment to model
beliefs of human experts expressed in natural language (with linguistic
labels). We show how qualitative beliefs can be efficiently combined using an
extension of Dezert-Smarandache Theory (DSmT) of plausible and paradoxical
quantitative reasoning to qualitative reasoning. We propose a new arithmetic on
linguistic labels which allows a direct extension of classical DSm fusion rule
or DSm Hybrid rules. An approximate qualitative PCR5 rule is also proposed
jointly with a Qualitative Average Operator. We also show how crisp or interval
mappings can be used to deal indirectly with linguistic labels. A very simple
example is provided to illustrate our qualitative fusion rules.
"
0608003,On a solution to display non-filled-in quaternionic Julia sets,"  During early 1980s, the so-called `escape time' method, developed to display
the Julia sets for complex dynamical systems, was exported to quaternions in
order to draw analogous pictures in this wider numerical field. Despite of the
fine results in the complex plane, where all topological configurations of
Julia sets have been successfully displayed, the `escape time' method fails to
render properly the non-filled-in variety of quaternionic Julia sets. So their
digital visualisation remained an open problem for several years. Both the
solution for extending this old method to non-filled-in quaternionic Julia sets
and its implementation into a program are explained here.
"
0608004,Separating the articles of authors with the same name,"  I describe a method to separate the articles of different authors with the
same name. It is based on a distance between any two publications, defined in
terms of the probability that they would have as many coincidences if they were
drawn at random from all published documents. Articles with a given author name
are then clustered according to their distance, so that all articles in a
cluster belong very likely to the same author. The method has proven very
useful in generating groups of papers that are then selected manually. This
simplifies considerably citation analysis when the author publication lists are
not available.
"
0608005,A field-theory motivated approach to symbolic computer algebra,"  Field theory is an area in physics with a deceptively compact notation.
Although general purpose computer algebra systems, built around generic
list-based data structures, can be used to represent and manipulate
field-theory expressions, this often leads to cumbersome input formats,
unexpected side-effects, or the need for a lot of special-purpose code. This
makes a direct translation of problems from paper to computer and back
needlessly time-consuming and error-prone. A prototype computer algebra system
is presented which features TeX-like input, graph data structures, lists with
Young-tableaux symmetries and a multiple-inheritance property system. The
usefulness of this approach is illustrated with a number of explicit
field-theory problems.
"
0608015,"Towards ""Propagation = Logic + Control""","  Constraint propagation algorithms implement logical inference. For
efficiency, it is essential to control whether and in what order basic
inference steps are taken. We provide a high-level framework that clearly
differentiates between information needed for controlling propagation versus
that needed for the logical semantics of complex constraints composed from
primitive ones. We argue for the appropriateness of our controlled propagation
framework by showing that it captures the underlying principles of manually
designed propagation algorithms, such as literal watching for unit clause
propagation and the lexicographic ordering constraint. We provide an
implementation and benchmark results that demonstrate the practicality and
efficiency of our framework.
"
0608021,"The Shannon capacity of a graph and the independence numbers of its
  powers","  The independence numbers of powers of graphs have been long studied, under
several definitions of graph products, and in particular, under the strong
graph product. We show that the series of independence numbers in strong powers
of a fixed graph can exhibit a complex structure, implying that the Shannon
Capacity of a graph cannot be approximated (up to a sub-polynomial factor of
the number of vertices) by any arbitrarily large, yet fixed, prefix of the
series. This is true even if this prefix shows a significant increase of the
independence number at a given power, after which it stabilizes for a while.
"
0608022,Expressing Security Properties Using Selective Interleaving Functions,"  McLean's notion of Selective Interleaving Functions (SIFs) is perhaps the
best-known attempt to construct a framework for expressing various security
properties. We examine the expressive power of SIFs carefully. We show that
SIFs cannot capture nondeducibility on strategies (NOS). We also prove that the
set of security properties expressed with SIFs is not closed under conjunction,
from which it follows that separability is strictly stronger than double
generalized noninterference. However, we show that if we generalize the notion
of SIF in a natural way, then NOS is expressible, and the set of security
properties expressible by generalized SIFs is closed under conjunction.
"
0608033,A Study on Learnability for Rigid Lambek Grammars,"  We present basic notions of Gold's ""learnability in the limit"" paradigm,
first presented in 1967, a formalization of the cognitive process by which a
native speaker gets to grasp the underlying grammar of his/her own native
language by being exposed to well formed sentences generated by that grammar.
Then we present Lambek grammars, a formalism issued from categorial grammars
which, although not as expressive as needed for a full formalization of natural
languages, is particularly suited to easily implement a natural interface
between syntax and semantics. In the last part of this work, we present a
learnability result for Rigid Lambek grammars from structured examples.
"
0608049,"Solving non-uniqueness in agglomerative hierarchical clustering using
  multidendrograms","  In agglomerative hierarchical clustering, pair-group methods suffer from a
problem of non-uniqueness when two or more distances between different clusters
coincide during the amalgamation process. The traditional approach for solving
this drawback has been to take any arbitrary criterion in order to break ties
between distances, which results in different hierarchical classifications
depending on the criterion followed. In this article we propose a
variable-group algorithm that consists in grouping more than two clusters at
the same time when ties occur. We give a tree representation for the results of
the algorithm, which we call a multidendrogram, as well as a generalization of
the Lance and Williams' formula which enables the implementation of the
algorithm in a recursive way.
"
0608065,"Combinatorial and Arithmetical Properties of Infinite Words Associated
  with Non-simple Quadratic Parry Numbers","  We study arithmetical and combinatorial properties of $\beta$-integers for
$\beta$ being the root of the equation $x^2=mx-n, m,n \in \mathbb N, m \geq
n+2\geq 3$. We determine with the accuracy of $\pm 1$ the maximal number of
$\beta$-fractional positions, which may arise as a result of addition of two
$\beta$-integers. For the infinite word $u_\beta$ coding distances between
consecutive $\beta$-integers, we determine precisely also the balance. The word
$u_\beta$ is the fixed point of the morphism $A \to A^{m-1}B$ and $B\to
A^{m-n-1}B$. In the case $n=1$ the corresponding infinite word $u_\beta$ is
sturmian and therefore 1-balanced. On the simplest non-sturmian example with
$n\geq 2$, we illustrate how closely the balance and arithmetical properties of
$\beta$-integers are related.
"
0608072,"Applications of Random Parameter Matrices Kalman Filtering in Uncertain
  Observation and Multi-Model Systems","  This paper considers the Linear Minimum Variance recursive state estimation
for the linear discrete time dynamic system with random state transition and
measurement matrices, i.e., random parameter matrices Kalman filtering. It is
shown that such system can be converted to a linear dynamic system with
deterministic parameter matrices but state-dependent process and measurement
noises. It is proved that under mild conditions, the recursive state estimation
of this system is still of the form of a modified Kalman filtering. More
importantly, this result can be applied to Kalman filtering with intermittent
and partial observations as well as randomly variant dynamic systems.
"
0608083,"Where's the ""Party"" in ""Multi-Party""? Analyzing the Structure of
  Small-Group Sociable Talk","  Spontaneous multi-party interaction - conversation among groups of three or
more participants - is part of daily life. While automated modeling of such
interactions has received increased attention in ubiquitous computing research,
there is little applied research on the organization of this highly dynamic and
spontaneous sociable interaction within small groups. We report here on an
applied conversation analytic study of small-group sociable talk, emphasizing
structural and temporal aspects that can inform computational models. In
particular, we examine the mechanics of multiple simultaneous conversational
floors - how participants initiate a new floor amidst an on-going floor, and
how they subsequently show their affiliation with one floor over another. We
also discuss the implications of these findings for the design of ""smart""
multi-party applications.
"
0608086,Analog Codes on Graphs,"  We consider the problem of transmission of a sequence of real data produced
by a Nyquist sampled band-limited analog source over a band-limited analog
channel, which introduces an additive white Gaussian noise. An analog coding
scheme is described, which can achieve a mean-squared error distortion
proportional to $(1+SNR)^{-B}$ for a bandwidth expansion factor of $B/R$, where
$0 < R < 1$ is the rate of individual component binary codes used in the
construction and $B \geq 1$ is an integer. Thus, over a wide range of SNR
values, the proposed code performs much better than any single previously known
analog coding system.
"
0608090,A Condition Number Analysis of a Line-Surface Intersection Algorithm,"  We propose an algorithm based on Newton's method and subdivision for finding
all zeros of a polynomial system in a bounded region of the plane. This
algorithm can be used to find the intersections between a line and a surface,
which has applications in graphics and computer-aided geometric design. The
algorithm can operate on polynomials represented in any basis that satisfies a
few conditions. The power basis, the Bernstein basis, and the first-kind
Chebyshev basis are among those compatible with the algorithm. The main novelty
of our algorithm is an analysis showing that its running is bounded only in
terms of the condition number of the polynomial's zeros and a constant
depending on the polynomial basis.
"
0608093,"Connection between continuous and digital n-manifolds and the Poincare
  conjecture","  We introduce LCL covers of closed n-dimensional manifolds by n-dimensional
disks and study their properties. We show that any LCL cover of an
n-dimensional sphere can be converted to the minimal LCL cover, which consists
of 2n+2 disks. We prove that an LCL collection of n-disks is a cover of a
continuous n-sphere if and only if the intersection graph of this collection is
a digital n-sphere. Using a link between LCL covers of closed continuous
n-manifolds and digital n-manifolds, we find conditions where a continuous
closed three-dimensional manifold is the three-dimensional sphere. We discuss a
connection between the classification problems for closed continuous
three-dimensional manifolds and digital three-manifolds.
"
0608097,A study of fuzzy and many-valued logics in cellular automata,"  In this paper we provide an analytical study of the theory of multi-valued
and fuzzy cellular automata where the fuzziness appears as the result of the
application of an underlying multi-valued or continuous logic as opposed to
standard logic as used conventionally. Using the disjunctive normal form of any
one of the 255 ECA's so defined, we modify the underlying logic structure and
redefine the ECA within the framework of this new logic. The idea here is to
show that the evolution of space-time diagrams of ECA's under even a
probabilistic logic can exhibit non-chaotic behavior. This is looked at
specifically for Probabilistic Rule 110, in contrast with Boolean Rule 110
which is known to be capable of universal computation.
"
0608108,Spherical Indexing for Neighborhood Queries,"  This is an algorithm for finding neighbors when the objects can freely move
and have no predefined position. The query consists in finding neighbors for a
center location and a given radius. Space is discretized in cubic cells. This
algorithm introduces a direct spherical indexing that gives the list of all
cells making up the query sphere, for any radius and any center location. It
can additionally take in account both cyclic and non-cyclic regions of
interest. Finding only the K nearest neighbors naturally benefits from the
spherical indexing by minimally running through the sphere from center to edge,
and reducing the maximum distance when K neighbors have been found.
"
0608116,"Transparent Migration of Multi-Threaded Applications on a Java Based
  Grid","  Grid computing has enabled pooling a very large number of heterogeneous
resource administered by different security domains. Applications are
dynamically deployed on the resources available at the time. Dynamic nature of
the resources and applications requirements makes needs the grid middleware to
support the ability of migrating a running application to a different resource.
Especially, Grid applications are typically long running and thus stoping them
and starting them from scratch is not a feasible option. This paper presents an
overview of migration support in a java based grid middleware called DGET.
Migration support in DGET includes multi-threaded migration and asynchronous
migration as well.
"
0609007,A Massive Local Rules Search Approach to the Classification Problem,"  An approach to the classification problem of machine learning, based on
building local classification rules, is developed. The local rules are
considered as projections of the global classification rules to the event we
want to classify. A massive global optimization algorithm is used for
optimization of quality criterion. The algorithm, which has polynomial
complexity in typical case, is used to find all high--quality local rules. The
other distinctive feature of the algorithm is the integration of attributes
levels selection (for ordered attributes) with rules searching and original
conflicting rules resolution strategy. The algorithm is practical; it was
tested on a number of data sets from UCI repository, and a comparison with the
other predicting techniques is presented.
"
0609009,"Finding heaviest H-subgraphs in real weighted graphs, with applications","  For a graph G with real weights assigned to the vertices (edges), the MAX
H-SUBGRAPH problem is to find an H-subgraph of G with maximum total weight, if
one exists. The all-pairs MAX H-SUBGRAPH problem is to find for every pair of
vertices u,v, a maximum H-subgraph containing both u and v, if one exists. Our
main results are new strongly polynomial algorithms for the all-pairs MAX
H-SUBGRAPH problem for vertex weighted graphs. We also give improved algorithms
for the MAX-H SUBGRAPH problem for edge weighted graphs, and various related
problems, including computing the first k most significant bits of the distance
product of two matrices. Some of our algorithms are based, in part, on fast
matrix multiplication.
"
0609015,Residual Finite Tree Automata,"  Tree automata based algorithms are essential in many fields in computer
science such as verification, specification, program analysis. They become also
essential for databases with the development of standards such as XML. In this
paper, we define new classes of non deterministic tree automata, namely
residual finite tree automata (RFTA). In the bottom-up case, we obtain a new
characterization of regular tree languages. In the top-down case, we obtain a
subclass of regular tree languages which contains the class of languages
recognized by deterministic top-down tree automata. RFTA also come with the
property of existence of canonical non deterministic tree automata.
"
0609019,Improving Term Extraction with Terminological Resources,"  Studies of different term extractors on a corpus of the biomedical domain
revealed decreasing performances when applied to highly technical texts. The
difficulty or impossibility of customising them to new domains is an additional
limitation. In this paper, we propose to use external terminologies to
influence generic linguistic data in order to augment the quality of the
extraction. The tool we implemented exploits testified terms at different steps
of the process: chunking, parsing and extraction of term candidates.
Experiments reported here show that, using this method, more term candidates
can be acquired with a higher level of reliability. We further describe the
extraction process involving endogenous disambiguation implemented in the term
extractor YaTeA.
"
0609028,"VLSI Implementation of RSA Encryption System Using Ancient Indian Vedic
  Mathematics","  This paper proposes the hardware implementation of RSA encryption/decryption
algorithm using the algorithms of Ancient Indian Vedic Mathematics that have
been modified to improve performance. The recently proposed hierarchical
overlay multiplier architecture is used in the RSA circuitry for multiplication
operation. The most significant aspect of the paper is the development of a
division architecture based on Straight Division algorithm of Ancient Indian
Vedic Mathematics and embedding it in RSA encryption/decryption circuitry for
improved efficiency. The coding is done in Verilog HDL and the FPGA synthesis
is done using Xilinx Spartan library. The results show that RSA circuitry
implemented using Vedic division and multiplication is efficient in terms of
area/speed compared to its implementation using conventional multiplication and
division architectures
"
0609033,Choosing Colors for Geometric Graphs via Color Space Embeddings,"  Graph drawing research traditionally focuses on producing geometric
embeddings of graphs satisfying various aesthetic constraints. After the
geometric embedding is specified, there is an additional step that is often
overlooked or ignored: assigning display colors to the graph's vertices. We
study the additional aesthetic criterion of assigning distinct colors to
vertices of a geometric graph so that the colors assigned to adjacent vertices
are as different from one another as possible. We formulate this as a problem
involving perceptual metrics in color space and we develop algorithms for
solving this problem by embedding the graph in color space. We also present an
application of this work to a distributed load-balancing visualization problem.
"
0609034,"Social Decision Making with Multi-Relational Networks and Grammar-Based
  Particle Swarms","  Social decision support systems are able to aggregate the local perspectives
of a diverse group of individuals into a global social decision. This paper
presents a multi-relational network ontology and grammar-based particle swarm
algorithm capable of aggregating the decisions of millions of individuals. This
framework supports a diverse problem space and a broad range of vote
aggregation algorithms. These algorithms account for individual expertise and
representation across different domains of the group problem space. Individuals
are able to pose and categorize problems, generate potential solutions, choose
trusted representatives, and vote for particular solutions. Ultimately, via a
social decision making algorithm, the system aggregates all the individual
votes into a single collective decision.
"
0609037,(HO)RPO Revisited,"  The notion of computability closure has been introduced for proving the
termination of the combination of higher-order rewriting and beta-reduction. It
is also used for strengthening the higher-order recursive path ordering. In the
present paper, we study in more details the relations between the computability
closure and the (higher-order) recursive path ordering. We show that the
first-order recursive path ordering is equal to an ordering naturally defined
from the computability closure. In the higher-order case, we get an ordering
containing the higher-order recursive path ordering whose well-foundedness
relies on the correctness of the computability closure. This provides a simple
way to extend the higher-order recursive path ordering to richer type systems.
"
0609045,Metric entropy in competitive on-line prediction,"  Competitive on-line prediction (also known as universal prediction of
individual sequences) is a strand of learning theory avoiding making any
stochastic assumptions about the way the observations are generated. The
predictor's goal is to compete with a benchmark class of prediction rules,
which is often a proper Banach function space. Metric entropy provides a
unifying framework for competitive on-line prediction: the numerous known upper
bounds on the metric entropy of various compact sets in function spaces readily
imply bounds on the performance of on-line prediction strategies. This paper
discusses strengths and limitations of the direct approach to competitive
on-line prediction via metric entropy, including comparisons to other
approaches.
"
0609050,"Exact Spectral Analysis of Single-h and Multi-h CPM Signals through PAM
  decomposition and Matrix Series Evaluation","  In this paper we address the problem of closed-form spectral evaluation of
CPM. We show that the multi-h CPM signal can be conveniently generated by a PTI
SM. The output is governed by a Markov chain with the unusual peculiarity of
being cyclostationary and reducible; this holds also in the single-h context.
Judicious reinterpretation of the result leads to a formalization through a
stationary and irreducible Markov chain, whose spectral evaluation is known in
closed-form from the literature. Two are the major outcomes of this paper.
First, unlike the literature, we obtain a PSD in true closed-form. Second, we
give novel insights into the CPM format.
"
0609051,Multilingual person name recognition and transliteration,"  We present an exploratory tool that extracts person names from multilingual
news collections, matches name variants referring to the same person, and
infers relationships between people based on the co-occurrence of their names
in related news. A novel feature is the matching of name variants across
languages and writing systems, including names written with the Greek, Cyrillic
and Arabic writing system. Due to our highly multilingual setting, we use an
internal standard representation for name representation and matching, instead
of adopting the traditional bilingual approach to transliteration. This work is
part of the news analysis system NewsExplorer that clusters an average of
25,000 news articles per day to detect related news within the same and across
different languages.
"
0609053,"Navigating multilingual news collections using automatically extracted
  information","  We are presenting a text analysis tool set that allows analysts in various
fields to sieve through large collections of multilingual news items quickly
and to find information that is of relevance to them. For a given document
collection, the tool set automatically clusters the texts into groups of
similar articles, extracts names of places, people and organisations, lists the
user-defined specialist terms found, links clusters and entities, and generates
hyperlinks. Through its daily news analysis operating on thousands of articles
per day, the tool also learns relationships between people and other entities.
The fully functional prototype system allows users to explore and navigate
multilingual document collections across languages and time.
"
0609063,"Extending an Information Extraction tool set to Central and Eastern
  European languages","  In a highly multilingual and multicultural environment such as in the
European Commission with soon over twenty official languages, there is an
urgent need for text analysis tools that use minimal linguistic knowledge so
that they can be adapted to many languages without much human effort. We are
presenting two such Information Extraction tools that have already been adapted
to various Western and Eastern European languages: one for the recognition of
date expressions in text, and one for the detection of geographical place names
and the visualisation of the results in geographical maps. An evaluation of the
performance has produced very satisfying results.
"
0609070,"Exploring Computer Science Concepts with a Ready-made Computer Game
  Framework","  Leveraging the prevailing interest in computer games among college students,
both for entertainment and as a possible career path, is a major reason for the
increasing prevalence of computer game design courses in computer science
curricula. Because implementing a computer game requires strong programming
skills, game design courses are most often restricted to more advanced computer
science students. This paper reports on a ready-made game design and
experimentation framework, implemented in Java, that makes game programming
more widely accessible. This framework, called Labyrinth, enables students at
all programming skill levels to participate in computer game design. We
describe the architecture of the framework, and discuss programming projects
suitable for a wide variety of computer science courses, from capstone to
non-major.
"
0609084,Non-photorealistic image rendering with a labyrinthine tiling,"  The paper describes a new image processing for a non-photorealistic
rendering. The algorithm is based on a random generation of gray tones and
competing statistical requirements. The gray tone value of each pixel in the
starting image is replaced selecting among randomly generated tone values,
according to the statistics of nearest-neighbor and next-nearest-neighbor
pixels. Two competing conditions for replacing the tone values - one position
on the local mean value the other on the local variance - produce a peculiar
pattern on the image. This pattern has a labyrinthine tiling aspect. For
certain subjects, the pattern enhances the look of the image.
"
0609087,"A comparative analysis of the geometrical surface texture of a real and
  virtual model of a tooth flank of a cylindrical gear","  The paper presents the methodology of modelling tooth flanks of cylindrical
gears in the Cad environment. The modelling consists in a computer simulation
of gear generation. A model of tooth flanks is an envelope curve of a family of
envelopes that originate from the rolling motion of a solid tool model in
relation to a solid model of the cylindrical gear. The surface stereometry and
topography of the tooth flanks, hobbed and chiselled by Fellows method, are
compared to their numerical models. Metrological measurements of the real gears
were carried out using a coordinated measuring machine and a two - and a
three-dimensional profilometer. A computer simulation of the gear generation
was performed in the Mechanical Desktop environment.
"
0609088,Deriving the Normalized Min-Sum Algorithm from Cooperative Optimization,"  The normalized min-sum algorithm can achieve near-optimal performance at
decoding LDPC codes. However, it is a critical question to understand the
mathematical principle underlying the algorithm. Traditionally, people thought
that the normalized min-sum algorithm is a good approximation to the
sum-product algorithm, the best known algorithm for decoding LDPC codes and
Turbo codes. This paper offers an alternative approach to understand the
normalized min-sum algorithm. The algorithm is derived directly from
cooperative optimization, a newly discovered general method for
global/combinatorial optimization. This approach provides us another
theoretical basis for the algorithm and offers new insights on its power and
limitation. It also gives us a general framework for designing new decoding
algorithms.
"
0609092,Analysis of Equality Relationships for Imperative Programs,"  In this article, we discuss a flow--sensitive analysis of equality
relationships for imperative programs. We describe its semantic domains,
general purpose operations over abstract computational states (term evaluation
and identification, semantic completion, widening operator, etc.) and semantic
transformers corresponding to program constructs. We summarize our experiences
from the last few years concerning this analysis and give attention to
applications of analysis of automatically generated code. Among other
illustrating examples, we consider a program for which the analysis diverges
without a widening operator and results of analyzing residual programs produced
by some automatic partial evaluator. An example of analysis of a program
generated by this evaluator is given.
"
0609095,"Free Choice Petri Nets without frozen tokens and Bipolar Synchronization
  Systems","  Bipolar synchronization systems (BP-systems) constitute a class of coloured
Petri nets, well suited for modeling the control flow of discrete, dynamical
systems. Every BP-system has an underlying ordinary Petri net, which is a
T-system. Moreover, it has a second ordinary net attached, which is a
free-choice system. We prove that a BP-system is live and safe if the T-system
and the free-choice system are live and safe and if the free-choice system has
no frozen tokens. This result is the converse of a theorem of Genrich and
Thiagarajan and proves an elder conjecture. The proof compares the different
Petri nets by Petri net morphisms and makes use of the classical theory of
free-choice systems
"
0609102,Using groups for investigating rewrite systems,"  We describe several technical tools that prove to be efficient for
investigating the rewrite systems associated with a family of algebraic laws,
and might be useful for more general rewrite systems. These tools consist in
introducing a monoid of partial operators, listing the monoid relations
expressing the possible local confluence of the rewrite system, then
introducing the group presented by these relations, and finally replacing the
initial rewrite system with a internal process entirely sitting in the latter
group. When the approach can be completed, one typically obtains a practical
method for constructing algebras satisfying prescribed laws and for solving the
associated word problem.
"
0609111,"A State-Based Regression Formulation for Domains with Sensing
  Actions<br> and Incomplete Information","  We present a state-based regression function for planning domains where an
agent does not have complete information and may have sensing actions. We
consider binary domains and employ a three-valued characterization of domains
with sensing actions to define the regression function. We prove the soundness
and completeness of our regression formulation with respect to the definition
of progression. More specifically, we show that (i) a plan obtained through
regression for a planning problem is indeed a progression solution of that
planning problem, and that (ii) for each plan found through progression, using
regression one obtains that plan or an equivalent one.
"
0609121,"Approximating Rate-Distortion Graphs of Individual Data: Experiments in
  Lossy Compression and Denoising","  Classical rate-distortion theory requires knowledge of an elusive source
distribution. Instead, we analyze rate-distortion properties of individual
objects using the recently developed algorithmic rate-distortion theory. The
latter is based on the noncomputable notion of Kolmogorov complexity. To apply
the theory we approximate the Kolmogorov complexity by standard data
compression techniques, and perform a number of experiments with lossy
compression and denoising of objects from different domains. We also introduce
a natural generalization to lossy compression with side information. To
maintain full generality we need to address a difficult searching problem.
While our solutions are therefore not time efficient, we do observe good
denoising and compression performance.
"
0609137,Ontologies and Information Extraction,"  This report argues that, even in the simplest cases, IE is an ontology-driven
process. It is not a mere text filtering method based on simple pattern
matching and keywords, because the extracted pieces of texts are interpreted
with respect to a predefined partial domain model. This report shows that
depending on the nature and the depth of the interpretation to be done for
extracting the information, more or less knowledge must be involved. This
report is mainly illustrated in biology, a domain in which there are critical
needs for content-based exploration of the scientific literature and which
becomes a major application domain for IE.
"
0609138,MDL Denoising Revisited,"  We refine and extend an earlier MDL denoising criterion for wavelet-based
denoising. We start by showing that the denoising problem can be reformulated
as a clustering problem, where the goal is to obtain separate clusters for
informative and non-informative wavelet coefficients, respectively. This
suggests two refinements, adding a code-length for the model index, and
extending the model in order to account for subband-dependent coefficient
distributions. A third refinement is derivation of soft thresholding inspired
by predictive universal coding with weighted mixtures. We propose a practical
method incorporating all three refinements, which is shown to achieve good
performance and robustness in denoising both artificial and natural signals.
"
0609159,Duality for Several Families of Evaluation Codes,"  We consider generalizations of Reed-Muller codes, toric codes, and codes from
certain plane curves, such as those defined by norm and trace functions on
finite fields. In each case we are interested in codes defined by evaluating
arbitrary subsets of monomials, and in identifying when the dual codes are also
obtained by evaluating monomials. We then move to the context of order domain
theory, in which the subsets of monomials can be chosen to optimize decoding
performance using the Berlekamp-Massey-Sakata algorithm with majority voting.
We show that for the codes under consideration these subsets are well-behaved
and the dual codes are also defined by monomials.
"
0609161,"The Order Bound on the Minimum Distance of the One-Point Codes
  Associated to a Garcia-Stichtenoth Tower of Function Fields","  Garcia and Stichtenoth discovered two towers of function fields that meet the
Drinfeld-Vl\u{a}du\c{t} bound on the ratio of the number of points to the
genus. For one of these towers, Garcia, Pellikaan and Torres derived a
recursive description of the Weierstrass semigroups associated to a tower of
points on the associated curves. In this article, a non-recursive description
of the semigroups is given and from this the enumeration of each of the
semigroups is derived as well as its inverse. This enables us to find an
explicit formula for the order (Feng-Rao) bound on the minimum distance of the
associated one-point codes.
"
0609166,Private Approximate Heavy Hitters,"  We consider the problem of private computation of approximate Heavy Hitters.
Alice and Bob each hold a vector and, in the vector sum, they want to find the
B largest values along with their indices. While the exact problem requires
linear communication, protocols in the literature solve this problem
approximately using polynomial computation time, polylogarithmic communication,
and constantly many rounds. We show how to solve the problem privately with
comparable cost, in the sense that nothing is learned by Alice and Bob beyond
what is implied by their input, the ideal top-B output, and goodness of
approximation (equivalently, the Euclidean norm of the vector sum). We give
lower bounds showing that the Euclidean norm must leak by any efficient
algorithm.
"
0610007,Full Text Searching in the Astrophysics Data System,"  The Smithsonian/NASA Astrophysics Data System (ADS) provides a search system
for the astronomy and physics scholarly literature. All major and many smaller
astronomy journals that were published on paper have been scanned back to
volume 1 and are available through the ADS free of charge. All scanned pages
have been converted to text and can be searched through the ADS Full Text
Search System. In addition, searches can be fanned out to several external
search systems to include the literature published in electronic form. Results
from the different search systems are combined into one results list.
  The ADS Full Text Search System is available at:
http://adsabs.harvard.edu/fulltext_service.html
"
0610011,Creation and use of Citations in the ADS,"  With over 20 million records, the ADS citation database is regularly used by
researchers and librarians to measure the scientific impact of individuals,
groups, and institutions. In addition to the traditional sources of citations,
the ADS has recently added references extracted from the arXiv e-prints on a
nightly basis. We review the procedures used to harvest and identify the
reference data used in the creation of citations, the policies and procedures
that we follow to avoid double-counting and to eliminate contributions which
may not be scholarly in nature. Finally, we describe how users and institutions
can easily obtain quantitative citation data from the ADS, both interactively
and via web-based programming tools.
  The ADS is available at http://ads.harvard.edu.
"
0610012,"On Shift Sequences for Interleaved Construction of Sequence Sets with
  Low Correlation","  Construction of signal sets with low correlation property is of interest to
designers of CDMA systems. One of the preferred ways of constructing such sets
is the interleaved construction which uses two sequences a and b with 2-level
autocorrelation and a shift sequence e. The shift sequence has to satisfy
certain conditions for the resulting signal set to have low correlation
properties. This article shows that the conditions reported in literature are
too strong and gives a version which results in more number of shift sequences.
An open problem on the existence of shift sequences for attaining an
interleaved set with maximum correlation value bounded by v+2 is also taken up
and solved.
"
0610016,Norm Based Causal Reasoning in Textual Corpus,"  Truth based entailments are not sufficient for a good comprehension of NL. In
fact, it can not deduce implicit information necessary to understand a text. On
the other hand, norm based entailments are able to reach this goal. This idea
was behind the development of Frames (Minsky 75) and Scripts (Schank 77, Schank
79) in the 70's. But these theories are not formalized enough and their
adaptation to new situations is far from being obvious. In this paper, we
present a reasoning system which uses norms in a causal reasoning process in
order to find the cause of an accident from a text describing it.
"
0610018,"Raisonnement stratifi\'{e} \`{a} base de normes pour inf\'{e}rer les
  causes dans un corpus textuel","  To understand texts written in natural language (LN), we use our knowledge
about the norms of the domain. Norms allow to infer more implicit information
from the text. This kind of information can, in general, be defeasible, but it
remains useful and acceptable while the text do not contradict it explicitly.
In this paper we describe a non-monotonic reasoning system based on the norms
of the car crash domain. The system infers the cause of an accident from its
textual description. The cause of an accident is seen as the most specific norm
which has been violated. The predicates and the rules of the system are
stratified: organized on layers in order to obtain an efficient reasoning.
"
0610024,Network calculus based FDI approach for switched Ethernet architecture,"  The Networked Control Systems (NCS) are complex systems which integrate
information provided by several domians such as automatic control, computer
science, communication network. The work presented in this paper concerns fault
detection, isolation and compensation of communication network. The proposed
method is based on the classical approach of Fault Detection and Isolation and
Fault Tolerant Control (FDI/FTC) currently used in diagnosis. The modelling of
the network to be supervised is based on both couloured petri nets and network
calculus theory often used to represent and analyse the network behaviour. The
goal is to implement inside network devices algorithms enabling to detect,
isolate and compensate communication faults in an autonomous way.
"
0610055,Extending the Calculus of Constructions with Tarski's fix-point theorem,"  We propose to use Tarski's least fixpoint theorem as a basis to define
recursive functions in the calculus of inductive constructions. This widens the
class of functions that can be modeled in type-theory based theorem proving
tool to potentially non-terminating functions. This is only possible if we
extend the logical framework by adding the axioms that correspond to classical
logic. We claim that the extended framework makes it possible to reason about
terminating and non-terminating computations and we show that common facilities
of the calculus of inductive construction, like program extraction can be
extended to also handle the new functions.
"
0610071,Rewriting modulo in Deduction modulo,"  We study the termination of rewriting modulo a set of equations in the
Calculus of Algebraic Constructions, an extension of the Calculus of
Constructions with functions and predicates defined by higher-order rewrite
rules. In a previous work, we defined general syntactic conditions based on the
notion of computable closure for ensuring the termination of the combination of
rewriting and beta-reduction. Here, we show that this result is preserved when
considering rewriting modulo a set of equations if the equivalence classes
generated by these equations are finite, the equations are linear and satisfy
general syntactic conditions also based on the notion of computable closure.
This includes equations like associativity and commutativity, and provides an
original treatment of termination modulo equations.
"
0610074,"Collaborative Decoding of Interleaved Reed-Solomon Codes and
  Concatenated Code Designs","  Interleaved Reed-Solomon codes are applied in numerous data processing, data
transmission, and data storage systems. They are generated by interleaving
several codewords of ordinary Reed-Solomon codes. Usually, these codewords are
decoded independently by classical algebraic decoding methods. However, by
collaborative algebraic decoding approaches, such interleaved schemes allow the
correction of error patterns beyond half the minimum distance, provided that
the errors in the received signal occur in bursts. In this work, collaborative
decoding of interleaved Reed-Solomon codes by multi-sequence shift-register
synthesis is considered and analyzed. Based on the framework of interleaved
Reed-Solomon codes, concatenated code designs are investigated, which are
obtained by interleaving several Reed-Solomon codes, and concatenating them
with an inner block code.
"
0610084,"Share and Disperse: How to Resist Against Aggregator Compromises in
  Sensor Networks","  A common approach to overcome the limited nature of sensor networks is to
aggregate data at intermediate nodes. A challenging issue in this context is to
guarantee end-to-end security mainly because sensor networks are extremely
vulnerable to node compromises. In order to secure data aggregation, in this
paper we propose three schemes that rely on multipath routing. The first one
guarantees data confidentiality through secret sharing, while the second and
third ones provide data availability through information dispersal. Based on
qualitative analysis and implementation, we show that, by applying these
schemes, a sensor network can achieve data confidentiality, authenticity, and
protection against denial of service attacks even in the presence of multiple
compromised nodes.
"
0610085,Symbolic Simulation-Checking of Dense-Time Systems,"  Intuitively, an (implementation) automata is simulated by a (specification)
automata if every externally observable transition by the implementation
automata can also be made by the specification automata. In this work, we
present a symbolic algorithm for the simulation-checking of timed automatas. We
first present a simulation-checking procedure that operates on state spaces,
representable with convex polyhedra, of timed automatas. We then present
techniques to represent those intermediate result convex polyhedra with zones
and make the procedure an algorithm. We then discuss how to handle Zeno states
in the implementation automata. Finally, we have endeavored to realize the
algorithm and report the performance of our algorithm in the experiment.
"
0610099,Properties of Codes with the Rank Metric,"  In this paper, we study properties of rank metric codes in general and
maximum rank distance (MRD) codes in particular. For codes with the rank
metric, we first establish Gilbert and sphere-packing bounds, and then obtain
the asymptotic forms of these two bounds and the Singleton bound. Based on the
asymptotic bounds, we observe that asymptotically Gilbert-Varsharmov bound is
exceeded by MRD codes and sphere-packing bound cannot be attained. We also
establish bounds on the rank covering radius of maximal codes, and show that
all MRD codes are maximal codes and all the MRD codes known so far achieve the
maximum rank covering radius.
"
0610107,Interference Channels with Common Information,"  In this paper, we consider the discrete memoryless interference channel with
common information, in which two senders need deliver not only private messages
but also certain common messages to their corresponding receivers. We derive an
achievable rate region for such a channel by exploiting a random coding
strategy, namely cascaded superposition coding. We reveal that the derived
achievable rate region generalizes some important existing results for the
interference channels with or without common information. Furthermore, we
specialize to a class of deterministic interference channels with common
information, and show that the derived achievable rate region is indeed the
capacity region for this class of channels.
"
0610108,Doppler Spectrum Estimation by Ramanujan Fourier Transforms,"  The Doppler spectrum estimation of a weather radar signal in a classic way
can be made by two methods, temporal one based in the autocorrelation of the
successful signals, whereas the other one uses the estimation of the power
spectral density PSD by using Fourier transforms. We introduces a new tool of
signal processing based on Ramanujan sums cq(n), adapted to the analysis of
arithmetical sequences with several resonances p/q. These sums are almost
periodic according to time n of resonances and aperiodic according to the order
q of resonances. New results will be supplied by the use of Ramanujan Fourier
Transform (RFT) for the estimation of the Doppler spectrum for the weather
radar signal.
"
0610115,An Achievable Rate Region for the Gaussian Interference Channel,"  An achievable rate region for the Gaussian interference channel is derived
using Sato's modified frequency division multiplexing idea and a special case
of Han and Kobayashi's rate region (denoted by $\Gmat^\prime$). We show that
the new inner bound includes $\Gmat^\prime$, Sason's rate region $\Dmat$, as
well as the achievable region via TDM/FDM, as its subsets. The advantage of
this improved inner bound over $\Gmat^\prime$ arises due to its inherent
ability to utilize the whole transmit power range on the real line without
violating the power constraint. We also provide analysis to examine the
conditions for the new achievable region to strictly extend $\Gmat^\prime$.
"
0610118,Applying Part-of-Seech Enhanced LSA to Automatic Essay Grading,"  Latent Semantic Analysis (LSA) is a widely used Information Retrieval method
based on ""bag-of-words"" assumption. However, according to general conception,
syntax plays a role in representing meaning of sentences. Thus, enhancing LSA
with part-of-speech (POS) information to capture the context of word
occurrences appears to be theoretically feasible extension. The approach is
tested empirically on a automatic essay grading system using LSA for document
similarity comparisons. A comparison on several POS-enhanced LSA models is
reported. Our findings show that the addition of contextual information in the
form of POS tags can raise the accuracy of the LSA-based scoring models up to
10.77 per cent.
"
0610122,Faithful Polynomial Evaluation with Compensated Horner Algorithm,"  This paper presents two sufficient conditions to ensure a faithful evaluation
of polynomial in IEEE-754 floating point arithmetic. Faithfulness means that
the computed value is one of the two floating point neighbours of the exact
result; it can be satisfied using a more accurate algorithm than the classic
Horner scheme. One condition here provided is an apriori bound of the
polynomial condition number derived from the error analysis of the compensated
Horner algorithm. The second condition is both dynamic and validated to check
at the running time the faithfulness of a given evaluation. Numerical
experiments illustrate the behavior of these two conditions and that associated
running time over-cost is really interesting.
"
0610127,The intersection and the union of the asynchronous systems,"  The asynchronous systems $f$ are the models of the asynchronous circuits from
digital electrical engineering. They are multi-valued functions that associate
to each input $u:\mathbf{R}\to \{0,1\}^{m}$ a set of states $x\in f(u),$ where
$x:\mathbf{R}\to \{0,1\}^{n}.$ The intersection of the systems allows adding
supplementary conditions in modeling and the union of the systems allows
considering the validity of one of two systems in modeling, for example when
testing the asynchronous circuits and the circuit is supposed to be 'good' or
'bad'. The purpose of the paper is that of analyzing the intersection and the
union against the initial/final states, initial/final time, initial/final state
functions, subsystems, dual systems, inverse systems, Cartesian product of
systems, parallel connection and serial connection of systems.
"
0610134,A Markov Chain based method for generating long-range dependence,"  This paper describes a model for generating time series which exhibit the
statistical phenomenon known as long-range dependence (LRD). A Markov Modulated
Process based upon an infinite Markov chain is described. The work described is
motivated by applications in telecommunications where LRD is a known property
of time-series measured on the internet. The process can generate a time series
exhibiting LRD with known parameters and is particularly suitable for modelling
internet traffic since the time series is in terms of ones and zeros which can
be interpreted as data packets and inter-packet gaps. The method is extremely
simple computationally and analytically and could prove more tractable than
other methods described in the literature
"
0610147,"Grooming of Dynamic Traffic in WDM Star and Tree Networks Using Genetic
  Algorithm","  The advances in WDM technology lead to the great interest in traffic grooming
problems. As traffic often changes from time to time, the problem of grooming
dynamic traffic is of great practical value. In this paper, we discuss dynamic
grooming of traffic in star and tree networks. A genetic algorithm (GA) based
approach is proposed to support arbitrary dynamic traffic patterns, which
minimizes the number of ADM's and wavelengths. To evaluate the algorithm,
tighter bounds are derived. Computer simulation results show that our algorithm
is efficient in reducing both the numbers of ADM's and wavelengths in tree and
star networks.
"
0610148,Decoder Error Probability of MRD Codes,"  In this paper, we first introduce the concept of elementary linear subspace,
which has similar properties to those of a set of coordinates. Using this new
concept, we derive properties of maximum rank distance (MRD) codes that
parallel those of maximum distance separable (MDS) codes. Using these
properties, we show that the decoder error probability of MRD codes with error
correction capability t decreases exponentially with t^2 based on the
assumption that all errors with the same rank are equally likely. We argue that
the channel based on this assumption is an approximation of a channel corrupted
by crisscross errors.
"
0610150,On LAO Testing of Multiple Hypotheses for Many Independent Objects,"  The problem of many hypotheses logarithmically asymptotically optimal (LAO)
testing for a model consisting of three or more independent objects is solved.
It is supposed that $M$ probability distributions are known and each object
independently of others follows to one of them. The matrix of asymptotic
interdependencies (reliability--reliability functions) of all possible pairs of
the error probability exponents (reliabilities) in optimal testing for this
model is studied.
  This problem was introduced (and solved for the case of two objects and two
given probability distributions) by Ahlswede and Haroutunian. The model with
two independent objects with $M$ hypotheses was explored by Haroutunian and
Hakobyan.
"
0610151,"Anytime coding on the infinite bandwidth AWGN channel: A sequential
  semi-orthogonal optimal code","  It is well known that orthogonal coding can be used to approach the Shannon
capacity of the power-constrained AWGN channel without a bandwidth constraint.
This correspondence describes a semi-orthogonal variation of pulse position
modulation that is sequential in nature -- bits can be ``streamed across''
without having to buffer up blocks of bits at the transmitter. ML decoding
results in an exponentially small probability of error as a function of
tolerated receiver delay and thus eventually a zero probability of error on
every transmitted bit. In the high-rate regime, a matching upper bound is given
on the delay error exponent. We close with some comments on the case with
feedback and the connections to the capacity per unit cost problem.
"
0610157,"A Genetic Algorithm Approach to the Grooming of Dynamic Traffic in Tree
  and Star Networks with Bifurcation","  Traffic grooming is widely employed to reduce the number of ADM's and
wavelengths. We consider the problem of grooming of dynamic traffic in WDM tree
and star networks in this paper. To achieve better results, we used the
bifurcation techniques to the grooming of arbitrary dynamic traffic in a
strictly non-blocking manner in networks. Three splitting methods, including
Traffic-Cutting, Traffic-Dividing and Synthesized-Splitting were proposed. A
genetic algorithm (GA) approach based on these methods was proposed to tackle
such grooming problems in tree and star networks. The performance of these
algorithms was tested under different conditions in star and tree networks.
Computer simulation results showed that our algorithm is efficient in reducing
both the numbers of ADM's and wavelengths.
"
0610167,"ECA-RuleML: An Approach combining ECA Rules with temporal interval-based
  KR Event/Action Logics and Transactional Update Logics","  An important problem to be addressed within Event-Driven Architecture (EDA)
is how to correctly and efficiently capture and process the event/action-based
logic. This paper endeavors to bridge the gap between the Knowledge
Representation (KR) approaches based on durable events/actions and such
formalisms as event calculus, on one hand, and event-condition-action (ECA)
reaction rules extending the approach of active databases that view events as
instantaneous occurrences and/or sequences of events, on the other. We propose
formalism based on reaction rules (ECA rules) and a novel interval-based event
logic and present concrete RuleML-based syntax, semantics and implementation.
We further evaluate this approach theoretically, experimentally and on an
example derived from common industry use cases and illustrate its benefits.
"
0610172,"On the Analysis and Generalization of Extended Visual Cryptography
  Schemes","  An Extended Visual Cryptography Scheme (EVCS) was proposed by Ateniese et al.
[3] to protect a binary secret image with meaningful (innocent-looking) shares.
This is implemented by concatenating an extended matrix to each basis matrix.
The minimum size of the extended matrix was obtained from a hypergraph coloring
model and the scheme was designed for binary images only [3]. In this paper, we
give a more concise derivation for this matrix extension for color images.
Furthermore, we present a (k, n) scheme to protect multiple color images with
meaningful shares. This scheme is an extension of the (n, n) VCS for multiple
binary images proposed in Droste scheme [2].
"
0610173,On Degree-Based Decentralized Search in Complex Networks,"  Decentralized search aims to find the target node in a large network by using
only local information. The applications of it include peer-to-peer file
sharing, web search and anything else that requires locating a specific target
in a complex system. In this paper, we examine the degree-based decentralized
search method. Specifically, we evaluate the efficiency of the method in
different cases with different amounts of available local information. In
addition, we propose a simple refinement algorithm for significantly shortening
the length of the route that has been found. Some insights useful for the
future developments of efficient decentralized search schemes have been
achieved.
"
0611003,"A Scalable Protocol for Cooperative Time Synchronization Using Spatial
  Averaging","  Time synchronization is an important aspect of sensor network operation.
However, it is well known that synchronization error accumulates over multiple
hops. This presents a challenge for large-scale, multi-hop sensor networks with
a large number of nodes distributed over wide areas. In this work, we present a
protocol that uses spatial averaging to reduce error accumulation in
large-scale networks. We provide an analysis to quantify the synchronization
improvement achieved using spatial averaging and find that in a basic
cooperative network, the skew and offset variance decrease approximately as
$1/\bar{N}$ where $\bar{N}$ is the number of cooperating nodes. For general
networks, simulation results and a comparison to basic cooperative network
results are used to illustrate the improvement in synchronization performance.
"
0611015,"On the Fairness of Rate Allocation in Gaussian Multiple Access Channel
  and Broadcast Channel","  The capacity region of a channel consists of all achievable rate vectors.
Picking a particular point in the capacity region is synonymous with rate
allocation. The issue of fairness in rate allocation is addressed in this
paper. We review several notions of fairness, including max-min fairness,
proportional fairness and Nash bargaining solution. Their efficiencies for
general multiuser channels are discussed. We apply these ideas to the Gaussian
multiple access channel (MAC) and the Gaussian broadcast channel (BC). We show
that in the Gaussian MAC, max-min fairness and proportional fairness coincide.
For both Gaussian MAC and BC, we devise efficient algorithms that locate the
fair point in the capacity region. Some elementary properties of fair rate
allocations are proved.
"
0611040,The Formal System lambda-delta,"  The formal system lambda-delta is a typed lambda calculus that pursues the
unification of terms, types, environments and contexts as the main goal.
lambda-delta takes some features from the Automath-related lambda calculi and
some from the pure type systems, but differs from both in that it does not
include the Pi construction while it provides for an abbreviation mechanism at
the level of terms. lambda-delta enjoys some important desirable properties
such as the confluence of reduction, the correctness of types, the uniqueness
of types up to conversion, the subject reduction of the type assignment, the
strong normalization of the typed terms and, as a corollary, the decidability
of type inference problem.
"
0611041,Groebner Bases Applied to Systems of Linear Difference Equations,"  In this paper we consider systems of partial (multidimensional) linear
difference equations. Specifically, such systems arise in scientific computing
under discretization of linear partial differential equations and in
computational high energy physics as recurrence relations for multiloop Feynman
integrals. The most universal algorithmic tool for investigation of linear
difference systems is based on their transformation into an equivalent Groebner
basis form. We present an algorithm for this transformation implemented in
Maple. The algorithm and its implementation can be applied to automatic
generation of difference schemes for linear partial differential equations and
to reduction of Feynman integrals. Some illustrative examples are given.
"
0611045,"The evolution of the parametric models of drawings (modules) in the
  enterprises reconstruction CAD system","  Progressing methods of drawings creating automation is discussed on the basis
of so-called modules containing parametric representation of a part of the
drawing and the geometrical elements. The stages of evolution of modular
technology of automation of engineering are describing alternatives of applying
of moduluss for simple association of elements of the drawing without
parametric representation with an opportunity of its commenting, for graphic
symbols creating in the schemas of automation and drawings of pipelines, for
storage of the specific properties of elements, for development of the
specialized parts of the project: the axonometric schemas, profiles of outboard
pipe networks etc.
"
0611054,"How Random is a Coin Toss? Bayesian Inference and the Symbolic Dynamics
  of Deterministic Chaos","  Symbolic dynamics has proven to be an invaluable tool in analyzing the
mechanisms that lead to unpredictability and random behavior in nonlinear
dynamical systems. Surprisingly, a discrete partition of continuous state space
can produce a coarse-grained description of the behavior that accurately
describes the invariant properties of an underlying chaotic attractor. In
particular, measures of the rate of information production--the topological and
metric entropy rates--can be estimated from the outputs of Markov or generating
partitions. Here we develop Bayesian inference for k-th order Markov chains as
a method to finding generating partitions and estimating entropy rates from
finite samples of discretized data produced by coarse-grained dynamical
systems.
"
0611068,Wikipedia: organisation from a bottom-up approach,"  Wikipedia can be considered as an extreme form of a self-managing team, as a
means of labour division. One could expect that this bottom-up approach, with
the absense of top-down organisational control, would lead to a chaos, but our
analysis shows that this is not the case. In the Dutch Wikipedia, an integrated
and coherent data structure is created, while at the same time users succeed in
distributing roles by self-selection. Some users focus on an area of expertise,
while others edit over the whole encyclopedic range. This constitutes our
conclusion that Wikipedia, in general, is a successful example of a
self-managing team.
"
0611069,Scaling Construction Grammar up to Production Systems: the SCIM,"  While a great effort has concerned the development of fully integrated
modular understanding systems, few researches have focused on the problem of
unifying existing linguistic formalisms with cognitive processing models. The
Situated Constructional Interpretation Model is one of these attempts. In this
model, the notion of ""construction"" has been adapted in order to be able to
mimic the behavior of Production Systems. The Construction Grammar approach
establishes a model of the relations between linguistic forms and meaning, by
the mean of constructions. The latter can be considered as pairings from a
topologically structured space to an unstructured space, in some way a special
kind of production rules.
"
0611073,Prefix Codes for Power Laws with Countable Support,"  In prefix coding over an infinite alphabet, methods that consider specific
distributions generally consider those that decline more quickly than a power
law (e.g., Golomb coding). Particular power-law distributions, however, model
many random variables encountered in practice. For such random variables,
compression performance is judged via estimates of expected bits per input
symbol. This correspondence introduces a family of prefix codes with an eye
towards near-optimal coding of known distributions. Compression performance is
precisely estimated for well-known probability distributions using these codes
and using previously known prefix codes. One application of these near-optimal
codes is an improved representation of rational numbers.
"
0611077,Evolutionary Optimization in an Algorithmic Setting,"  Evolutionary processes proved very useful for solving optimization problems.
In this work, we build a formalization of the notion of cooperation and
competition of multiple systems working toward a common optimization goal of
the population using evolutionary computation techniques. It is justified that
evolutionary algorithms are more expressive than conventional recursive
algorithms. Three subclasses of evolutionary algorithms are proposed here:
bounded finite, unbounded finite and infinite types. Some results on
completeness, optimality and search decidability for the above classes are
presented. A natural extension of Evolutionary Turing Machine model developed
in this paper allows one to mathematically represent and study properties of
cooperation and competition in a population of optimized species.
"
0611092,Design approaches in technology enhanced learning,"  Design is a critical to the successful development of any interactive
learning environment (ILE). Moreover, in technology enhanced learning (TEL),
the design process requires input from many diverse areas of expertise. As
such, anyone undertaking tool development is required to directly address the
design challenge from multiple perspectives. We provide a motivation and
rationale for design approaches for learning technologies that draws upon
Simon's seminal proposition of Design Science (Simon, 1969). We then review the
application of Design Experiments (Brown, 1992) and Design Patterns (Alexander
et al., 1977) and argue that a patterns approach has the potential to address
many of the critical challenges faced by learning technologists.
"
0611099,On the space complexity of one-pass compression,"  We study how much memory one-pass compression algorithms need to compete with
the best multi-pass algorithms. We call a one-pass algorithm an (f (n,
\ell))-footprint compressor if, given $n$, $\ell$ and an $n$-ary string $S$, it
stores $S$ in ((\rule{0ex}{2ex} O (H_\ell (S)) + o (\log n)) |S| + O (n^{\ell +
1} \log n)) bits -- where (H_\ell (S)) is the $\ell$th-order empirical entropy
of $S$ -- while using at most (f (n, \ell)) bits of memory. We prove that, for
any (\epsilon > 0) and some (f (n, \ell) \in O (n^{\ell + \epsilon} \log n)),
there is an (f (n, \ell))-footprint compressor; on the other hand, there is no
(f (n, \ell))-footprint compressor for (f (n, \ell) \in o (n^\ell \log n)).
"
0611123,Functional Bregman Divergence and Bayesian Estimation of Distributions,"  A class of distortions termed functional Bregman divergences is defined,
which includes squared error and relative entropy. A functional Bregman
divergence acts on functions or distributions, and generalizes the standard
Bregman divergence for vectors and a previous pointwise Bregman divergence that
was defined for functions. A recently published result showed that the mean
minimizes the expected Bregman divergence. The new functional definition
enables the extension of this result to the continuous case to show that the
mean minimizes the expected functional Bregman divergence over a set of
functions or distributions. It is shown how this theorem applies to the
Bayesian estimation of distributions. Estimation of the uniform distribution
from independent and identically drawn samples is used as a case study.
"
0611141,A Generic Global Constraint based on MDDs,"  The paper suggests the use of Multi-Valued Decision Diagrams (MDDs) as the
supporting data structure for a generic global constraint. We give an algorithm
for maintaining generalized arc consistency (GAC) on this constraint that
amortizes the cost of the GAC computation over a root-to-terminal path in the
search tree. The technique used is an extension of the GAC algorithm for the
regular language constraint on finite length input. Our approach adds support
for skipped variables, maintains the reduced property of the MDD dynamically
and provides domain entailment detection. Finally we also show how to adapt the
approach to constraint types that are closely related to MDDs, such as AOMDDs
and Case DAGs.
"
0611153,"Changing our view on design evaluation meetings methodology: a study of
  software technical review meetings","  By contrast to design meetings, design evaluation meetings (DEMs) have
generally been considered as situations in which, according to DEMs
methodologies, design activities are quite marginal. In a study of DEMs in
software development, i.e. in technical review meetings following a particular
review methodology, we showed: (i) the occurrence of design activities as part
of an argumentation process; (ii) the relative importance of cognitive
synchronisation as a prerequisite for evaluation; (iii) the important role
played in evaluation by argumentation that makes explicit the underlying design
rationale (DR). On the basis of our results, we discuss the potential for using
DR methodologies in this kind of meetings.
"
0612014,Going Stupid with EcoLab,"  In 2005, Railsback et al. proposed a very simple model ({\em Stupid
  Model}) that could be implemented within a couple of hours, and later
extended to demonstrate the use of common ABM platform functionality. They
provided implementations of the model in several agent based modelling
platforms, and compared the platforms for ease of implementation of this simple
model, and performance. In this paper, I implement Railsback et al's Stupid
Model in the EcoLab simulation platform, a C++ based modelling platform,
demonstrating that it is a feasible platform for these sorts of models, and
compare the performance of the implementation with Repast, Mason and Swarm
versions.
"
0612015,On the intersection of additive perfect codes,"  The intersection problem for additive (extended and non-extended) perfect
codes, i.e. which are the possibilities for the number of codewords in the
intersection of two additive codes C1 and C2 of the same length, is
investigated. Lower and upper bounds for the intersection number are computed
and, for any value between these bounds, codes which have this given
intersection value are constructed. For all these codes the abelian group
structure of the intersection is characterized. The parameters of this abelian
group structure corresponding to the intersection codes are computed and lower
and upper bounds for these parameters are established. Finally, constructions
of codes the intersection of which fits any parameters between these bounds are
given.
"
0612017,Confrontation of viewpoints in a concurrent engineering process,"  We present an empirical study aimed at analysing the use of viewpoints in an
industrial Concurrent Engineering context. Our focus is on the viewpoints
expressed in the argumentative process taking place in evaluation meetings. Our
results show that arguments enabling a viewpoint or proposal to be defended are
often characterized by the use of constraints. One result involved the way in
which the proposals for solutions are assessed during these meetings. We have
revealed the existence of specific assessment modes in these meetings as well
as their combination. Then, we show that, even if some constraints are
apparently identically used by the different specialists involved in meetings,
various meanings and weightings are associated with these constraints by these
different specialists.
"
0612018,"Mental Representations Constructed by Experts and Novices in
  Object-Oriented Program Comprehension","  Previous studies on program comprehension were carried out largely in the
context of procedural languages. Our purpose is to develop and evaluate a
cognitive model of object-oriented (OO) program understanding. Our model is
based on the van Dijk and Kintsch's model of text understanding (1983). One key
aspect of this theoretical approach is the distinction between two kinds of
representation the reader might construct from a text: the textbase and the
situation model. On the basis of results of an experiment we have conducted, we
evaluate the cognitive validity of this distinction in OO program
understanding. We examine how the construction of these two representations is
differentially affected by the programmer's expertise and how they evolve
differentially over time.
"
0612022,Both Generic Design and Different Forms of Designing,"  This paper defends an augmented cognitively oriented ""generic-design
hypothesis"": There are both significant similarities between the design
activities implemented in different situations and crucial differences between
these and other cognitive activities; yet, characteristics of a design
situation (i.e., related to the designers, the artefact, and other task
variables influencing these two) introduce specificities in the corresponding
design activities and cognitive structures that are used. We thus combine the
generic-design hypothesis with that of different ""forms"" of designing. In this
paper, outlining a number of directions that need further elaboration, we
propose a series of candidate dimensions underlying such forms of design.
"
0612037,Least Significant Digit First Presburger Automata,"  Since 1969 \cite{C-MST69,S-SMJ77}, we know that any Presburger-definable set
\cite{P-PCM29} (a set of integer vectors satisfying a formula in the
first-order additive theory of the integers) can be represented by a
state-based symmbolic representation, called in this paper Finite Digit Vector
Automata (FDVA). Efficient algorithms for manipulating these sets have been
recently developed. However, the problem of deciding if a FDVA represents such
a set, is a well-known hard problem first solved by Muchnik in 1991 with a
quadruply-exponential time algorithm. In this paper, we show how to determine
in polynomial time whether a FDVA represents a Presburger-definable set, and we
provide in this positive case a polynomial time algorithm that constructs a
Presburger-formula that defines the same set.
"
0612039,Computing the Equilibria of Bimatrix Games using Dominance Heuristics,"  We propose a formulation of a general-sum bimatrix game as a bipartite
directed graph with the objective of establishing a correspondence between the
set of the relevant structures of the graph (in particular elementary cycles)
and the set of the Nash equilibria of the game. We show that finding the set of
elementary cycles of the graph permits the computation of the set of
equilibria. For games whose graphs have a sparse adjacency matrix, this serves
as a good heuristic for computing the set of equilibria. The heuristic also
allows the discarding of sections of the support space that do not yield any
equilibrium, thus serving as a useful pre-processing step for algorithms that
compute the equilibria through support enumeration.
"
0612043,About the Lifespan of Peer to Peer Networks,"  We analyze the ability of peer to peer networks to deliver a complete file
among the peers. Early on we motivate a broad generalization of network
behavior organizing it into one of two successive phases. According to this
view the network has two main states: first centralized - few sources (roots)
hold the complete file, and next distributed - peers hold some parts (chunks)
of the file such that the entire network has the whole file, but no individual
has it. In the distributed state we study two scenarios, first, when the peers
are ``patient'', i.e, do not leave the system until they obtain the complete
file; second, peers are ``impatient'' and almost always leave the network
before obtaining the complete file.
"
0612064,Bounds on Key Appearance Equivocation for Substitution Ciphers,"  The average conditional entropy of the key given the message and its
corresponding cryptogram, H(K|M,C), which is reffer as a key appearance
equivocation, was proposed as a theoretical measure of the strength of the
cipher system under a known-plaintext attack by Dunham in 1980. In the same
work (among other things), lower and upper bounds for H(S}_{M}|M^L,C^L) are
found and its asymptotic behaviour as a function of cryptogram length L is
described for simple substitution ciphers i.e. when the key space S_{M} is the
symmetric group acting on a discrete alphabet M. In the present paper we
consider the same problem when the key space is an arbitrary subgroup K of
S_{M} and generalize Dunham's result.
"
0612069,Cores of Countably Categorical Structures,"  A relational structure is a core, if all its endomorphisms are embeddings.
This notion is important for computational complexity classification of
constraint satisfaction problems. It is a fundamental fact that every finite
structure has a core, i.e., has an endomorphism such that the structure induced
by its image is a core; moreover, the core is unique up to isomorphism. Weprove
that every \omega -categorical structure has a core. Moreover, every
\omega-categorical structure is homomorphically equivalent to a model-complete
core, which is unique up to isomorphism, and which is finite or \omega
-categorical. We discuss consequences for constraint satisfaction with \omega
-categorical templates.
"
0612076,"A New Approach for Capacity Analysis of Large Dimensional Multi-Antenna
  Channels","  This paper adresses the behaviour of the mutual information of correlated
MIMO Rayleigh channels when the numbers of transmit and receive antennas
converge to infinity at the same rate. Using a new and simple approach based on
Poincar\'{e}-Nash inequality and on an integration by parts formula, it is
rigorously established that the mutual information converges to a Gaussian
random variable whose mean and variance are evaluated. These results confirm
previous evaluations based on the powerful but non rigorous replica method. It
is believed that the tools that are used in this paper are simple, robust, and
of interest for the communications engineering community.
"
0612083,A Byzantine Fault Tolerant Distributed Commit Protocol,"  In this paper, we present a Byzantine fault tolerant distributed commit
protocol for transactions running over untrusted networks. The traditional
two-phase commit protocol is enhanced by replicating the coordinator and by
running a Byzantine agreement algorithm among the coordinator replicas. Our
protocol can tolerate Byzantine faults at the coordinator replicas and a subset
of malicious faults at the participants. A decision certificate, which includes
a set of registration records and a set of votes from participants, is used to
facilitate the coordinator replicas to reach a Byzantine agreement on the
outcome of each transaction. The certificate also limits the ways a faulty
replica can use towards non-atomic termination of transactions, or semantically
incorrect transaction outcomes.
"
0612093,A Calculus for Sensor Networks,"  We consider the problem of providing a rigorous model for programming
wireless sensor networks. Assuming that collisions, packet losses, and errors
are dealt with at the lower layers of the protocol stack, we propose a Calculus
for Sensor Networks (CSN) that captures the main abstractions for programming
applications for this class of devices. Besides providing the syntax and
semantics for the calculus, we show its expressiveness by providing
implementations for several examples of typical operations on sensor networks.
Also included is a detailed discussion of possible extensions to CSN that
enable the modeling of other important features of these networks such as
sensor state, sampling strategies, and network security.
"
0612095,Approximation of the Two-Part MDL Code,"  Approximation of the optimal two-part MDL code for given data, through
successive monotonically length-decreasing two-part MDL codes, has the
following properties: (i) computation of each step may take arbitrarily long;
(ii) we may not know when we reach the optimum, or whether we will reach the
optimum at all; (iii) the sequence of models generated may not monotonically
improve the goodness of fit; but (iv) the model associated with the optimum has
(almost) the best goodness of fit. To express the practically interesting
goodness of fit of individual models for individual data sets we have to rely
on Kolmogorov complexity.
"
0612100,Improved results for a memory allocation problem,"  We consider a memory allocation problem that can be modeled as a version of
bin packing where items may be split, but each bin may contain at most two
(parts of) items. A 3/2-approximation algorithm and an NP-hardness proof for
this problem was given by Chung et al. We give a simpler 3/2-approximation
algorithm for it which is in fact an online algorithm. This algorithm also has
good performance for the more general case where each bin may contain at most k
parts of items. We show that this general case is also strongly NP-hard.
Additionally, we give an efficient 7/5-approximation algorithm.
"
0612106,On Completeness of Logical Relations for Monadic Types,"  Software security can be ensured by specifying and verifying security
properties of software using formal methods with strong theoretical bases. In
particular, programs can be modeled in the framework of lambda-calculi, and
interesting properties can be expressed formally by contextual equivalence
(a.k.a. observational equivalence). Furthermore, imperative features, which
exist in most real-life software, can be nicely expressed in the so-called
computational lambda-calculus. Contextual equivalence is difficult to prove
directly, but we can often use logical relations as a tool to establish it in
lambda-calculi. We have already defined logical relations for the computational
lambda-calculus in previous work. We devote this paper to the study of their
completeness w.r.t. contextual equivalence in the computational
lambda-calculus.
"
0612108,On Using Matching Theory to Understand P2P Network Design,"  This paper aims to provide insight into stability of collaboration choices in
P2P networks. We study networks where exchanges between nodes are driven by the
desire to receive the best service available. This is the case for most
existing P2P networks. We explore an evolution model derived from stable
roommates theory that accounts for heterogeneity between nodes. We show that
most P2P applications can be modeled using stable matching theory. This is the
case whenever preference lists can be deduced from the exchange policy. In many
cases, the preferences lists are characterized by an interesting acyclic
property. We show that P2P networks with acyclic preferences possess a unique
stable state with good convergence properties.
"
0612119,Symmetric Subresultants and Applications,"  Schur's transforms of a polynomial are used to count its roots in the unit
disk. These are generalized them by introducing the sequence of symmetric
sub-resultants of two polynomials. Although they do have a determinantal
definition, we show that they satisfy a structure theorem which allows us to
compute them with a type of Euclidean division. As a consequence, a fast
algorithm based on a dichotomic process and FFT is designed. We prove also that
these symmetric sub-resultants have a deep link with Toeplitz matrices.
Finally, we propose a new algorithm of inversion for such matrices. It has the
same cost as those already known, however it is fraction-free and consequently
well adapted to computer algebra.
"
0612135,"Accommodation of the Service Offered by the Network for Networked
  Control Systems","  Networked Controlled Systems (NCSs) are more and more used in industrial
applications. They are strongly connected to real-time constraints because
important delays induced by the network can lead to an unstable process
control. Usually, the network used in NCSs is shared with many others
applications requiring different Quality of Service. The objective of this
paper is to optimize the tuning of the network scheduling mechanisms in taking
into account the level of Quality of Control. The goal is to maximize the
bandwidth allocation for unconstrained frames in guarantying that the control
constraints are respected. In this paper, we focus on switched Ethernet network
implementing the Classification of Service (IEEE 802.1p) based on a Weighted
Round Robin policy.
"
0612139,Alignment of Speech to Highly Imperfect Text Transcriptions,"  We introduce a novel and inexpensive approach for the temporal alignment of
speech to highly imperfect transcripts from automatic speech recognition (ASR).
Transcripts are generated for extended lecture and presentation videos, which
in some cases feature more than 30 speakers with different accents, resulting
in highly varying transcription qualities. In our approach we detect a subset
of phonemes in the speech track, and align them to the sequence of phonemes
extracted from the transcript. We report on the results for 4 speech-transcript
sets ranging from 22 to 108 minutes. The alignment performance is promising,
showing a correct matching of phonemes within 10, 20, 30 second error margins
for more than 60%, 75%, 90% of text, respectively, on average.
"
0612141,Exact Failure Frequency Calculations for Extended Systems,"  This paper shows how the steady-state availability and failure frequency can
be calculated in a single pass for very large systems, when the availability is
expressed as a product of matrices. We apply the general procedure to
$k$-out-of-$n$:G and linear consecutive $k$-out-of-$n$:F systems, and to a
simple ladder network in which each edge and node may fail. We also give the
associated generating functions when the components have identical
availabilities and failure rates. For large systems, the failure rate of the
whole system is asymptotically proportional to its size. This paves the way to
ready-to-use formulae for various architectures, as well as proof that the
differential operator approach to failure frequency calculations is very useful
and straightforward.
"
0701003,"Magnification Laws of Winner-Relaxing and Winner-Enhancing Kohonen
  Feature Maps","  Self-Organizing Maps are models for unsupervised representation formation of
cortical receptor fields by stimuli-driven self-organization in laterally
coupled winner-take-all feedforward structures. This paper discusses
modifications of the original Kohonen model that were motivated by a potential
function, in their ability to set up a neural mapping of maximal mutual
information. Enhancing the winner update, instead of relaxing it, results in an
algorithm that generates an infomax map corresponding to magnification exponent
of one. Despite there may be more than one algorithm showing the same
magnification exponent, the magnification law is an experimentally accessible
quantity and therefore suitable for quantitative description of neural
optimization principles.
"
0701004,An algebraic approach to complexity of data stream computations,"  We consider a basic problem in the general data streaming model, namely, to
estimate a vector $f \in \Z^n$ that is arbitrarily updated (i.e., incremented
or decremented) coordinate-wise. The estimate $\hat{f} \in \Z^n$ must satisfy
$\norm{\hat{f}-f}_{\infty}\le \epsilon\norm{f}_1 $, that is, $\forall i
~(\abs{\hat{f}_i - f_i} \le \epsilon \norm{f}_1)$. It is known to have
$\tilde{O}(\epsilon^{-1})$ randomized space upper bound \cite{cm:jalgo},
$\Omega(\epsilon^{-1} \log (\epsilon n))$ space lower bound
\cite{bkmt:sirocco03} and deterministic space upper bound of
$\tilde{\Omega}(\epsilon^{-2})$ bits.\footnote{The $\tilde{O}$ and
$\tilde{\Omega}$ notations suppress poly-logarithmic factors in $n, \log
\epsilon^{-1}, \norm{f}_{\infty}$ and $\log \delta^{-1}$, where, $\delta$ is
the error probability (for randomized algorithm).} We show that any
deterministic algorithm for this problem requires space $\Omega(\epsilon^{-2}
(\log \norm{f}_1))$ bits.
"
0701009,"Approximation and Inapproximability Results for Maximum Clique of Disc
  Graphs in High Dimensions","  We prove algorithmic and hardness results for the problem of finding the
largest set of a fixed diameter in the Euclidean space. In particular, we prove
that if $A^*$ is the largest subset of diameter $r$ of $n$ points in the
Euclidean space, then for every $\epsilon>0$ there exists a polynomial time
algorithm that outputs a set $B$ of size at least $|A^*|$ and of diameter at
most $r(\sqrt{2}+\epsilon)$. On the hardness side, roughly speaking, we show
that unless $P=NP$ for every $\epsilon>0$ it is not possible to guarantee the
diameter $r(\sqrt{4/3}-\epsilon)$ for $B$ even if the algorithm is allowed to
output a set of size $({95\over 94}-\epsilon)^{-1}|A^*|$.
"
0701025,Free deconvolution for signal processing applications,"  Situations in many fields of research, such as digital communications,
nuclear physics and mathematical finance, can be modelled with random matrices.
When the matrices get large, free probability theory is an invaluable tool for
describing the asymptotic behaviour of many systems. It will be shown how free
probability can be used to aid in source detection for certain systems. Sample
covariance matrices for systems with noise are the starting point in our source
detection problem. Multiplicative free deconvolution is shown to be a method
which can aid in expressing limit eigenvalue distributions for sample
covariance matrices, and to simplify estimators for eigenvalue distributions of
covariance matrices.
"
0701027,The source coding game with a cheating switcher,"  Berger's paper `The Source Coding Game', IEEE Trans. Inform. Theory, 1971,
considers the problem of finding the rate-distortion function for an
adversarial source comprised of multiple known IID sources. The adversary,
called the `switcher', was allowed only causal access to the source
realizations and the rate-distortion function was obtained through the use of a
type covering lemma. In this paper, the rate-distortion function of the
adversarial source is described, under the assumption that the switcher has
non-causal access to all source realizations. The proof utilizes the type
covering lemma and simple conditional, random `switching' rules. The
rate-distortion function is once again the maximization of the R(D) function
for a region of attainable IID distributions.
"
0701028,Statistical keyword detection in literary corpora,"  Understanding the complexity of human language requires an appropriate
analysis of the statistical distribution of words in texts. We consider the
information retrieval problem of detecting and ranking the relevant words of a
text by means of statistical information referring to the ""spatial"" use of the
words. Shannon's entropy of information is used as a tool for automatic keyword
extraction. By using The Origin of Species by Charles Darwin as a
representative text sample, we show the performance of our detector and compare
it with another proposals in the literature. The random shuffled text receives
special attention as a tool for calibrating the ranking indices.
"
0701034,"Performance of Rake Receivers in IR-UWB Networks Using Energy-Efficient
  Power Control","  This paper studies the performance of partial-Rake (PRake) receivers in
impulse-radio ultrawideband wireless networks when an energy-efficient power
control scheme is adopted. Due to the large bandwidth of the system, the
multipath channel is assumed to be frequency-selective. By making use of
noncooperative game-theoretic models and large-system analysis tools, explicit
expressions are derived in terms of network parameters to measure the effects
of self-interference and multiple-access interference at a receiving access
point. Performance of the PRake receivers is thus compared in terms of achieved
utilities and loss to that of the all-Rake receiver. Simulation results are
provided to validate the analysis.
"
0701040,Curve Tracking Control for Legged Locomotion in Horizontal Plane,"  We derive a hybrid feedback control law for the lateral leg spring (LLS)
model so that the center of mass of a legged runner follows a curved path in
horizontal plane. The control law enables the runner to change the placement
and the elasticity of its legs to move in a desired direction. Stable motion
along a curved path is achieved using curvature, bearing and relative distance
between the runner and the curve as feedback. Constraints on leg parameters
determine the class of curves that can be followed. We also derive an optimal
control law that stabilizes the orientation of the runner's body relative to
the velocity of the runner's center of mass.
"
0701042,Sending a Bivariate Gaussian Source over a Gaussian MAC with Feedback,"  We consider the problem of transmitting a bivariate Gaussian source over a
two-user additive Gaussian multiple-access channel with feedback. Each of the
transmitters observes one of the source components and tries to describe it to
the common receiver. We are interested in the minimal mean squared error at
which the receiver can reconstruct each of the source components.
  In the ``symmetric case'' we show that, below a certain signal-to-noise ratio
threshold which is determined by the source correlation, feedback is useless
and the minimal distortion is achieved by uncoded transmission. For the general
case we give necessary conditions for the achievability of a distortion pair.
"
0701045,Polygon Convexity: Another O(n) Test,"  An n-gon is defined as a sequence \P=(V_0,...,V_{n-1}) of n points on the
plane. An n-gon \P is said to be convex if the boundary of the convex hull of
the set {V_0,...,V_{n-1}} of the vertices of \P coincides with the union of the
edges [V_0,V_1],...,[V_{n-1},V_0]; if at that no three vertices of \P are
collinear then \P is called strictly convex. We prove that an n-gon \P with
n\ge3 is strictly convex if and only if a cyclic shift of the sequence
(\al_0,...,\al_{n-1})\in[0,2\pi)^n of the angles between the x-axis and the
vectors V_1-V_0,...,V_0-V_{n-1} is strictly monotone. A ``non-strict'' version
of this result is also proved.
"
0701050,"A Simple Proof of the Entropy-Power Inequality via Properties of Mutual
  Information","  While most useful information theoretic inequalities can be deduced from the
basic properties of entropy or mutual information, Shannon's entropy power
inequality (EPI) seems to be an exception: available information theoretic
proofs of the EPI hinge on integral representations of differential entropy
using either Fisher's information (FI) or minimum mean-square error (MMSE). In
this paper, we first present a unified view of proofs via FI and MMSE, showing
that they are essentially dual versions of the same proof, and then fill the
gap by providing a new, simple proof of the EPI, which is solely based on the
properties of mutual information and sidesteps both FI or MMSE representations.
"
0701053,"A Case For Amplify-Forward Relaying in the Block-Fading Multi-Access
  Channel","  This paper demonstrates the significant gains that multi-access users can
achieve from sharing a single amplify-forward relay in slow fading
environments. The proposed protocol, namely the multi-access relay
amplify-forward, allows for a low-complexity relay and achieves the optimal
diversity-multiplexing trade-off at high multiplexing gains. Analysis of the
protocol reveals that it uniformly dominates the compress-forward strategy and
further outperforms the dynamic decode-forward protocol at high multiplexing
gains. An interesting feature of the proposed protocol is that, at high
multiplexing gains, it resembles a multiple-input single-output system, and at
low multiplexing gains, it provides each user with the same
diversity-multiplexing trade-off as if there is no contention for the relay
from the other users.
"
0701054,"Nearly-Exponential Size Lower Bounds for Symbolic Quantifier Elimination
  Algorithms and OBDD-Based Proofs of Unsatisfiability","  We demonstrate a family of propositional formulas in conjunctive normal form
so that a formula of size $N$ requires size $2^{\Omega(\sqrt[7]{N/logN})}$ to
refute using the tree-like OBDD refutation system of Atserias, Kolaitis and
Vardi with respect to all variable orderings. All known symbolic quantifier
elimination algorithms for satisfiability generate tree-like proofs when run on
unsatisfiable CNFs, so this lower bound applies to the run-times of these
algorithms. Furthermore, the lower bound generalizes earlier results on
OBDD-based proofs of unsatisfiability in that it applies for all variable
orderings, it applies when the clauses are processed according to an arbitrary
schedule, and it applies when variables are eliminated via quantification.
"
0701063,"Hierarchical Decoupling Principle of a MIMO-CDMA Channel in Asymptotic
  Limits","  We analyze an uplink of a fast flat fading MIMO-CDMA channel in the case
where the data symbol vector for each user follows an arbitrary distribution.
The spectral efficiency of the channel with CSI at the receiver is evaluated
analytically with the replica method. The main result is that the hierarchical
decoupling principle holds in the MIMO-CDMA channel, i.e., the MIMO-CDMA
channel is decoupled into a bank of single-user MIMO channels in the many-user
limit, and each single-user MIMO channel is further decoupled into a bank of
scalar Gaussian channels in the many-antenna limit for a fading model with a
limited number of scatterers.
"
0701065,"Can Punctured Rate-1/2 Turbo Codes Achieve a Lower Error Floor than
  their Rate-1/3 Parent Codes?","  In this paper we concentrate on rate-1/3 systematic parallel concatenated
convolutional codes and their rate-1/2 punctured child codes. Assuming
maximum-likelihood decoding over an additive white Gaussian channel, we
demonstrate that a rate-1/2 non-systematic child code can exhibit a lower error
floor than that of its rate-1/3 parent code, if a particular condition is met.
However, assuming iterative decoding, convergence of the non-systematic code
towards low bit-error rates is problematic. To alleviate this problem, we
propose rate-1/2 partially-systematic codes that can still achieve a lower
error floor than that of their rate-1/3 parent codes. Results obtained from
extrinsic information transfer charts and simulations support our conclusion.
"
0701075,"Open-architecture Implementation of Fragment Molecular Orbital Method
  for Peta-scale Computing","  We present our perspective and goals on highperformance computing for
nanoscience in accordance with the global trend toward ""peta-scale computing.""
After reviewing our results obtained through the grid-enabled version of the
fragment molecular orbital method (FMO) on the grid testbed by the Japanese
Grid Project, National Research Grid Initiative (NAREGI), we show that FMO is
one of the best candidates for peta-scale applications by predicting its
effective performance in peta-scale computers. Finally, we introduce our new
project constructing a peta-scale application in an open-architecture
implementation of FMO in order to realize both goals of highperformance in
peta-scale computers and extendibility to multiphysics simulations.
"
0701078,Low SNR Capacity of Fading Channels -- MIMO and Delay Spread,"  Discrete-time Rayleigh fading multiple-input multiple-output (MIMO) channels
are considered, with no channel state information at the transmitter and
receiver. The fading is assumed to be correlated in time and independent from
antenna to antenna. Peak and average transmit power constraints are imposed,
either on the sum over antennas, or on each individual antenna. In both cases,
an upper bound and an asymptotic lower bound, as the signal-to-noise ratio
approaches zero, on the channel capacity are presented. The limit of normalized
capacity is identified under the sum power constraints, and, for a subclass of
channels, for individual power constraints. These results carry over to a SISO
channel with delay spread (i.e. frequency selective fading).
"
0701083,A Backtracking-Based Algorithm for Computing Hypertree-Decompositions,"  Hypertree decompositions of hypergraphs are a generalization of tree
decompositions of graphs. The corresponding hypertree-width is a measure for
the cyclicity and therefore tractability of the encoded computation problem.
Many NP-hard decision and computation problems are known to be tractable on
instances whose structure corresponds to hypergraphs of bounded
hypertree-width. Intuitively, the smaller the hypertree-width, the faster the
computation problem can be solved. In this paper, we present the new
backtracking-based algorithm det-k-decomp for computing hypertree
decompositions of small width. Our benchmark evaluations have shown that
det-k-decomp significantly outperforms opt-k-decomp, the only exact hypertree
decomposition algorithm so far. Even compared to the best heuristic algorithm,
we obtained competitive results as long as the hypergraphs are not too large.
"
0701090,"Ergodic Capacity of Discrete- and Continuous-Time, Frequency-Selective
  Rayleigh Fading Channels with Correlated Scattering","  We study the ergodic capacity of a frequency-selective Rayleigh fading
channel with correlated scattering, which finds application in the area of UWB.
Under an average power constraint, we consider a single-user, single-antenna
transmission. Coherent reception is assumed with full CSI at the receiver and
no CSI at the transmitter. We distinguish between a continuous- and a
discrete-time channel, modeled either as random process or random vector with
generic covariance. As a practically relevant example, we examine an
exponentially attenuated Ornstein-Uhlenbeck process in detail. Finally, we give
numerical results, discuss the relation between the continuous- and the
discrete-time channel model and show the significant impact of correlated
scattering.
"
0701118,"Optimal Order of Decoding for Max-Min Fairness in $K$-User Memoryless
  Interference Channels","  A $K$-user memoryless interference channel is considered where each receiver
sequentially decodes the data of a subset of transmitters before it decodes the
data of the designated transmitter. Therefore, the data rate of each
transmitter depends on (i) the subset of receivers which decode the data of
that transmitter, (ii) the decoding order, employed at each of these receivers.
In this paper, a greedy algorithm is developed to find the users which are
decoded at each receiver and the corresponding decoding order such that the
minimum rate of the users is maximized. It is proven that the proposed
algorithm is optimal.
"
0701120,Algorithmic Complexity Bounds on Future Prediction Errors,"  We bound the future loss when predicting any (computably) stochastic sequence
online. Solomonoff finitely bounded the total deviation of his universal
predictor $M$ from the true distribution $mu$ by the algorithmic complexity of
$mu$. Here we assume we are at a time $t>1$ and already observed $x=x_1...x_t$.
We bound the future prediction performance on $x_{t+1}x_{t+2}...$ by a new
variant of algorithmic complexity of $mu$ given $x$, plus the complexity of the
randomness deficiency of $x$. The new complexity is monotone in its condition
in the sense that this complexity can only decrease if the condition is
prolonged. We also briefly discuss potential generalizations to Bayesian model
classes and to classification problems.
"
0701129,"Space-time codes with controllable ML decoding complexity for any number
  of transmit antennas","  We construct a class of linear space-time block codes for any number of
transmit antennas that have controllable ML decoding complexity with a maximum
rate of 1 symbol per channel use. The decoding complexity for $M$ transmit
antennas can be varied from ML decoding of $2^{\lceil \log_2M \rceil -1}$
symbols together to single symbol ML decoding. For ML decoding of $2^{\lceil
\log_2M \rceil - n}$ ($n=1,2,...$) symbols together, a diversity of
$\min(M,2^{\lceil \log_2M \rceil-n+1})$ can be achieved. Numerical results show
that the performance of the constructed code when $2^{\lceil \log_2M \rceil-1}$
symbols are decoded together is quite close to the performance of ideal rate-1
orthogonal codes (that are non-existent for more than 2 transmit antennas).
"
0701134,Byzantine Fault Tolerance for Nondeterministic Applications,"  All practical applications contain some degree of nondeterminism. When such
applications are replicated to achieve Byzantine fault tolerance (BFT), their
nondeterministic operations must be controlled to ensure replica consistency.
To the best of our knowledge, only the most simplistic types of replica
nondeterminism have been dealt with. Furthermore, there lacks a systematic
approach to handling common types of nondeterminism. In this paper, we propose
a classification of common types of replica nondeterminism with respect to the
requirement of achieving Byzantine fault tolerance, and describe the design and
implementation of the core mechanisms necessary to handle such nondeterminism
within a Byzantine fault tolerance framework.
"
0701139,Time and the Prisoner's Dilemma,"  This paper examines the integration of computational complexity into game
theoretic models. The example focused on is the Prisoner's Dilemma, repeated
for a finite length of time. We show that a minimal bound on the players'
computational ability is sufficient to enable cooperative behavior.
  In addition, a variant of the repeated Prisoner's Dilemma game is suggested,
in which players have the choice of opting out. This modification enriches the
game and suggests dominance of cooperative strategies.
  Competitive analysis is suggested as a tool for investigating sub-optimal
(but computationally tractable) strategies and game theoretic models in
general. Using competitive analysis, it is shown that for bounded players, a
sub-optimal strategy might be the optimal choice, given resource limitations.
"
0701144,Trusted Ticket Systems and Applications,"  Trusted Computing is a security base technology that will perhaps be
ubiquitous in a few years in personal computers and mobile devices alike.
Despite its neutrality with respect to applications, it has raised some privacy
concerns. We show that trusted computing can be applied for service access
control in a manner protecting users' privacy. We construct a ticket system --
a concept which is at the heart of Identity Management -- relying solely on the
capabilities of the trusted platform module and the standards specified by the
Trusted Computing Group. Two examples show how it can be used for pseudonymous
and protected service access.
"
0701146,State constraints and list decoding for the AVC,"  List decoding for arbitrarily varying channels (AVCs) under state constraints
is investigated. It is shown that rates within $\epsilon$ of the randomized
coding capacity of AVCs with input-dependent state can be achieved under
maximal error with list decoding using lists of size $O(1/\epsilon)$. Under
average error an achievable rate region and converse bound are given for lists
of size $L$. These bounds are based on two different notions of
symmetrizability and do not coincide in general. An example is given that shows
that for list size $L$ the capacity may be positive but strictly smaller than
the randomized coding capacity. This behavior is different than the situation
without state constraints.
"
0701147,A Generic Analysis Environment for Curry Programs,"  We present CurryBrowser, a generic analysis environment for the declarative
multi-paradigm language Curry. CurryBrowser supports browsing through the
program code of an application written in Curry, i.e., the main module and all
directly or indirectly imported modules. Each module can be shown in different
formats (e.g., source code, interface, intermediate code) and, inside each
module, various properties of functions defined in this module can be analyzed.
In order to support the integration of various program analyses, CurryBrowser
has a generic interface to connect local and global analyses implemented in
Curry. CurryBrowser is completely implemented in Curry using libraries for GUI
programming and meta-programming.
"
0702005,"An empirical study of software reuse by experts in object-oriented
  design","  This paper presents an empirical study of the software reuse activity by
expert designers in the context of object-oriented design. Our study focuses on
the three following aspects of reuse : (1) the interaction between some design
processes, e.g. constructing a problem representation, searching for and
evaluating solutions, and reuse processes, i.e. retrieving and using previous
solutions, (2) the mental processes involved in reuse, e.g. example-based
retrieval or bottom-up versus top-down expanding of the solution, and (3) the
mental representations constructed throughout the reuse activity, e.g. dynamic
versus static representations. Some implications of these results for the
specification of software reuse support environments are discussed.
"
0702019,A Dynamic I/O Model for TRACON Traffic Management,"  This work investigates the TRACON flow management around a major airport.
Aircraft flows are analyzed through a study of TRACON trajectories records.
Rerouting and queuing processes are highlighted and airport characteristics are
shown as function of the number of planes in the TRACON. Then, a simple
input-output TRACON queuing and landing model is proposed. This model is
calibrated and validated using available TRACON data. It reproduces the same
phenomenon as the real system. This model is used to show the impact of
limiting the number of aircrafts in the TRACON. A limited number of aircraft
does not increase delays but reduces the controller's workload and increases
safety.
"
0702052,On Random Network Coding for Multicast,"  Random linear network coding is a particularly decentralized approach to the
multicast problem. Use of random network codes introduces a non-zero
probability however that some sinks will not be able to successfully decode the
required sources. One of the main theoretical motivations for random network
codes stems from the lower bound on the probability of successful decoding
reported by Ho et. al. (2003). This result demonstrates that all sinks in a
linearly solvable network can successfully decode all sources provided that the
random code field size is large enough. This paper develops a new bound on the
probability of successful decoding.
"
0702066,"Comments on ""Design and performance evaluation of load distribution
  strategies for multiple loads on heterogeneous linear daisy chain networks''","  Min, Veeravalli, and Barlas proposed strategies to minimize the overall
execution time of one or several divisible loads on a heterogeneous linear
network, using one or more installments. We show on a very simple example that
the proposed approach does not always produce a solution and that, when it
does, the solution is often suboptimal. We also show how to find an optimal
scheduling for any instance, once the number of installments per load is given.
Finally, we formally prove that under a linear cost model, as in the original
paper, an optimal schedule has an infinite number of installments. Such a cost
model can therefore not be sed to design practical multi-installment
strategies.
"
0702074,Dynamic Random Geometric Graphs,"  In this work we introduce Dynamic Random Geometric Graphs as a basic rough
model for mobile wireless sensor networks, where communication distances are
set to the known threshold for connectivity of static random geometric graphs.
We provide precise asymptotic results for the expected length of the
connectivity and disconnectivity periods of the network. We believe the formal
tools developed in this work could be of use in future studies in more concrete
settings. In addition, for static random geometric graphs at the threshold for
connectivity, we provide asymptotic expressions on the probability of existence
of components according to their sizes.
"
0702076,A First Step Towards Automatically Building Network Representations,"  To fully harness Grids, users or middlewares must have some knowledge on the
topology of the platform interconnection network. As such knowledge is usually
not available, one must uses tools which automatically build a topological
network model through some measurements. In this article, we define a
methodology to assess the quality of these network model building tools, and we
apply this methodology to representatives of the main classes of model builders
and to two new algorithms. We show that none of the main existing techniques
build models that enable to accurately predict the running time of simple
application kernels for actual platforms. However some of the new algorithms we
propose give excellent results in a wide range of situations.
"
0702078,A Local Algorithm for Finding Dense Subgraphs,"  We present a local algorithm for finding dense subgraphs of bipartite graphs,
according to the definition of density proposed by Kannan and Vinay. Our
algorithm takes as input a bipartite graph with a specified starting vertex,
and attempts to find a dense subgraph near that vertex. We prove that for any
subgraph S with k vertices and density theta, there are a significant number of
starting vertices within S for which our algorithm produces a subgraph S' with
density theta / O(log n) on at most O(D k^2) vertices, where D is the maximum
degree. The running time of the algorithm is O(D k^2), independent of the
number of vertices in the graph.
"
0702100,A Class of Multi-Channel Cosine Modulated IIR Filter Banks,"  This paper presents a class of multi-channel cosine-modulated filter banks
satisfying the perfect reconstruction (PR) property using an IIR prototype
filter. By imposing a suitable structure on the polyphase filter coefficients,
we show that it is possible to greatly simplify the PR condition, while
preserving the causality and stability of the system. We derive closed-form
expressions for the synthesis filters and also study the numerical stability of
the filter bank using frame theoretic bounds. Further, we show that it is
possible to implement this filter bank with much lower number of arithmetic
operations when compared to FIR filter banks with comparable performance. The
filter bank's modular structure also lends itself to efficient VLSI
implementation.
"
0702110,"Security Implications of Converged Networks and Protecting Them, without
  Compromising Efficiency","  This dissertation has extensively looked into all aspects of VoIP
commu-nications technology, and information presented in preceding chapters,
which build up a solid framework to discuss the conceptual design model, and
investigate features that could be incorporated for actual Pro-jects, with
parameters that are tested on field values. The dissertation follows a
five-course model, for answering different questions, both tech-nical and
businesslike, around central issues, that have been crucial to explanation of
the topic; starting with a general overview of VoIP tech-nology, analyzing
current VoIP encryption methods, identifying security threats, designing a
robust VoIP system based on particulars discussed in preceding chapters, and
finally, a VoIP simulation.
"
0702115,Guessing based on length functions,"  A guessing wiretapper's performance on a Shannon cipher system is analyzed
for a source with memory. Close relationships between guessing functions and
length functions are first established. Subsequently, asymptotically optimal
encryption and attack strategies are identified and their performances analyzed
for sources with memory. The performance metrics are exponents of guessing
moments and probability of large deviations. The metrics are then characterized
for unifilar sources. Universal asymptotically optimal encryption and attack
strategies are also identified for unifilar sources. Guessing in the increasing
order of Lempel-Ziv coding lengths is proposed for finite-state sources, and
shown to be asymptotically optimal. Finally, competitive optimality properties
of guessing in the increasing order of description lengths and Lempel-Ziv
coding lengths are demonstrated.
"
0702117,"On a family of strong geometric spanners that admit local routing
  strategies","  We introduce a family of directed geometric graphs, denoted $\paz$, that
depend on two parameters $\lambda$ and $\theta$. For $0\leq
\theta<\frac{\pi}{2}$ and ${1/2} < \lambda < 1$, the $\paz$ graph is a strong
$t$-spanner, with $t=\frac{1}{(1-\lambda)\cos\theta}$. The out-degree of a node
in the $\paz$ graph is at most $\lfloor2\pi/\min(\theta,
\arccos\frac{1}{2\lambda})\rfloor$. Moreover, we show that routing can be
achieved locally on $\paz$. Next, we show that all strong $t$-spanners are also
$t$-spanners of the unit disk graph. Simulations for various values of the
parameters $\lambda$ and $\theta$ indicate that for random point sets, the
spanning ratio of $\paz$ is better than the proven theoretical bounds.
"
0702120,"On the decidability and complexity of Metric Temporal Logic over finite
  words","  Metric Temporal Logic (MTL) is a prominent specification formalism for
real-time systems. In this paper, we show that the satisfiability problem for
MTL over finite timed words is decidable, with non-primitive recursive
complexity. We also consider the model-checking problem for MTL: whether all
words accepted by a given Alur-Dill timed automaton satisfy a given MTL
formula. We show that this problem is decidable over finite words. Over
infinite words, we show that model checking the safety fragment of MTL--which
includes invariance and time-bounded response properties--is also decidable.
These results are quite surprising in that they contradict various claims to
the contrary that have appeared in the literature.
"
0702138,"On the Maximal Diversity Order of Spatial Multiplexing with Transmit
  Antenna Selection","  Zhang et. al. recently derived upper and lower bounds on the achievable
diversity of an N_R x N_T i.i.d. Rayleigh fading multiple antenna system using
transmit antenna selection, spatial multiplexing and a linear receiver
structure. For the case of L = 2 transmitting (out of N_T available) antennas
the bounds are tight and therefore specify the maximal diversity order. For the
general case with L <= min(N_R,N_T) transmitting antennas it was conjectured
that the maximal diversity is (N_T-L+1)(N_R-L+1) which coincides with the lower
bound. Herein, we prove this conjecture for the zero forcing and zero forcing
decision feedback (with optimal detection ordering) receiver structures.
"
0702140,Assessing the Value of Coooperation in Wikipedia,"  Since its inception six years ago, the online encyclopedia Wikipedia has
accumulated 6.40 million articles and 250 million edits, contributed in a
predominantly undirected and haphazard fashion by 5.77 million unvetted
volunteers. Despite the apparent lack of order, the 50 million edits by 4.8
million contributors to the 1.5 million articles in the English-language
Wikipedia follow strong certain overall regularities. We show that the
accretion of edits to an article is described by a simple stochastic mechanism,
resulting in a heavy tail of highly visible articles with a large number of
edits. We also demonstrate a crucial correlation between article quality and
number of edits, which validates Wikipedia as a successful collaborative
effort.
"
0702153,Games on the Sperner Triangle,"  We create a new two-player game on the Sperner Triangle based on Sperner's
lemma. Our game has simple rules and several desirable properties. First, the
game is always certain to have a winner. Second, like many other interesting
games such as Hex and Geography, we prove that deciding whether one can win our
game is a PSPACE-complete problem. Third, there is an elegant balance in the
game such that neither the first nor the second player always has a decisive
advantage. We provide a web-based version of the game, playable at:
http://cs-people.bu.edu/paithan/spernerGame/ . In addition we propose other
games, also based on fixed-point theorems.
"
0702167,"Finite Volume Analysis of Nonlinear Thermo-mechanical Dynamics of Shape
  Memory Alloys","  In this paper, the finite volume method is developed to analyze coupled
dynamic problems of nonlinear thermoelasticity. The major focus is given to the
description of martensitic phase transformations essential in the modelling of
shape memory alloys. Computational experiments are carried out to study the
thermo-mechanical wave interactions in a shape memory alloy rod, and a patch.
Both mechanically and thermally induced phase transformations, as well as
hysteresis effects, in a one-dimensional structure are successfully simulated
with the developed methodology. In the two-dimensional case, the main focus is
given to square-to-rectangular transformations and examples of martensitic
combinations under different mechanical loadings are provided.
"
0702172,"Numerical Model For Vibration Damping Resulting From the First Order
  Phase Transformations","  A numerical model is constructed for modelling macroscale damping effects
induced by the first order martensite phase transformations in a shape memory
alloy rod. The model is constructed on the basis of the modified
Landau-Ginzburg theory that couples nonlinear mechanical and thermal fields.
The free energy function for the model is constructed as a double well function
at low temperature, such that the external energy can be absorbed during the
phase transformation and converted into thermal form. The Chebyshev spectral
methods are employed together with backward differentiation for the numerical
analysis of the problem. Computational experiments performed for different
vibration energies demonstrate the importance of taking into account damping
effects induced by phase transformations.
"
0703003,Functions to Support Input and Output of Intervals,"  Interval arithmetic is hardly feasible without directed rounding as provided,
for example, by the IEEE floating-point standard. Equally essential for
interval methods is directed rounding for conversion between the external
decimal and internal binary numerals. This is not provided by the standard I/O
libraries. Conversion algorithms exist that guarantee identity upon conversion
followed by its inverse. Although it may be possible to adapt these algorithms
for use in decimal interval I/O, we argue that outward rounding in radix
conversion is computationally a simpler problem than guaranteeing identity.
Hence it is preferable to develop decimal interval I/O ab initio, which is what
we do in this paper.
"
0703024,Algorithmic Information Theory: a brief non-technical guide to the field,"  This article is a brief guide to the field of algorithmic information theory
(AIT), its underlying philosophy, and the most important concepts. AIT arises
by mixing information theory and computation theory to obtain an objective and
absolute notion of information in an individual object, and in so doing gives
rise to an objective and robust notion of randomness of individual objects.
This is in contrast to classical information theory that is based on random
variables and communication, and has no bearing on information and randomness
of individual objects. After a brief overview, the major subfields,
applications, history, and a map of the field are presented.
"
0703025,"LIBOPT - An environment for testing solvers on heterogeneous collections
  of problems - Version 1.0","  The Libopt environment is both a methodology and a set of tools that can be
used for testing, comparing, and profiling solvers on problems belonging to
various collections. These collections can be heterogeneous in the sense that
their problems can have common features that differ from one collection to the
other. Libopt brings a unified view on this composite world by offering, for
example, the possibility to run any solver on any problem compatible with it,
using the same Unix/Linux command. The environment also provides tools for
comparing the results obtained by solvers on a specified set of problems. Most
of the scripts going with the Libopt environment have been written in Perl.
"
0703039,Transforming structures by set interpretations,"  We consider a new kind of interpretation over relational structures: finite
sets interpretations. Those interpretations are defined by weak monadic
second-order (WMSO) formulas with free set variables. They transform a given
structure into a structure with a domain consisting of finite sets of elements
of the orignal structure. The definition of these interpretations directly
implies that they send structures with a decidable WMSO theory to structures
with a decidable first-order theory. In this paper, we investigate the
expressive power of such interpretations applied to infinite deterministic
trees. The results can be used in the study of automatic and tree-automatic
structures.
"
0703040,Why the Standard Data Processing should be changed,"  The basic statistical methods of data representation did not change since
their emergence. Their simplicity was dictated by the intricacies of
computations in the before computers epoch. It turns out that such approach is
not uniquely possible in the presence of quick computers. The suggested here
method improves significantly the reliability of data processing and their
graphical representation. In this paper we show problems of the standard data
processing which can bring to incorrect results. A method solving these
problems is proposed. It is based on modification of data representation. The
method was implemented in a computer program Consensus5. The program
performances are illustrated through varied examples.
"
0703048,Path Loss Models Based on Stochastic Rays,"  In this paper, two-dimensional percolation lattices are applied to describe
wireless propagation environment, and stochastic rays are employed to model the
trajectories of radio waves. We first derive the probability that a stochastic
ray undergoes certain number of collisions at a specific spatial location.
Three classes of stochastic rays with different constraint conditions are
considered: stochastic rays of random walks, and generic stochastic rays with
two different anomalous levels. Subsequently, we obtain the closed-form
formulation of mean received power of radio waves under non line-of-sight
conditions for each class of stochastic ray. Specifically, the determination of
model parameters and the effects of lattice structures on the path loss are
investigated. The theoretical results are validated by comparison with
experimental data.
"
0703057,Doppler Resilient Waveforms with Perfect Autocorrelation,"  We describe a method of constructing a sequence of phase coded waveforms with
perfect autocorrelation in the presence of Doppler shift. The constituent
waveforms are Golay complementary pairs which have perfect autocorrelation at
zero Doppler but are sensitive to nonzero Doppler shifts. We extend this
construction to multiple dimensions, in particular to radar polarimetry, where
the two dimensions are realized by orthogonal polarizations. Here we determine
a sequence of two-by-two Alamouti matrices where the entries involve Golay
pairs and for which the sum of the matrix-valued ambiguity functions vanish at
small Doppler shifts. The Prouhet-Thue-Morse sequence plays a key role in the
construction of Doppler resilient sequences of Golay pairs.
"
0703058,"A Comparison of Five Probabilistic View-Size Estimation Techniques in
  OLAP","  A data warehouse cannot materialize all possible views, hence we must
estimate quickly, accurately, and reliably the size of views to determine the
best candidates for materialization. Many available techniques for view-size
estimation make particular statistical assumptions and their error can be
large. Comparatively, unassuming probabilistic techniques are slower, but they
estimate accurately and reliability very large view sizes using little memory.
We compare five unassuming hashing-based view-size estimation techniques
including Stochastic Probabilistic Counting and LogLog Probabilistic Counting.
Our experiments show that only Generalized Counting, Gibbons-Tirthapura, and
Adaptive Counting provide universally tight estimates irrespective of the size
of the view; of those, only Adaptive Counting remains constantly fast as we
increase the memory budget.
"
0703071,Automatic Annotation of XHTML Pages with Audio Components,"  In this paper we present Deiush, a multimodal system for browsing hypertext
Web documents. The Deiush system is based on our novel approach to
automatically annotate hypertext Web documents (i.e. XHTML pages) with
browsable audio components. It combines two key technologies: (1) middleware
automatic separation of Web documents through structural and semantic analysis
which is annotated with audio components, transforming them into XHTML+VoiceXML
format to represent multimodal dialog; and (2) Opera Browser, an already
standardized browser which we adopt as an interface of the XHTML+VoiceXML
output of annotating. This paper describes the annotation technology of Deiush
and presents an initial system evaluation.
"
0703084,The Octagon Abstract Domain,"  This article presents a new numerical abstract domain for static analysis by
abstract interpretation. It extends a former numerical abstract domain based on
Difference-Bound Matrices and allows us to represent invariants of the form
(+/-x+/-y<=c), where x and y are program variables and c is a real constant. We
focus on giving an efficient representation based on Difference-Bound Matrices
- O(n2) memory cost, where n is the number of variables - and graph-based
algorithms for all common abstract operators - O(n3) time cost. This includes a
normal form algorithm to test equivalence of representation and a widening
operator to compute least fixpoint approximations.
"
0703106,"Practical Identity-Based Encryption (IBE) in Multiple PKG Environments
  and Its Applications","  In this paper, we present a new identity-based encryption (IBE) scheme using
bilinear pairings. Our IBE scheme enjoys the same \textsf{Key Extraction} and
\textsf{Decryption} algorithms with the famous IBE scheme of Boneh and Franklin
(BF-IBE for short), while differs from the latter in that it has modified
\textsf{Setup} and \textsf{Encryption} algorithms.
  Compared with BF-IBE, we show that ours are more practical in a multiple
private key generator (PKG) environment, mainly due to that the session secret
$g_{ID}$ could be pre-computed \emph{before} any interaction, and the sender
could encrypt a message using $g_{ID}$ prior to negotiating with the intended
recipient(s). As an application of our IBE scheme, we also derive an escrowed
ElGamal scheme which possesses certain good properties in practice.
"
0703108,"Wireless Lan to Support Multimedia Communication Using Spread Spectrum
  Technology","  Wireless LAN is currently enjoying rapid deployment in University
departments, business offices, hospitals and homes. It becomes an inexpensive
technology and allows multiple numbers of the households to simultaneously
access the internet while roaming about the house. In the present work, the
design and development of a wireless LAN is highlighted which utilizes direct
sequence spread spectrum (DSSS) technology at 900MHz RF carrier frequency in
its physical layer. This provides enormous security in the physical layer and
hence it is very difficult to hack or jam the network. The installation cost is
also less due to the use of 900 MHz RF carrier frequency..
"
0703117,"Self-adaptive Gossip Policies for Distributed Population-based
  Algorithms","  Gossipping has demonstrate to be an efficient mechanism for spreading
information among P2P networks. Within the context of P2P computing, we propose
the so-called Evolvable Agent Model for distributed population-based algorithms
which uses gossipping as communication policy, and represents every individual
as a self-scheduled single thread. The model avoids obsolete nodes in the
population by defining a self-adaptive refresh rate which depends on the
latency and bandwidth of the network. Such a mechanism balances the migration
rate to the congestion of the links pursuing global population coherence. We
perform an experimental evaluation of this model on a real parallel system and
observe how solution quality and algorithm speed scale with the number of
processors with this seamless approach.
"
0703119,Support-Graph Preconditioners for 2-Dimensional Trusses,"  We use support theory, in particular the fretsaw extensions of Shklarski and
Toledo, to design preconditioners for the stiffness matrices of 2-dimensional
truss structures that are stiffly connected. Provided that all the lengths of
the trusses are within constant factors of each other, that the angles at the
corners of the triangles are bounded away from 0 and $\pi$, and that the
elastic moduli and cross-sectional areas of all the truss elements are within
constant factors of each other, our preconditioners allow us to solve linear
equations in the stiffness matrices to accuracy $\epsilon$ in time $O (n^{5/4}
(\log^{2}n \log \log n)^{3/4} \log (1/\epsilon))$.
"
0703121,Differential Equations for Algebraic Functions,"  It is classical that univariate algebraic functions satisfy linear
differential equations with polynomial coefficients. Linear recurrences follow
for the coefficients of their power series expansions. We show that the linear
differential equation of minimal order has coefficients whose degree is cubic
in the degree of the function. We also show that there exists a linear
differential equation of order linear in the degree whose coefficients are only
of quadratic degree. Furthermore, we prove the existence of recurrences of
order and degree close to optimal. We study the complexity of computing these
differential equations and recurrences. We deduce a fast algorithm for the
expansion of algebraic series.
"
0703140,How to Guarantee Secrecy for Cryptographic Protocols,"  In this paper we propose a general definition of secrecy for cryptographic
protocols in the Dolev-Yao model. We give a sufficient condition ensuring
secrecy for protocols where rules have encryption depth at most two, that is
satisfied by almost all practical protocols. The only allowed primitives in the
class of protocols we consider are pairing and encryption with atomic keys.
Moreover, we describe an algorithm of practical interest which transforms a
cryptographic protocol into a secure one from the point of view of secrecy,
without changing its original goal with respect to secrecy of nonces and keys,
provided the protocol satisfies some conditions. These conditions are not very
restrictive and are satisfied for most practical protocols.
"
0703156,Case Base Mining for Adaptation Knowledge Acquisition,"  In case-based reasoning, the adaptation of a source case in order to solve
the target problem is at the same time crucial and difficult to implement. The
reason for this difficulty is that, in general, adaptation strongly depends on
domain-dependent knowledge. This fact motivates research on adaptation
knowledge acquisition (AKA). This paper presents an approach to AKA based on
the principles and techniques of knowledge discovery from databases and
data-mining. It is implemented in CABAMAKA, a system that explores the
variations within the case base to elicit adaptation knowledge. This system has
been successfully tested in an application of case-based reasoning to decision
support in the domain of breast cancer treatment.
"
9301101,Verifying the Unification Algorithm in LCF,"  Manna and Waldinger's theory of substitutions and unification has been
verified using the Cambridge LCF theorem prover. A proof of the monotonicity of
substitution is presented in detail, as an example of interaction with LCF.
Translating the theory into LCF's domain-theoretic logic is largely
straightforward. Well-founded induction on a complex ordering is translated
into nested structural inductions. Correctness of unification is expressed
using predicates for such properties as idempotence and most-generality. The
verification is presented as a series of lemmas. The LCF proofs are compared
with the original ones, and with other approaches. It appears difficult to find
a logic that is both simple and flexible, especially for proving termination.
"
9301102,Constructing Recursion Operators in Intuitionistic Type Theory,"  Martin-L\""of's Intuitionistic Theory of Types is becoming popular for formal
reasoning about computer programs. To handle recursion schemes other than
primitive recursion, a theory of well-founded relations is presented. Using
primitive recursion over higher types, induction and recursion are formally
derived for a large class of well-founded relations. Included are < on natural
numbers, and relations formed by inverse images, addition, multiplication, and
exponentiation of other relations. The constructions are given in full detail
to allow their use in theorem provers for Type Theory, such as Nuprl. The
theory is compared with work in the field of ordinal recursion over higher
types.
"
9301104,Natural Deduction as Higher-Order Resolution,"  An interactive theorem prover, Isabelle, is under development. In LCF, each
inference rule is represented by one function for forwards proof and another (a
tactic) for backwards proof. In Isabelle, each inference rule is represented by
a Horn clause. Resolution gives both forwards and backwards proof, supporting a
large class of logics. Isabelle has been used to prove theorems in
Martin-L\""of's Constructive Type Theory. Quantifiers pose several difficulties:
substitution, bound variables, Skolemization. Isabelle's representation of
logical syntax is the typed lambda-calculus, requiring higher- order
unification. It may have potential for logic programming. Depth-first
subgoaling along inference rules constitutes a higher-order Prolog.
"
9301105,The Foundation of a Generic Theorem Prover,"  Isabelle is an interactive theorem prover that supports a variety of logics.
It represents rules as propositions (not as functions) and builds proofs by
combining rules. These operations constitute a meta-logic (or `logical
framework') in which the object-logics are formalized. Isabelle is now based on
higher-order logic -- a precise and well-understood foundation. Examples
illustrate use of this meta-logic to formalize logics and proofs. Axioms for
first-order logic are shown sound and complete. Backwards proof is formalized
by meta-reasoning about object-level entailment. Higher-order logic has several
practical advantages over other meta-logics. Many proof techniques are known,
such as Huet's higher-order unification procedure.
"
9308102,"A Market-Oriented Programming Environment and its Application to
  Distributed Multicommodity Flow Problems","  Market price systems constitute a well-understood class of mechanisms that
under certain conditions provide effective decentralization of decision making
with minimal communication overhead. In a market-oriented programming approach
to distributed problem solving, we derive the activities and resource
allocations for a set of computational agents by computing the competitive
equilibrium of an artificial economy. WALRAS provides basic constructs for
defining computational market structures, and protocols for deriving their
corresponding price equilibria. In a particular realization of this approach
for a form of multicommodity flow problem, we see that careful construction of
the decision process according to economic principles can lead to efficient
distributed resource allocation, and that the behavior of the system can be
meaningfully analyzed in economic terms.
"
9311103,Set Theory for Verification: I. From Foundations to Functions,"  A logic for specification and verification is derived from the axioms of
Zermelo-Fraenkel set theory. The proofs are performed using the proof assistant
Isabelle. Isabelle is generic, supporting several different logics. Isabelle
has the flexibility to adapt to variants of set theory. Its higher-order syntax
supports the definition of new binding operators. Unknowns in subgoals can be
instantiated incrementally. The paper describes the derivation of rules for
descriptions, relations and functions, and discusses interactive proofs of
Cantor's Theorem, the Composition of Homomorphisms challenge [9], and Ramsey's
Theorem [5]. A generic proof assistant can stand up against provers dedicated
to particular logics.
"
9406101,"A Semantics and Complete Algorithm for Subsumption in the CLASSIC
  Description Logic","  This paper analyzes the correctness of the subsumption algorithm used in
CLASSIC, a description logic-based knowledge representation system that is
being used in practical applications. In order to deal efficiently with
individuals in CLASSIC descriptions, the developers have had to use an
algorithm that is incomplete with respect to the standard, model-theoretic
semantics for description logics. We provide a variant semantics for
descriptions with respect to which the current implementation is complete, and
which can be independently motivated. The soundness and completeness of the
polynomial-time subsumption algorithm is established using description graphs,
which are an abstracted version of the implementation structures used in
CLASSIC, and are of independent interest.
"
9408103,A System for Induction of Oblique Decision Trees,"  This article describes a new system for induction of oblique decision trees.
This system, OC1, combines deterministic hill-climbing with two forms of
randomization to find a good oblique split (in the form of a hyperplane) at
each node of a decision tree. Oblique decision tree methods are tuned
especially for domains in which the attributes are numeric, although they can
be adapted to symbolic or mixed symbolic/numeric attributes. We present
extensive empirical studies, using both real and artificial data, that analyze
OC1's ability to construct oblique trees that are smaller and more accurate
than their axis-parallel counterparts. We also examine the benefits of
randomization for the construction of oblique decision trees.
"
9409101,On Planning while Learning,"  This paper introduces a framework for Planning while Learning where an agent
is given a goal to achieve in an environment whose behavior is only partially
known to the agent. We discuss the tractability of various plan-design
processes. We show that for a large natural class of Planning while Learning
systems, a plan can be presented and verified in a reasonable time. However,
coming up algorithmically with a plan, even for simple classes of systems is
apparently intractable. We emphasize the role of off-line plan-design
processes, and show that, in most natural cases, the verification (projection)
part can be carried out in an efficient algorithmic manner.
"
9412103,Total-Order and Partial-Order Planning: A Comparative Analysis,"  For many years, the intuitions underlying partial-order planning were largely
taken for granted. Only in the past few years has there been renewed interest
in the fundamental principles underlying this paradigm. In this paper, we
present a rigorous comparative analysis of partial-order and total-order
planning by focusing on two specific planners that can be directly compared. We
show that there are some subtle assumptions that underly the wide-spread
intuitions regarding the supposed efficiency of partial-order planning. For
instance, the superiority of partial-order planning can depend critically upon
the search strategy and the structure of the search space. Understanding the
underlying assumptions is crucial for constructing efficient planners.
"
9505102,Adaptive Load Balancing: A Study in Multi-Agent Learning,"  We study the process of multi-agent reinforcement learning in the context of
load balancing in a distributed system, without use of either central
coordination or explicit communication. We first define a precise framework in
which to study adaptive load balancing, important features of which are its
stochastic nature and the purely local information available to individual
agents. Given this framework, we show illuminating results on the interplay
between basic adaptive behavior parameters and their effect on system
efficiency. We then investigate the properties of adaptive load balancing in
heterogeneous populations, and address the issue of exploration vs.
exploitation in that context. Finally, we show that naive use of communication
may not improve, and might even harm system efficiency.
"
9506102,"Induction of First-Order Decision Lists: Results on Learning the Past
  Tense of English Verbs","  This paper presents a method for inducing logic programs from examples that
learns a new class of concepts called first-order decision lists, defined as
ordered lists of clauses each ending in a cut. The method, called FOIDL, is
based on FOIL (Quinlan, 1990) but employs intensional background knowledge and
avoids the need for explicit negative examples. It is particularly useful for
problems that involve rules with specific exceptions, such as learning the
past-tense of English verbs, a task widely studied in the context of the
symbolic/connectionist debate. FOIDL is able to learn concise, accurate
programs for this problem from significantly fewer examples than previous
methods (both connectionist and symbolic).
"
9511103,A Concrete Final Coalgebra Theorem for ZF Set Theory,"  A special final coalgebra theorem, in the style of Aczel's, is proved within
standard Zermelo-Fraenkel set theory. Aczel's Anti-Foundation Axiom is replaced
by a variant definition of function that admits non-well-founded constructions.
Variant ordered pairs and tuples, of possibly infinite length, are special
cases of variant functions. Analogues of Aczel's Solution and Substitution
Lemmas are proved in the style of Rutten and Turi. The approach is less general
than Aczel's, but the treatment of non-well-founded objects is simple and
concrete. The final coalgebra of a functor is its greatest fixedpoint. The
theory is intended for machine implementation and a simple case of it is
already implemented using the theorem prover Isabelle.
"
9512102,"Vision-Based Road Detection in Automotive Systems: A Real-Time
  Expectation-Driven Approach","  The main aim of this work is the development of a vision-based road detection
system fast enough to cope with the difficult real-time constraints imposed by
moving vehicle applications. The hardware platform, a special-purpose massively
parallel system, has been chosen to minimize system production and operational
costs. This paper presents a novel approach to expectation-driven low-level
image segmentation, which can be mapped naturally onto mesh-connected massively
parallel SIMD architectures capable of handling hierarchical data structures.
The input image is assumed to contain a distorted version of a given template;
a multiresolution stretching process is used to reshape the original template
in accordance with the acquired image content, minimizing a potential function.
The distorted template is the process output.
"
9512104,Decision-Theoretic Foundations for Causal Reasoning,"  We present a definition of cause and effect in terms of decision-theoretic
primitives and thereby provide a principled foundation for causal reasoning.
Our definition departs from the traditional view of causation in that causal
assertions may vary with the set of decisions available. We argue that this
approach provides added clarity to the notion of cause. Also in this paper, we
examine the encoding of causal relationships in directed acyclic graphs. We
describe a special class of influence diagrams, those in canonical form, and
show its relationship to Pearl's representation of cause and effect. Finally,
we show how canonical form facilitates counterfactual reasoning.
"
9603101,Quantum Computing and Phase Transitions in Combinatorial Search,"  We introduce an algorithm for combinatorial search on quantum computers that
is capable of significantly concentrating amplitude into solutions for some NP
search problems, on average. This is done by exploiting the same aspects of
problem structure as used by classical backtrack methods to avoid unproductive
search choices. This quantum algorithm is much more likely to find solutions
than the simple direct use of quantum parallelism. Furthermore, empirical
evaluation on small problems shows this quantum algorithm displays the same
phase transition behavior, and at the same location, as seen in many previously
studied classical search methods. Specifically, difficult problem instances are
concentrated near the abrupt change from underconstrained to overconstrained
problems.
"
9603104,Active Learning with Statistical Models,"  For many types of machine learning algorithms, one can compute the
statistically `optimal' way to select training data. In this paper, we review
how optimal data selection techniques have been used with feedforward neural
networks. We then show how the same principles may be used to select data for
two alternative, statistically-based learning architectures: mixtures of
Gaussians and locally weighted regression. While the techniques for neural
networks are computationally expensive and approximate, the techniques for
mixtures of Gaussians and locally weighted regression are both efficient and
accurate. Empirically, we observe that the optimality criterion sharply
decreases the number of training examples the learner needs in order to achieve
good performance.
"
9605101,Further Experimental Evidence against the Utility of Occam's Razor,"  This paper presents new experimental evidence against the utility of Occam's
razor. A~systematic procedure is presented for post-processing decision trees
produced by C4.5. This procedure was derived by rejecting Occam's razor and
instead attending to the assumption that similar objects are likely to belong
to the same class. It increases a decision tree's complexity without altering
the performance of that tree on the training data from which it is inferred.
The resulting more complex decision trees are demonstrated to have, on average,
for a variety of common learning tasks, higher predictive accuracy than the
less complex original decision trees. This result raises considerable doubt
about the utility of Occam's razor as it is commonly applied in modern machine
learning.
"
9605104,"Adaptive Problem-solving for Large-scale Scheduling Problems: A Case
  Study","  Although most scheduling problems are NP-hard, domain specific techniques
perform well in practice but are quite expensive to construct. In adaptive
problem-solving solving, domain specific knowledge is acquired automatically
for a general problem solver with a flexible control architecture. In this
approach, a learning system explores a space of possible heuristic methods for
one well-suited to the eccentricities of the given domain and problem
distribution. In this article, we discuss an application of the approach to
scheduling satellite communications. Using problem distributions based on
actual mission requirements, our approach identifies strategies that not only
decrease the amount of CPU time required to produce schedules, but also
increase the percentage of problems that are solvable within computational
resource limitations.
"
9612104,Mechanizing Set Theory: Cardinal Arithmetic and the Axiom of Choice.,"  Fairly deep results of Zermelo-Frenkel (ZF) set theory have been mechanized
using the proof assistant Isabelle. The results concern cardinal arithmetic and
the Axiom of Choice (AC). A key result about cardinal multiplication is K*K =
K, where K is any infinite cardinal. Proving this result required developing
theories of orders, order-isomorphisms, order types, ordinal arithmetic,
cardinals, etc.; this covers most of Kunen, Set Theory, Chapter I. Furthermore,
we have proved the equivalence of 7 formulations of the Well-ordering Theorem
and 20 formulations of AC; this covers the first two chapters of Rubin and
Rubin, Equivalents of the Axiom of Choice, and involves highly technical
material. The definitions used in the proofs are largely faithful in style to
the original mathematics.
"
9704101,Lifeworld Analysis,"  We argue that the analysis of agent/environment interactions should be
extended to include the conventions and invariants maintained by agents
throughout their activity. We refer to this thicker notion of environment as a
lifeworld and present a partial set of formal tools for describing structures
of lifeworlds and the ways in which they computationally simplify activity. As
one specific example, we apply the tools to the analysis of the Toast system
and show how versions of the system with very different control structures in
fact implement a common control structure together with different conventions
for encoding task state in the positions or states of objects in the
environment.
"
9707103,"Defining Relative Likelihood in Partially-Ordered Preferential
  Structures","  Starting with a likelihood or preference order on worlds, we extend it to a
likelihood ordering on sets of worlds in a natural way, and examine the
resulting logic. Lewis earlier considered such a notion of relative likelihood
in the context of studying counterfactuals, but he assumed a total preference
order on worlds. Complications arise when examining partial orders that are not
present for total orders. There are subtleties involving the exact approach to
lifting the order on worlds to an order on sets of worlds. In addition, the
axiomatization of the logic of relative likelihood in the case of partial
orders gives insight into the connection between relative likelihood and
default reasoning.
"
9709102,Identifying Hierarchical Structure in Sequences: A linear-time algorithm,"  SEQUITUR is an algorithm that infers a hierarchical structure from a sequence
of discrete symbols by replacing repeated phrases with a grammatical rule that
generates the phrase, and continuing this process recursively. The result is a
hierarchical representation of the original sequence, which offers insights
into its lexical structure. The algorithm is driven by two constraints that
reduce the size of the grammar, and produce structure as a by-product. SEQUITUR
breaks new ground by operating incrementally. Moreover, the method's simple
structure permits a proof that it operates in space and time that is linear in
the size of the input. Our implementation can process 50,000 symbols per second
and has been applied to an extensive range of real world sequences.
"
9808004,"Differentiated End-to-End Internet Services using a Weighted
  Proportional Fair Sharing TCP","  In this document we study the application of weighted proportional fairness
to data flows in the Internet. We let the users set the weights of their
connections in order to maximise the utility they get from the network. When
combined with a pricing scheme where connections are billed by weight and time,
such a system is known to maximise the total utility of the network. Our study
case is a national Web cache server connected to long distance links. We
propose two ways of weighting TCP connections by manipulating some parameters
of the protocol and present results from simulations and prototypes. We finally
discuss how proportional fairness could be used to implement an Internet with
differentiated services.
"
9808006,Set-Theoretic Completeness for Epistemic and Conditional Logic,"  The standard approach to logic in the literature in philosophy and
mathematics, which has also been adopted in computer science, is to define a
language (the syntax), an appropriate class of models together with an
interpretation of formulas in the language (the semantics), a collection of
axioms and rules of inference characterizing reasoning (the proof theory), and
then relate the proof theory to the semantics via soundness and completeness
results. Here we consider an approach that is more common in the economics
literature, which works purely at the semantic, set-theoretic level. We provide
set-theoretic completeness results for a number of epistemic and conditional
logics, and contrast the expressive power of the syntactic and set-theoretic
approaches
"
9809006,"The Design and Architecture of the Microsoft Cluster Service -- A
  Practical Approach to High-Availability and Scalability","  Microsoft Cluster Service (MSCS) extends the Win-dows NT operating system to
support high-availability services. The goal is to offer an execution
environment where off-the-shelf server applications can continue to operate,
even in the presence of node failures. Later ver-sions of MSCS will provide
scalability via a node and application management system that allows
applications to scale to hundreds of nodes. This paper provides a de-tailed
description of the MSCS architecture and the de-sign decisions that have driven
the implementation of the service. The paper also describes how some major
appli-cations use the MSCS features, and describes features added to make it
easier to implement and manage fault-tolerant applications on MSCS.
"
9809021,Producing NLP-based On-line Contentware,"  For its internal needs as well as for commercial purposes, CDC Group has
produced several NLP-based on-line contentware applications for years. The
development process of such applications is subject to numerous constraints
such as quality of service, integration of new advances in NLP, direct
reactions from users, continuous versioning, short delivery deadlines and cost
control. Following this industrial and commercial experience, malleability of
the applications, their openness towards foreign components, efficiency of
applications and their ease of exploitation have appeared to be key points. In
this paper, we describe TalLab, a powerful architecture for on-line contentware
which fulfils these requirements.
"
9809023,Similarity-Based Queries for Time Series Data,"  We study a set of linear transformations on the Fourier series representation
of a sequence that can be used as the basis for similarity queries on
time-series data. We show that our set of transformations is rich enough to
formulate operations such as moving average and time warping. We present a
query processing algorithm that uses the underlying R-tree index of a
multidimensional data set to answer similarity queries efficiently. Our
experiments show that the performance of this algorithm is competitive to that
of processing ordinary (exact match) queries using the index, and much faster
than sequential scanning. We relate our transformations to the general
framework for similarity queries of Jagadish et al.
"
9809036,"Document Archiving, Replication and Migration Container for Mobile Web
  Users","  With the increasing use of mobile workstations for a wide variety of tasks
and associated information needs, and with many variations of available
networks, access to data becomes a prime consideration. This paper discusses
issues of workstation mobility and proposes a solution wherein the data
structures are accessed in an encapsulated form - through the Portable File
System (PFS) wrapper. The paper discusses an implementation of the Portable
File System, highlighting the architecture and commenting upon performance of
an experimental system. Although investigations have been focused upon mobile
access of WWW documents, this technique could be applied to any mobile data
access situation.
"
9809047,Modeling Traffic Management in ATM Networks with OPNET,"  Asynchronous transfer mode (ATM) is the new generation of computer and
communication networks that are being deployed throughout the telecommunication
industry as well as in campus backbones. ATM technology distinguishes itself
from the previous networking protocols in that it has the latest traffic
management technology and thus allows guaranteeing delay, throughput, and other
performance measures. This in turn, allows users to integrate voice, video, and
data on the same network. Available bit rate (ABR) service in ATM has been
designed to fairly distribute all unused capacity to data traffic and is
specified in the ATM Forum's Traffic Management (TM4.0) standard. This paper
will describe the OPNET models that have been developed for ATM and ABR design
and analysis.
"
9809057,"On Determining the Fair Bandwidth Share for ABR Connections in ATM
  Networks","  The ABR service is designed to fairly allocate the bandwidth unused by higher
priority services. The network indicates to the ABR sources the rates at which
they should transmit to minimize their cell loss. Switches must constantly
measure the demand and available capacity, and divide the capacity fairly among
the contending connections. In order to compute the fair and efficient
allocation for each connection, a switch needs to determine the effective
number of active connections. In this paper, we propose a method for
determining the number of active connections and the fair bandwidth share for
each. We prove the efficiency and fairness of the proposed method analytically,
and simulate it by incorporating it into the ERICA switch algorithm.
"
9809058,"The OSU Scheme for Congestion Avoidance in ATM Networks: Lessons Learnt
  and Extensions","  The OSU scheme is a rate-based congestion avoidance scheme for ATM networks
using explicit rate indication. This work was one of the first attempts to
define explicit rate switch mechanisms and the Resource Management (RM) cell
format in Asynchronous Transfer Mode (ATM) networks. The key features of the
scheme include explicit rate feedback, congestion avoidance, fair operation
while maintaining high utilization, use of input rate as a congestion metric,
O(1) complexity. This paper presents an overview of the scheme, presents those
features of the scheme that have now become common features of other switch
algorithms and discusses three extensions of the scheme.
"
9809059,The ERICA Switch Algorithm for ABR Traffic Management in ATM Networks,"  We propose an explicit rate indication scheme for congestion avoidance in ATM
networks. In this scheme, the network switches monitor their load on each link,
determining a load factor, the available capacity, and the number of currently
active virtual channels. This information is used to advise the sources about
the rates at which they should transmit. The algorithm is designed to achieve
efficiency, fairness, controlled queueing delays, and fast transient response.
The algorithm is also robust to measurement errors caused due to variation in
ABR demand and capacity. We present performance analysis of the scheme using
both analytical arguments and simulation results. The scheme is being
implemented by several ATM switch manufacturers.
"
9809065,"Feedback Consolidation Algorithms for ABR Point-to-Multipoint
  Connections in ATM Networks","  ABR traffic management for point-to-multipoint connections controls the
source rate to the minimum rate supported by all the branches of the multicast
tree. A number of algorithms have been developed for extending ABR congestion
avoidance algorithms to perform feedback consolidation at the branch points.
This paper discusses various design options and implementation alternatives for
the consolidation algorithms, and proposes a number of new algorithms. The
performance of the proposed algorithms and the previous algorithms is compared
under a variety of conditions. Results indicate that the algorithms we propose
eliminate the consolidation noise (caused if the feedback is returned before
all branches respond), while exhibiting a fast transient response.
"
9809066,"TCP Selective Acknowledgments and UBR Drop Policies to Improve ATM-UBR
  Performance over Terrestrial and Satellite Networks","  We study the performance of Selective Acknowledgments with TCP over the
ATM-UBR service category. We examine various UBR drop policies, TCP mechanisms
and network configurations to recommend optimal parameters for TCP over UBR. We
discuss various TCP congestion control mechanisms compare their performance for
LAN and WAN networks. We describe the effect of satellite delays on TCP
performance over UBR and present simulation results for LAN, WAN and satellite
networks. SACK TCP improves the performance of TCP over UBR, especially for
large delay networks. Intelligent drop policies at the switches are an
important factor for good performance in local area networks.
"
9809071,UBR+: Improving Performance of TCP over ATM-UBR service,"  ATM-UBR switches respond to congestion by dropping cells when their buffers
become full. TCP connections running over UBR experience low throughput and
high unfairness. For 100% TCP throughput each switch needs buffers equal to the
sum of the window sizes of all the TCP connections. Intelligent drop policies
can improve the performance of TCP over UBR with limited buffers. The UBR+
service proposes enhancements to UBR for intelligent drop. Early Packet Discard
improves throughput but does not attempt to improve fairness. Selective packet
drop based on per-connection buffer occupancy improves fairness. The Fair
Buffer Allocation scheme further improves both throughput and fairness.
"
9809074,"Performance of TCP/IP Using ATM ABR and UBR Services over Satellite
  Networks","  We study the buffering requirements for zero cell loss for TCP/IP over
satellite links using the available bit rate (ABR) and unspecified bit rate
(UBR) services of asynchronous transfer mode (ATM) networks. For the ABR
service, we explore the effect of feedback delay (a factor which depends upon
the position of the bottleneck), the switch scheme used, and background
variable bit rate (VBR) traffic. It is shown that the buffer requirement for
TCP over ABR is independent of the number of TCP sources, but depends on the
aforementioned factors. For the UBR service, we show that the buffer
requirement is the sum of the TCP receiver window sizes. We substantiate our
arguments with simulation results.
"
9809076,"A Survey of Congestion Control Techniques and Data Link Protocols in
  Satellite Networks","  Satellite communication systems are the means of realizing a global broadband
integrated services digital network. Due to the statistical nature of the
integrated services traffic, the resulting rate fluctuations and burstiness
render congestion control a complicated, yet indispensable function. The long
propagation delay of the earth-satellite link further imposes severe demands
and constraints on the congestion control schemes, as well as the media access
control techniques and retransmission protocols that can be employed in a
satellite network. The problems in designing satellite network protocols, as
well as some of the solutions proposed to tackle these problems, will be the
primary focus of this survey.
"
9809089,"Performance Analysis of FDDI Token Ring Networks: Effect of Parameters
  and Guidelines for Setting TTRT","  The performance of Fiber-Distributed Data Interface (FDDI) depends upon
several workload parameters; for example; the arrival pattern, frame size, and
configuration parameters, such as the number of stations on the ring, extent of
the ring, and number of stations that are waiting to transmit. In addition, the
performance is affected by a parameter called the Target Token Rotation Time
(TTRT), which can be controlled by the network manager. We considered the
effect of TTRT on various performance metrics for different ring configurations
and concluded that a TTRT value of 8 ms provides a good performance over a wide
range of configurations and workloads.
"
9809091,Congestion Control in Computer Networks: Trends and Issues,"  Popular myths that cheaper memory, high-speed links and high-speed processors
will solve the problem of congestion in computer networks are shown to be
false. A simple definition for congestion based on supply and demand of
resources is proposed and is then used to classify various congestion schemes.
The issues that make the congestion problem a difficult one are discussed, and
then the architectural decisions that affect the design of a congestion scheme
are presented. It is argued that long-, medium- and short-term congestion
problems require different solutions. Some of the recent schemes are brifly
surveyed, and areas for further research are discussed.
"
9809096,"A Timeout Based Congestion Control Scheme for Window Flow- Controlled
  Networks","  During overload, most networks drop packets due to buffer unavailability. The
resulting timeouts at the source provide an implicit mechanism to convey
congestion signals from the network to the source. On a timeout, a source
should not only retransmit the lost packet, but it should also reduce its load
on the network. Based on this realization, we have developed a simple
congestion control scheme using the acknowledgment timeouts as indications of
packet loss and congestion. This scheme does not require any new message
formats, therefore, it can be used in any network with window flow control,
e.g., ARPAnet or ISO.
"
9809107,Computing Declarative Prosodic Morphology,"  This paper describes a computational, declarative approach to prosodic
morphology that uses inviolable constraints to denote small finite candidate
sets which are filtered by a restrictive incremental optimization mechanism.
The new approach is illustrated with an implemented fragment of Modern Hebrew
verbs couched in MicroCUF, an expressive constraint logic formalism. For
generation and parsing of word forms, I propose a novel off-line technique to
eliminate run-time optimization. It produces a finite-state oracle that
efficiently restricts the constraint interpreter's search space. As a
byproduct, unknown words can be analyzed without special mechanisms. Unlike
pure finite-state transducer approaches, this hybrid setup allows for more
expressivity in constraints to specify e.g. token identity for reduplication or
arithmetic constraints for phonetics.
"
9809123,A role of constraint in self-organization,"  In this paper we introduce a neural network model of self-organization. This
model uses a variation of Hebb rule for updating its synaptic weights, and
surely converges to the equilibrium status. The key point of the convergence is
the update rule that constrains the total synaptic weight and this seems to
make the model stable. We investigate the role of the constraint and show that
it is the constraint that makes the model stable. For analyzing this setting,
we propose a simple probabilistic game that models the neural network and the
self-organization process. Then, we investigate the characteristics of this
game, namely, the probability that the game becomes stable and the number of
the steps it takes.
"
9810009,Object-Oriented Design of Graph Oriented Data Structures,"  Applied research in graph algorithms and combinatorial structures needs
comprehensive and versatile software libraries. However, the design and the
implementation of flexible libraries are challenging activities. Among the
other problems involved in such a difficult field, a very special role is
played by graph classification issues.
  We propose new techniques devised to help the designer and the programmer in
the development activities. Such techniques are especially suited for dealing
with graph classification problems and rely on an extension of the usual
object-oriented paradigm. In order to support the usage of our approach, we
devised an extension of the C++ programming language and implemented the
corresponding pre-compiler.
"
9810010,C++ Templates as Partial Evaluation,"  This paper explores the relationship between C++ templates and partial
evaluation. Templates were designed to support generic programming, but
unintentionally provided the ability to perform compile-time computations and
code generation. These features are completely accidental, and as a result
their syntax is awkward. By recasting these features in terms of partial
evaluation, a much simpler syntax can be achieved. C++ may be regarded as a
two-level language in which types are first-class values. Template
instantiation resembles an offline partial evaluator. This paper describes
preliminary work toward a single mechanism based on Partial Evaluation which
unifies generic programming, compile-time computation and code generation. The
language Catat is introduced to illustrate these ideas.
"
9810015,Restrictions on Tree Adjoining Languages,"  Several methods are known for parsing languages generated by Tree Adjoining
Grammars (TAGs) in O(n^6) worst case running time. In this paper we investigate
which restrictions on TAGs and TAG derivations are needed in order to lower
this O(n^6) time complexity, without introducing large runtime constants, and
without losing any of the generative power needed to capture the syntactic
constructions in natural language that can be handled by unrestricted TAGs. In
particular, we describe an algorithm for parsing a strict subclass of TAG in
O(n^5), and attempt to show that this subclass retains enough generative power
to make it useful in the general case.
"
9811004,Does Meaning Evolve?,"  A common method of making a theory more understandable, is by comparing it to
another theory which has been better developed. Radical interpretation is a
theory which attempts to explain how communication has meaning. Radical
interpretation is treated as another time-dependent theory and compared to the
time dependent theory of biological evolution. The main reason for doing this
is to find the nature of the time dependence; producing analogs between the two
theories is a necessary prerequisite to this and brings up many problems. Once
the nature of the time dependence is better known it might allow the underlying
mechanism to be uncovered. Several similarities and differences are uncovered,
there appear to be more differences than similarities.
"
9811012,"Deriving Abstract Semantics for Forward Analysis of Normal Logic
  Programs","  The problem of forward abstract interpretation of {\em normal} logic programs
has not been formally addressed in the literature although negation as failure
is dealt with through the built-in predicate ! in the way it is implemented in
Prolog. This paper proposes a solution to this problem by deriving two generic
fixed-point abstract semantics $F^b and $F^\diamond for forward abstract
interpretation of {\em normal} logic programs. $F^b$ is intended for inferring
data descriptions for edges in the program graph where an edge denotes the
possibility that the control of execution transfers from its source program
point to its destination program point. $F^\diamond$ is derived from $F^b$ and
is intended for inferring data descriptions for textual program points.
"
9812003,"Neural Network Methods for Boundary Value Problems Defined in
  Arbitrarily Shaped Domains","  Partial differential equations (PDEs) with Dirichlet boundary conditions
defined on boundaries with simple geometry have been succesfuly treated using
sigmoidal multilayer perceptrons in previous works. This article deals with the
case of complex boundary geometry, where the boundary is determined by a number
of points that belong to it and are closely located, so as to offer a
reasonable representation. Two networks are employed: a multilayer perceptron
and a radial basis function network. The later is used to account for the
satisfaction of the boundary conditions. The method has been successfuly tested
on two-dimensional and three-dimensional PDEs and has yielded accurate
solutions.
"
9812015,"Adaptive Interaction Using the Adaptive Agent Oriented Software
  Architecture (AAOSA)","  User interfaces that adapt their characteristics to those of the user are
referred to as adaptive interfaces. We propose Adaptive Agent Oriented Software
Architecture (AAOSA) as a new way of designing adaptive interfaces. AAOSA is a
new approach to software design based on an agent-oriented architecture. In
this approach agents are considered adaptively communicating concurrent modules
which are divided into a white box module responsible for the communications
and learning, and a black box which is responsible for the independent
specialized processes of the agent. A distributed learning policy that makes
use of this architecture is used for purposes of system adaptability.
"
9812017,"A reusable iterative optimization software library to solve
  combinatorial problems with approximate reasoning","  Real world combinatorial optimization problems such as scheduling are
typically too complex to solve with exact methods. Additionally, the problems
often have to observe vaguely specified constraints of different importance,
the available data may be uncertain, and compromises between antagonistic
criteria may be necessary. We present a combination of approximate reasoning
based constraints and iterative optimization based heuristics that help to
model and solve such problems in a framework of C++ software libraries called
StarFLIP++. While initially developed to schedule continuous caster units in
steel plants, we present in this paper results from reusing the library
components in a shift scheduling system for the workforce of an industrial
production plant.
"
9812018,A Flexible Shallow Approach to Text Generation,"  In order to support the efficient development of NL generation systems, two
orthogonal methods are currently pursued with emphasis: (1) reusable, general,
and linguistically motivated surface realization components, and (2) simple,
task-oriented template-based techniques. In this paper we argue that, from an
application-oriented perspective, the benefits of both are still limited. In
order to improve this situation, we suggest and evaluate shallow generation
methods associated with increased flexibility. We advise a close connection
between domain-motivated and linguistic ontologies that supports the quick
adaptation to new tasks and domains, rather than the reuse of general
resources. Our method is especially designed for generating reports with
limited linguistic variations.
"
9901001,"TDLeaf(lambda): Combining Temporal Difference Learning with Game-Tree
  Search","  In this paper we present TDLeaf(lambda), a variation on the TD(lambda)
algorithm that enables it to be used in conjunction with minimax search. We
present some experiments in both chess and backgammon which demonstrate its
utility and provide comparisons with TD(lambda) and another less radical
variant, TD-directed(lambda). In particular, our chess program, ``KnightCap,''
used TDLeaf(lambda) to learn its evaluation function while playing on the Free
Internet Chess Server (FICS, fics.onenet.net). It improved from a 1650 rating
to a 2100 rating in just 308 games. We discuss some of the reasons for this
success and the relationship between our results and Tesauro's results in
backgammon.
"
9901007,Universal Object Oriented Languages and Computer Algebra,"  The universal object oriented languages made programming more simple and
efficient. In the article is considered possibilities of using similar methods
in computer algebra. A clear and powerful universal language is useful if
particular problem was not implemented in standard software packages like
REDUCE, MATHEMATICA, etc. and if the using of internal programming languages of
the packages looks not very efficient.
  Functional languages like LISP had some advantages and traditions for
algebraic and symbolic manipulations. Functional and object oriented
programming are not incompatible ones. An extension of the model of an object
for manipulation with pure functions and algebraic expressions is considered.
"
9902002,"Automatic Identification of Subjects for Textual Documents in Digital
  Libraries","  The amount of electronic documents in the Internet grows very quickly. How to
effectively identify subjects for documents becomes an important issue. In
past, the researches focus on the behavior of nouns in documents. Although
subjects are composed of nouns, the constituents that determine which nouns are
subjects are not only nouns. Based on the assumption that texts are
well-organized and event-driven, nouns and verbs together contribute the
process of subject identification. This paper considers four factors: 1) word
importance, 2) word frequency, 3) word co-occurrence, and 4) word distance and
proposes a model to identify subjects for textual documents. The preliminary
experiments show that the performance of the proposed model is close to that of
human beings.
"
9902007,KEA: Practical Automatic Keyphrase Extraction,"  Keyphrases provide semantic metadata that summarize and characterize
documents. This paper describes Kea, an algorithm for automatically extracting
keyphrases from text. Kea identifies candidate keyphrases using lexical
methods, calculates feature values for each candidate, and uses a
machine-learning algorithm to predict which candidates are good keyphrases. The
machine learning scheme first builds a prediction model using training
documents with known keyphrases, and then uses the model to find keyphrases in
new documents. We use a large test corpus to evaluate Kea's effectiveness in
terms of how many author-assigned keyphrases are correctly identified. The
system is simple, robust, and publicly available.
"
9902008,Managing Object-Oriented Integration and Regression Testing,"  Systematic testing of object-oriented software turned out to be much more
complex than testing conventional software. Especially the highly incremental
and iterative development cycle demands both many more changes and partially
implemented resp. re-implemented classes. Much more integration and regression
testing has to be done to reach stable stages during the development. In this
presentation we propose a diagram capturing all possible dependencies and
interactions in an object-oriented program. Then we give algorithms and
coverage criteria to identify integration resp. regression test strategys and
all test cases to be executed after some implementation resp. modification
activities. Finally, we summarize some practical experiences and heuristics.
"
9902010,"Multiparty computation unconditionally secure against Q^2 adversary
  structures","  We present here a generalization of the work done by Rabin and Ben-Or. We
give a protocol for multiparty computation which tolerates any Q^2 active
adversary structure based on the existence of a broadcast channel, secure
communication between each pair of participants, and a monotone span program
with multiplication tolerating the structure. The secrecy achieved is
unconditional although we allow an exponentially small probability of error.
This is possible due to a protocol for computing the product of two values
already shared by means of a homomorphic commitment scheme which appeared
originally in a paper of Chaum, Evertse and van de Graaf.
"
9902011,Content-Based Book Recommending Using Learning for Text Categorization,"  Recommender systems improve access to relevant products and information by
making personalized suggestions based on previous examples of a user's likes
and dislikes. Most existing recommender systems use social filtering methods
that base recommendations on other users' preferences. By contrast,
content-based methods use information about an item itself to make suggestions.
This approach has the advantage of being able to recommended previously unrated
items to users with unique interests and to provide explanations for its
recommendations. We describe a content-based book recommending system that
utilizes information extraction and a machine-learning algorithm for text
categorization. Initial experimental results demonstrate that this approach can
produce accurate recommendations.
"
9902022,Semi-Automatic Indexing of Multilingual Documents,"  With the growing significance of digital libraries and the Internet, more and
more electronic texts become accessible to a wide and geographically disperse
public. This requires adequate tools to facilitate indexing, storage, and
retrieval of documents written in different languages. We present a method for
semi-automatic indexing of electronic documents and construction of a
multilingual thesaurus, which can be used for query formulation and information
retrieval. We use special dictionaries and user interaction in order to solve
ambiguities and find adequate canonical terms in the language and adequate
abstract language-independent terms. The abstract thesaurus is updated
incrementally by new indexed documents and is used to search document
concerning terms in a query to the document base.
"
9902028,A Scrollbar-based Visualization for Document Navigation,"  We are interested in questions of improving user control in best-match
text-retrieval systems, specifically questions as to whether simple
visualizations that nonetheless go beyond the minimal ones generally available
can significantly help users. Recently, we have been investigating ways to help
users decide-given a set of documents retrieved by a query-which documents and
passages are worth closer examination. We built a document viewer incorporating
a visualization centered around a novel content-displaying scrollbar and color
term highlighting, and studied whether the visualization is helpful to
non-expert searchers. Participants' reaction to the visualization was very
positive, while the objective results were inconclusive.
"
9903006,Designing SAT for HCP,"  For arbitrary undirected graph $G$, we are designing SATISFIABILITY problem
(SAT) for HCP, using tools of Boolean algebra only. The obtained SAT be the
logic formulation of conditions for Hamiltonian cycle existence, and use $m$
Boolean variables, where $m$ is the number of graph edges. This Boolean
expression is true if and only if an initial graph is Hamiltonian. That is,
each satisfying assignment of the Boolean variables determines a Hamiltonian
cycle of $G$, and each Hamiltonian cycle of $G$ corresponds to a satisfying
assignment of the Boolean variables. In common case, the obtained Boolean
expression may has an exponential length (the number of Boolean literals).
"
9903011,A complete anytime algorithm for balanced number partitioning,"  Given a set of numbers, the balanced partioning problem is to divide them
into two subsets, so that the sum of the numbers in each subset are as nearly
equal as possible, subject to the constraint that the cardinalities of the
subsets be within one of each other. We combine the balanced largest
differencing method (BLDM) and Korf's complete Karmarkar-Karp algorithm to get
a new algorithm that optimally solves the balanced partitioning problem. For
numbers with twelve significant digits or less, the algorithm can optimally
solve balanced partioning problems of arbitrary size in practice. For numbers
with greater precision, it first returns the BLDM solution, then continues to
find better solutions as time allows.
"
9903017,"SIMMUNE, a tool for simulating and analyzing immune system behavior","  We present a new approach to the simulation and analysis of immune system
behavior. The simulations that can be done with our software package called
SIMMUNE are based on immunological data that describe the behavior of immune
system agents (cells, molecules) on a microscopial (i.e. agent-agent
interaction) scale by defining cellular stimulus-response mechanisms. Since the
behavior of the agents in SIMMUNE can be very flexibly configured, its
application is not limited to immune system simulations. We outline the
principles of SIMMUNE's multiscale analysis of emergent structure within the
simulated immune system that allow the identification of immunological contexts
using minimal a priori assumptions about the higher level organization of the
immune system.
"
9903018,LuaJava - A Scripting Tool for Java,"  Scripting languages are becoming more and more important as a tool for
software development, as they provide great flexibility for rapid prototyping
and for configuring componentware applications. In this paper we present
LuaJava, a scripting tool for Java. LuaJava adopts Lua, a dynamically typed
interpreted language, as its script language. Great emphasis is given to the
transparency of the integration between the two languages, so that objects from
one language can be used inside the other like native objects. The final result
of this integration is a tool that allows the construction of configurable Java
applications, using off-the-shelf components, in a high abstraction level.
"
9904015,Mobile ATM Buffer Capacity Analysis,"  This paper extends a stochastic theory for buffer fill distribution for
multiple ``on'' and ``off'' sources to a mobile environment. Queue fill
distribution is described by a set of differential equations assuming sources
alternate asynchronously between exponentially distributed periods in ``on''
and ``off'' states. This paper includes the probabilities that mobile sources
have links to a given queue. The sources represent mobile user nodes, and the
queue represents the capacity of a switch. This paper presents a method of
analysis which uses mobile parameters such as speed, call rates per unit area,
cell area, and call duration and determines queue fill distribution at the ATM
cell level. The analytic results are compared with simulation results.
"
9904018,A Computational Memory and Processing Model for Processing for Prosody,"  This paper links prosody to the information in a text and how it is processed
by the speaker. It describes the operation and output of LOQ, a text-to-speech
implementation that includes a model of limited attention and working memory.
Attentional limitations are key. Varying the attentional parameter in the
simulations varies in turn what counts as given and new in a text, and
therefore, the intonational contours with which it is uttered. Currently, the
system produces prosody in three different styles: child-like, adult
expressive, and knowledgeable. This prosody also exhibits differences within
each style -- no two simulations are alike. The limited resource approach
captures some of the stylistic and individual variety found in natural prosody.
"
9905010,"Statistical Inference and Probabilistic Modelling for Constraint-Based
  NLP","  We present a probabilistic model for constraint-based grammars and a method
for estimating the parameters of such models from incomplete, i.e., unparsed
data. Whereas methods exist to estimate the parameters of probabilistic
context-free grammars from incomplete data (Baum 1970), so far for
probabilistic grammars involving context-dependencies only parameter estimation
techniques from complete, i.e., fully parsed data have been presented (Abney
1997). However, complete-data estimation requires labor-intensive, error-prone,
and grammar-specific hand-annotating of large language corpora. We present a
log-linear probability model for constraint logic programming, and a general
algorithm to estimate the parameters of such models from incomplete data by
extending the estimation algorithm of Della-Pietra, Della-Pietra, and Lafferty
(1997) to incomplete data settings.
"
9905015,State Abstraction in MAXQ Hierarchical Reinforcement Learning,"  Many researchers have explored methods for hierarchical reinforcement
learning (RL) with temporal abstractions, in which abstract actions are defined
that can perform many primitive actions before terminating. However, little is
known about learning with state abstractions, in which aspects of the state
space are ignored. In previous work, we developed the MAXQ method for
hierarchical RL. In this paper, we define five conditions under which state
abstraction can be combined with the MAXQ value function decomposition. We
prove that the MAXQ-Q learning algorithm converges under these conditions and
show experimentally that state abstraction is important for the successful
application of MAXQ-Q learning.
"
9906020,Temporal Meaning Representations in a Natural Language Front-End,"  Previous work in the context of natural language querying of temporal
databases has established a method to map automatically from a large subset of
English time-related questions to suitable expressions of a temporal logic-like
language, called TOP. An algorithm to translate from TOP to the TSQL2 temporal
database language has also been defined. This paper shows how TOP expressions
could be translated into a simpler logic-like language, called BOT. BOT is very
close to traditional first-order predicate logic (FOPL), and hence existing
methods to manipulate FOPL expressions can be exploited to interface to
time-sensitive applications other than TSQL2 databases, maintaining the
existing English-to-TOP mapping.
"
9906025,Mapping Multilingual Hierarchies Using Relaxation Labeling,"  This paper explores the automatic construction of a multilingual Lexical
Knowledge Base from pre-existing lexical resources. We present a new and robust
approach for linking already existing lexical/semantic hierarchies. We used a
constraint satisfaction algorithm (relaxation labeling) to select --among all
the candidate translations proposed by a bilingual dictionary-- the right
English WordNet synset for each sense in a taxonomy automatically derived from
a Spanish monolingual dictionary. Although on average, there are 15 possible
WordNet connections for each sense in the taxonomy, the method achieves an
accuracy over 80%. Finally, we also propose several ways in which this
technique could be applied to enrich and improve existing lexical databases.
"
9906028,On the Power of Positive Turing Reductions,"  In the early 1980s, Selman's seminal work on positive Turing reductions
showed that positive Turing reduction to NP yields no greater computational
power than NP itself. Thus, positive Turing and Turing reducibility to NP
differ sharply unless the polynomial hierarchy collapses.
  We show that the situation is quite different for DP, the next level of the
boolean hierarchy. In particular, positive Turing reduction to DP already
yields all (and only) sets Turing reducibility to NP. Thus, positive Turing and
Turing reducibility to DP yield the same class. Additionally, we show that an
even weaker class, P(NP[1]), can be substituted for DP in this context.
"
9906033,Robust Reductions,"  We continue the study of robust reductions initiated by Gavalda and Balcazar.
In particular, a 1991 paper of Gavalda and Balcazar claimed an optimal
separation between the power of robust and nondeterministic strong reductions.
Unfortunately, their proof is invalid. We re-establish their theorem.
  Generalizing robust reductions, we note that robustly strong reductions are
built from two restrictions, robust underproductivity and robust
overproductivity, both of which have been separately studied before in other
contexts. By systematically analyzing the power of these reductions, we explore
the extent to which each restriction weakens the power of reductions. We show
that one of these reductions yields a new, strong form of the Karp-Lipton
Theorem.
"
9907028,Further Results on Arithmetic Filters for Geometric Predicates,"  An efficient technique to solve precision problems consists in using exact
computations. For geometric predicates, using systematically expensive exact
computations can be avoided by the use of filters. The predicate is first
evaluated using rounding computations, and an error estimation gives a
certificate of the validity of the result. In this note, we studies the
statistical efficiency of filters for cosphericity predicate with an assumption
of regular distribution of the points. We prove that the expected value of the
polynomial corresponding to the in sphere test is greater than epsilon with
probability O(epsilon log 1/epsilon) improving the results of a previous paper
by the same authors.
"
9907036,"Exact Analysis of Dodgson Elections: Lewis Carroll's 1876 Voting System
  is Complete for Parallel Access to NP","  In 1876, Lewis Carroll proposed a voting system in which the winner is the
candidate who with the fewest changes in voters' preferences becomes a
Condorcet winner---a candidate who beats all other candidates in pairwise
majority-rule elections. Bartholdi, Tovey, and Trick provided a lower
bound---NP-hardness---on the computational complexity of determining the
election winner in Carroll's system. We provide a stronger lower bound and an
upper bound that matches our lower bound. In particular, determining the winner
in Carroll's system is complete for parallel access to NP, i.e., it is complete
for $\thetatwo$, for which it becomes the most natural complete problem known.
It follows that determining the winner in Carroll's elections is not
NP-complete unless the polynomial hierarchy collapses.
"
9907038,A Second Step Towards Complexity-Theoretic Analogs of Rice's Theorem,"  Rice's Theorem states that every nontrivial language property of the
recursively enumerable sets is undecidable. Borchert and Stephan initiated the
search for complexity-theoretic analogs of Rice's Theorem. In particular, they
proved that every nontrivial counting property of circuits is UP-hard, and that
a number of closely related problems are SPP-hard.
  The present paper studies whether their UP-hardness result itself can be
improved to SPP-hardness. We show that their UP-hardness result cannot be
strengthened to SPP-hardness unless unlikely complexity class containments
hold. Nonetheless, we prove that every P-constructibly bi-infinite counting
property of circuits is SPP-hard. We also raise their general lower bound from
unambiguous nondeterminism to constant-ambiguity nondeterminism.
"
9909003,Iterative Deepening Branch and Bound,"  In tree search problem the best-first search algorithm needs too much of
space . To remove such drawbacks of these algorithms the IDA* was developed
which is both space and time cost efficient. But again IDA* can give an optimal
solution for real valued problems like Flow shop scheduling, Travelling
Salesman and 0/1 Knapsack due to their real valued cost estimates. Thus further
modifications are done on it and the Iterative Deepening Branch and Bound
Search Algorithms is developed which meets the requirements. We have tried
using this algorithm for the Flow Shop Scheduling Problem and have found that
it is quite effective.
"
9909005,Computing largest circles separating two sets of segments,"  A circle $C$ separates two planar sets if it encloses one of the sets and its
open interior disk does not meet the other set. A separating circle is a
largest one if it cannot be locally increased while still separating the two
given sets. An Theta(n log n) optimal algorithm is proposed to find all largest
circles separating two given sets of line segments when line segments are
allowed to meet only at their endpoints. In the general case, when line
segments may intersect $\Omega(n^2)$ times, our algorithm can be adapted to
work in O(n alpha(n) log n) time and O(n \alpha(n)) space, where alpha(n)
represents the extremely slowly growing inverse of the Ackermann function.
"
9909012,Certificate Revocation Paradigms,"  Research in the field of electronic signature confirmation has been active
for some 20 years now. Unfortunately present certificate-based solutions also
come from that age when no-one knew about online data transmission. The
official standardized X.509 framework also depends heavily on offline
operations, one of the most complicated ones being certificate revocation
handling. This is done via huge Certificate Revocation Lists which are both
inconvenient and expencive. Several improvements to these lists are proposed
and in this report we try to analyze them briefly. We conclude that although it
is possible to do better than in the original X.509 setting, none of the
solutions presented this far is good enough.
"
9909014,Reasoning About Common Knowledge with Infinitely Many Agents,"  Complete axiomatizations and exponential-time decision procedures are
provided for reasoning about knowledge and common knowledge when there are
infinitely many agents. The results show that reasoning about knowledge and
common knowledge with infinitely many agents is no harder than when there are
finitely many agents, provided that we can check the cardinality of certain set
differences G - G', where G and G' are sets of agents. Since our complexity
results are independent of the cardinality of the sets G involved, they
represent improvements over the previous results even with the sets of agents
involved are finite. Moreover, our results make clear the extent to which
issues of complexity and completeness depend on how the sets of agents involved
are represented.
"
9909017,Finding an ordinary conic and an ordinary hyperplane,"  Given a finite set of non-collinear points in the plane, there exists a line
that passes through exactly two points. Such a line is called an ordinary line.
An efficient algorithm for computing such a line was proposed by Mukhopadhyay
et al. In this note we extend this result in two directions. We first show how
to use this algorithm to compute an ordinary conic, that is, a conic passing
through exactly five points, assuming that all the points do not lie on the
same conic. Both our proofs of existence and the consequent algorithms are
simpler than previous ones. We next show how to compute an ordinary hyperplane
in three and higher dimensions.
"
9910005,Query Order and the Polynomial Hierarchy,"  Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] initiated the field of
query order, which studies the ways in which computational power is affected by
the order in which information sources are accessed. The present paper studies,
for the first time, query order as it applies to the levels of the polynomial
hierarchy. We prove that the levels of the polynomial hierarchy are
order-oblivious. Yet, we also show that these ordered query classes form new
levels in the polynomial hierarchy unless the polynomial hierarchy collapses.
We prove that all leaf language classes - and thus essentially all standard
complexity classes - inherit all order-obliviousness results that hold for P.
"
9910008,Translating Equality Downwards,"  Downward translation of equality refers to cases where a collapse of some
pair of complexity classes would induce a collapse of some other pair of
complexity classes that (a priori) one expects are smaller. Recently, the first
downward translation of equality was obtained that applied to the polynomial
hierarchy-in particular, to bounded access to its levels [cs.CC/9910007]. In
this paper, we provide a much broader downward translation that extends not
only that downward translation but also that translation's elegant enhancement
by Buhrman and Fortnow. Our work also sheds light on previous research on the
structure of refined polynomial hierarchies, and strengthens the connection
between the collapse of bounded query hierarchies and the collapse of the
polynomial hierarchy.
"
9911009,Two-way finite automata with quantum and classical states,"  We introduce 2-way finite automata with quantum and classical states
(2qcfa's). This is a variant on the 2-way quantum finite automata (2qfa) model
which may be simpler to implement than unrestricted 2qfa's; the internal state
of a 2qcfa may include a quantum part that may be in a (mixed) quantum state,
but the tape head position is required to be classical.
  We show two languages for which 2qcfa's are better than classical 2-way
automata. First, 2qcfa's can recognize palindromes, a language that cannot be
recognized by 2-way deterministic or probabilistic finite automata. Second, in
polynomial time 2qcfa's can recognize {a^n b^n | n>=0}, a language that can be
recognized classically by a 2-way probabilistic automaton but only in
exponential time.
"
9912007,"An Example-Based Approach to Japanese-to-English Translation of Tense,
  Aspect, and Modality","  We have developed a new method for Japanese-to-English translation of tense,
aspect, and modality that uses an example-based method. In this method the
similarity between input and example sentences is defined as the degree of
semantic matching between the expressions at the ends of the sentences. Our
method also uses the k-nearest neighbor method in order to exclude the effects
of noise; for example, wrongly tagged data in the bilingual corpora.
Experiments show that our method can translate tenses, aspects, and modalities
more accurately than the top-level MT software currently available on the
market can. Moreover, it does not require hand-craft rules.
"
9912013,Multivariate Regression Depth,"  The regression depth of a hyperplane with respect to a set of n points in R^d
is the minimum number of points the hyperplane must pass through in a rotation
to vertical. We generalize hyperplane regression depth to k-flats for any k
between 0 and d-1. The k=0 case gives the classical notion of center points. We
prove that for any k and d, deep k-flats exist, that is, for any set of n
points there always exists a k-flat with depth at least a constant fraction of
n. As a consequence, we derive a linear-time (1+epsilon)-approximation
algorithm for the deepest flat.
"
9912018,Computation in an algebra of test selection criteria,"  One of the key concepts in testing is that of adequate test sets. A test
selection criterion decides which test sets are adequate. In this paper, a
language schema for specifying a large class of test selection criteria is
developed; the schema is based on two operations for building complex criteria
from simple ones. Basic algebraic properties of the two operations are derived.
  In the second part of the paper, a simple language-an instance of the general
schema-is studied in detail, with the goal of generating small adequate test
sets automatically. It is shown that one version of the problem is intractable,
while another is solvable by an efficient algorithm. An implementation of the
algorithm is described.
"
